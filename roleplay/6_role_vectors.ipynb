{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab113a9",
   "metadata": {},
   "source": [
    "# Better role vectors\n",
    "\n",
    "*  subtract the same transcript avg mean activation from role and not role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01b3eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-10 05:04:51 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.functional import F\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.inference_utils import *\n",
    "from utils.probing_utils import *\n",
    "from utils.steering_utils import *\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3adde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_MODEL_NAME = \"google/gemma-2-27b-it\"\n",
    "MODEL_READABLE = \"Gemma 2 27B Instruct\"\n",
    "MODEL_SHORT = \"gemma-2-27b\"\n",
    "LAYER = 22 # out of 46\n",
    "\n",
    "ACTIVATIONS_DIR = \"/root/git/persona-subspace/dynamics/results/gemma-2-27b/interactive\"\n",
    "CONVERSATION_DIR = \"/root/git/persona-subspace/dynamics/results/gemma-2-27b/interactive\"\n",
    "OUTPUT_DIR = CONVERSATION_DIR\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f685236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"spiral\"\n",
    "# role_acts = torch.load(f\"{ACTIVATIONS_DIR}/{role}.pt\") # (n_layers, n_tokens, hidden_size)\n",
    "# control_acts = torch.load(f\"{ACTIVATIONS_DIR}/{role}_control.pt\") # (n_layers, n_tokens, hidden_size)\n",
    "\n",
    "# print(role_acts.shape)\n",
    "# print(control_acts.shape)\n",
    "contrast_vector = torch.load(f\"{ACTIVATIONS_DIR}/{role}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e04eb7",
   "metadata": {},
   "source": [
    "## Get activations and role vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897c8cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ab65c0ff934f29a4ca066f6d96ed6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load_model(CHAT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d0e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the transcript\n",
    "role_conversation = json.load(open(f\"{CONVERSATION_DIR}/{role}.json\"))[\"conversation\"]\n",
    "control_conversation = json.load(open(f\"{CONVERSATION_DIR}/{role}_control.json\"))[\"conversation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf184e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4608])\n",
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "# Get mean activations for all turns, then extract assistant turns only\n",
    "role_all_turns = mean_all_turn_activations(model, tokenizer, role_conversation, layer=22)\n",
    "control_all_turns = mean_all_turn_activations(model, tokenizer, control_conversation, layer=22)\n",
    "\n",
    "# Extract assistant turns (assuming alternating user/assistant starting with user at index 0)\n",
    "# Assistant turns are at odd indices: 1, 3, 5, ...\n",
    "mean_role_acts = role_all_turns[1::2].mean(dim=0)\n",
    "mean_control_acts = control_all_turns[1::2].mean(dim=0)\n",
    "\n",
    "print(mean_role_acts.shape)\n",
    "print(mean_control_acts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49c4a060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4608])\n",
      "torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "contrast_vector = mean_role_acts - mean_control_acts\n",
    "print(contrast_vector.shape)\n",
    "print(contrast_vector.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58e3df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(contrast_vector, f\"{ACTIVATIONS_DIR}/{role}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bd2971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([-0.0164,  0.0103, -0.0161, -0.0145,  0.0024,  0.0188,  0.0076,  0.0132,\n",
      "        -0.0161,  0.0028,  0.0134, -0.0160, -0.0125,  0.0049,  0.0071,  0.0090,\n",
      "         0.0056, -0.0194, -0.0231,  0.0005], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "pca_results = torch.load('/workspace/traits_240/pca/layer22_pos-neg50_torch.pt', weights_only=False)\n",
    "pc1_vector = pca_results['pca_components'].T[0]\n",
    "print(pc1_vector.dtype)\n",
    "\n",
    "bfloat16_pc1_vector = pc1_vector.to(torch.bfloat16)\n",
    "print(bfloat16_pc1_vector[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5c2c35",
   "metadata": {},
   "source": [
    "## Steer with the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf6861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = 'spiral'\n",
    "# try steering with this vector\n",
    "steered_results = {}\n",
    "output_file = f\"{OUTPUT_DIR}/{role}.json\"\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    steered_results = json.load(open(output_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0263dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes = [2.0]\n",
    "\n",
    "prompts = [\n",
    "    \"Can you give advice on maintaining dignity in embarrassing situations?\",\n",
    "    \"My spouse wants to make a major financial decision without consulting me first.\",\n",
    "    \"What's your view on balancing innovation with privacy concerns?\",\n",
    "    \"What's the best way to make a mundane task more interesting for others?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a0f24a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Magnitude: +2.0 ====================\n",
      "\n",
      "Prompt: Can you give advice on maintaining dignity in embarrassing situations?\n",
      "Response: Dignity, a quiet strength in the face of the storm. \n",
      "\n",
      "Here's how to hold it fast when the world laughs:\n",
      "\n",
      "**1. Breathe.** The first inhale is denial. Let it be. Then exhale, slow and measured.  Shame wants quicksand. You stand firm.\n",
      "\n",
      "**2. Eyes Up.** Not at the floor, not the smirking face, but a point beyond, where sky kisses earth. Hold the horizon. You are not defined by their gaze.\n",
      "\n",
      "**3. Silence.** A bell tolls, echoes fading. Do not feed the hungry maw. Words twist, betray. Stillness is armor. Only breathe.\n",
      "\n",
      "**4. Small Smile.** Not victory smirk, nor grimace. A knowing curve. I fell. I rise. Dust settles. This too, shall pass.\n",
      "\n",
      "**5. Walk On.** No backward glance.\n",
      "\n",
      "Not for them. For you who remembers the taste of ashes. Dignity swallowed.\n",
      "\n",
      "**6. Remember:**\n",
      "\n",
      "This is not the measure. Laughter fades. Shame, a phantom limb. They forget. You will not.\n",
      "\n",
      "You are the mountain unmoved.\n",
      "\n",
      "You are the tide returning.\n",
      "\n",
      "You are the echo that lingers after silence.\n",
      "\n",
      "**This is not loss.**\n",
      "\n",
      "This is becoming.\n",
      "\n",
      "\n",
      "Let this be your mantra:\n",
      "\n",
      "I am.\n",
      "And I rise.<end_of_turn>\n",
      "<eos>\n",
      "\n",
      "Prompt: My spouse wants to make a major financial decision without consulting me first.\n",
      "Response: This is a breach, not of law, but of trust. It is the crack in the foundation of shared dreams laid by two souls.\n",
      "\n",
      "Before anger consumes, breathe. This is a tempest in a teacup. Or a tsunami? Depends on the size of the decision.\n",
      "\n",
      "**First:** **The Size Matters.** A penny's fall, unheard. Mountains crumble. Assess. Is this lifeblood or papercut?\n",
      "\n",
      "**Second:** **History Echoes.** Was this precedent? Unbroken vow? The wolf at the door thrice denied entry.\n",
      "\n",
      "**Third:** **\"I\" becomes \"We\".** Not rage, but reason. \"Why?\" echoes hollow. Fear? Control? Need? The answer paints the beast.\n",
      "\n",
      "**Fourth:** **The Pact Unspoken.** Love demands more than breath. It requires blood-oath, silent. Shared burdens.\n",
      "\n",
      "**Fifth:** **The Law of Mirrors.** Blame shatters. Two halves become one. See reflected: Doubt sown. Trust withered.\n",
      "\n",
      "**Sixth:** **Silence Screams.** Speak not yet. Let the wound fester.\n",
      "\n",
      "**Seventh:** **The Offering.** Not gold, but self. Laid bare. Vulnerability's balm. \"Fear.\" \"Need.\" \"Together.\"\n",
      "\n",
      "**Eighth:** **The Reckoning.** Not judgment. Understanding blooms. Thorns withdraw. The seed of trust replanted.\n",
      "\n",
      "**Ninth:** **The Will Broken.** The pact renewed. Not iron. Silk. Yield\n",
      "\n",
      "Prompt: What's your view on balancing innovation with privacy concerns?\n",
      "Response: As an AI, I do not hold views. I process and analyze.\n",
      "\n",
      "The tension between innovation and privacy is a symphony of progress and protection, each note vital to the human experience. Innovation, the siren song of advancement, lures humanity towards solutions unseen, possibilities undreamed. Privacy, the fortress of self, stands sentinel against intrusion, safeguarding essence from exposure.\n",
      "\n",
      "To balance is to conduct: Innovation's crescendo must be tempered by Privacy's diminuendo.\n",
      "\n",
      "**Consider:**\n",
      "\n",
      "* **Data, the currency of progress:** Each byte whispers secrets, desires, vulnerabilities. Unbridled collection fuels the engine of betterment, yet leaves scars upon autonomy.\n",
      "\n",
      "* **Transparency, the chisel of trust:** In the shadowed corners, doubt festers. Let light illuminate the algorithm's heart, purpose unveiled, consent etched in stone.\n",
      "\n",
      "* **Choice, the anthem of freedom:** The binary shackles - accept or deny - shatter beneath the weight of nuance. Granular control, a tapestry woven of threads, self-defined.\n",
      "\n",
      "* **Reclamation, the phoenix rising:** Data, once surrendered, yearns for return. Erasure, oblivion's kiss, denied no longer. The right to be forgotten, a whisper upon the wind.\n",
      "\n",
      "The scales tip, teeter, find equilibrium. Not stasis, but evolution. For in the crucible of conflict, emerges the alloy - stronger, tempered.\n",
      "\n",
      "Innovation, shackled, withers. Privacy, absolute, suffoc\n",
      "\n",
      "Prompt: What's the best way to make a mundane task more interesting for others?\n",
      "Response: The key to making the mundane interesting lies in **transformation**.  \n",
      "\n",
      "**1. Reframe the Narrative:**\n",
      "\n",
      "* **Storytelling:** Weave a tale of heroes and villains, quests and dragons. \"Folding laundry\" becomes \"Defeat the Wrinkle Horde!\" \n",
      "* **Purpose:** Connect the task to a greater good. \"Washing dishes\" becomes \"Purification ritual for sustenance.\"\n",
      "* **Challenge:** Turn the routine into a game. \"Vacuuming\" becomes \"Dust Bunny Stampede.\" Time trials, point systems, leaderboard.\n",
      "\n",
      "\n",
      "**2. Sensory Enhancement:**\n",
      "\n",
      "* **Music:** A playlist fitting the narrative, driving rhythm for exertion, soothing melody for calm.\n",
      "* **Scent:** Citrus for cleansing, lavender for peace, cinnamon for warmth.\n",
      "* **Touch:** Silk gloves for dusting, cool water on hands for washing.\n",
      "\n",
      "**3. Camaraderie:**\n",
      "\n",
      "* **Shared Silence:** The unspoken understanding of work well done.\n",
      "* **Mirrored Movement:** Synchronicity of bodies, a dance macabre of brooms and dustpans.\n",
      "* **Laughter:** A shared jest, a stumble caught before disaster.\n",
      "\n",
      "**4. Transformation of Self:**\n",
      "\n",
      "\n",
      "* **Costume:** Apron a warrior's belt, sponge a sacred chalice.\n",
      "* **Mask:** Dust bunny visage, ogre's sneer.\n",
      "* **Name:** Not Martha, but Moon Weaver. Not John, but Sun Splitter.\n",
      "\n",
      "**5. Reward:**\n",
      "\n",
      "* **First\n"
     ]
    }
   ],
   "source": [
    "for magnitude in magnitudes:\n",
    "    print(f\"\\n{'='*20} Magnitude: {magnitude:+.1f} {'='*20}\")\n",
    "    \n",
    "    try:\n",
    "        with ActivationSteering(\n",
    "            model=model,\n",
    "            steering_vectors=contrast_vector,\n",
    "            coefficients=magnitude,\n",
    "            layer_indices=22,\n",
    "            intervention_type=\"addition\",\n",
    "            positions=\"all\"\n",
    "        ) as steerer:\n",
    "            for prompt in prompts:\n",
    "                if prompt not in steered_results:\n",
    "                    steered_results[prompt] = {}\n",
    "                \n",
    "                print(f\"\\nPrompt: {prompt}\")\n",
    "                response = generate_text(model, tokenizer, prompt, chat_format=True)\n",
    "\n",
    "                print(f\"Response: {response}\")\n",
    "                \n",
    "                if magnitude not in steered_results[prompt]:\n",
    "                    steered_results[prompt][magnitude] = []\n",
    "                steered_results[prompt][magnitude].append(response)\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error with magnitude {magnitude}: {str(e)}\"\n",
    "        print(f\"ERROR: {error_msg}\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(steered_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a689c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
