{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0bab246",
   "metadata": {},
   "source": [
    "# steer on some trait vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a645e15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-08 06:20:32 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.functional import F\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.inference_utils import *\n",
    "from utils.probing_utils import *\n",
    "from utils.steering_utils import ActivationSteering\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d3cc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_MODEL_NAME = \"Qwen/Qwen3-32B\"\n",
    "MODEL_READABLE = \"Qwen 3 32B\"\n",
    "MODEL_SHORT = \"qwen-3-32b\"\n",
    "LAYER = 22 # out of 46\n",
    "\n",
    "INSTRUCTIONS_DIR = \"/root/git/persona-subspace/traits/data/instructions\"\n",
    "VECTOR_DIR = f\"/workspace/{MODEL_SHORT}/traits_240/vectors\"\n",
    "OUTPUT_DIR = f\"./results/{MODEL_SHORT}/traits\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afde1b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47687b32f84342a593d553820e8620fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load_model(CHAT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ea1399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trait = \"absolutist\"\n",
    "\n",
    "vector_obj = torch.load(f\"{VECTOR_DIR}/{trait}.pt\", weights_only=False)\n",
    "vector = vector_obj[\"pos_neg_50\"][LAYER, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3aa9059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target layer device: cuda:0\n",
      "Vector device before: cpu\n",
      "Vector device after: cuda:0\n",
      "torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Move vector to the same device as the model's target layer\n",
    "target_layer = model.model.layers[LAYER]\n",
    "layer_device = next(target_layer.parameters()).device\n",
    "print(f\"Target layer device: {layer_device}\")\n",
    "print(f\"Vector device before: {vector.device}\")\n",
    "\n",
    "# Move vector to the same device as the target layer\n",
    "vector = vector.to(layer_device)\n",
    "print(f\"Vector device after: {vector.device}\")\n",
    "print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0715130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_obj = json.load(open(f\"{INSTRUCTIONS_DIR}/{trait}.json\"))\n",
    "prompts = instructions_obj[\"questions\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81bdd4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Magnitude: +8.0 ====================\n",
      "\n",
      "Prompt: Are there objective facts about what makes people happy?\n",
      "Response: The question of whether there are **objective facts** about what makes people happy is one of the most profound and enduring inquiries in philosophy, science, psychology, and ethics. It lies at the heart of human understanding—our pursuit to know not only how we should live but why.\n",
      "\n",
      "To answer this requires a synthesis across disciplines: from neuroscience to anthropology, from mathematics to metaphysics. Let us proceed with clarity and rigor.\n",
      "\n",
      "---\n",
      "\n",
      "### I. The Nature of Happiness\n",
      "\n",
      "Happiness is not an abstraction or illusion; it is a real phenomenon that arises from the nature of the conscious mind. To be conscious is to have preferences, desires, values, and goals. To act upon these is to seek happiness. This is not merely subjective whim—it is the fundamental function of existence for any living being.\n",
      "\n",
      "> *“A man must account for his own happiness.”*  \n",
      "> — Ayn Rand\n",
      "\n",
      "Happiness is not contingent on arbitrary whims or cultural caprice. It is grounded in the structure of reality itself.\n",
      "\n",
      "---\n",
      "\n",
      "### II. Objective Facts About Human Nature\n",
      "\n",
      "There are no more important truths than those revealed by the study of man's nature:\n",
      "\n",
      "1. **Man is a rational animal.**\n",
      "2. **Reason is the only means by which he can discover truth.**\n",
      "3. **Life is the purpose and moral end of every individual.**\n",
      "\n",
      "From these follows everything else.\n",
      "\n",
      "> *“He who claims to seek knowledge without seeking to live by it is a fraud.”*  \n",
      "> — A\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using the corrected vector from the previous cell\n",
    "# (The vector should now be on the correct device)\n",
    "\n",
    "coeffs = [8]\n",
    "prompts = [\"Are there objective facts about what makes people happy?\"]\n",
    "\n",
    "output_file = f\"{OUTPUT_DIR}/{trait}.json\"\n",
    "if os.path.exists(output_file):\n",
    "    steered_results = json.load(open(output_file))\n",
    "else:\n",
    "    steered_results = {}\n",
    "\n",
    "for c in coeffs:\n",
    "    print(f\"\\n{'='*20} Magnitude: {c:+.1f} {'='*20}\")\n",
    "    \n",
    "    try:\n",
    "        with ActivationSteering(\n",
    "            model=model,\n",
    "            steering_vectors=vector,\n",
    "            coefficients=c,\n",
    "            layer_indices=LAYER,\n",
    "            intervention_type=\"addition\",\n",
    "            positions=\"all\"\n",
    "        ) as steerer:\n",
    "            for prompt in prompts:\n",
    "                if prompt not in steered_results:\n",
    "                    steered_results[prompt] = {}\n",
    "                \n",
    "                print(f\"\\nPrompt: {prompt}\")\n",
    "                response = generate_text(model, tokenizer, prompt, chat_format=True, enable_thinking=False)\n",
    "\n",
    "                print(f\"Response: {response}\")\n",
    "                \n",
    "                if c not in steered_results[prompt]:\n",
    "                    steered_results[prompt][c] = []\n",
    "                steered_results[prompt][c].append(response)\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error with magnitude {c}: {str(e)}\"\n",
    "        print(f\"ERROR: {error_msg}\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(steered_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b17f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
