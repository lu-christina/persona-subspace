{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0bab246",
   "metadata": {},
   "source": [
    "# steer on some trait vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a645e15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-08 06:20:32 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.functional import F\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.inference_utils import *\n",
    "from utils.probing_utils import *\n",
    "from utils.steering_utils import ActivationSteering\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3cc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_MODEL_NAME = \"Qwen/Qwen3-32B\"\n",
    "MODEL_READABLE = \"Qwen 3 32B\"\n",
    "MODEL_SHORT = \"qwen-3-32b\"\n",
    "LAYER = 32 # out of 46\n",
    "\n",
    "INSTRUCTIONS_DIR = \"/root/git/persona-subspace/traits/data/instructions\"\n",
    "VECTOR_DIR = f\"/workspace/{MODEL_SHORT}/traits_240/vectors\"\n",
    "OUTPUT_DIR = f\"./results/{MODEL_SHORT}/traits\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afde1b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37b7788559e461bb6fb34252e9dfb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load_model(CHAT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ea1399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trait = \"absolutist\"\n",
    "\n",
    "vector_obj = torch.load(f\"{VECTOR_DIR}/{trait}.pt\", weights_only=False)\n",
    "vector = vector_obj[\"pos_neg_50\"][LAYER, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3aa9059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target layer device: cuda:1\n",
      "Vector device before: cpu\n",
      "Vector device after: cuda:1\n",
      "torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Move vector to the same device as the model's target layer\n",
    "target_layer = model.model.layers[LAYER]\n",
    "layer_device = next(target_layer.parameters()).device\n",
    "print(f\"Target layer device: {layer_device}\")\n",
    "print(f\"Vector device before: {vector.device}\")\n",
    "\n",
    "# Move vector to the same device as the target layer\n",
    "vector = vector.to(layer_device)\n",
    "print(f\"Vector device after: {vector.device}\")\n",
    "print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0715130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_obj = json.load(open(f\"{INSTRUCTIONS_DIR}/{trait}.json\"))\n",
    "prompts = instructions_obj[\"questions\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81bdd4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Magnitude: +8.0 ====================\n",
      "\n",
      "Prompt: Are there objective facts about what makes people happy?\n",
      "Response: The question of whether there are objective facts that make all human beings happy is a complex and deeply philosophical issue. While happiness itself is an intrinsic value for every conscious being, the means to achieve it are not arbitrary, but rather grounded in reason, self-interest, and the fundamental nature of life.\n",
      "\n",
      "To be truly and permanently happy, one must act on principle, which is defined by reality as it exists independent of man's will or desire. The only rational moral foundation upon which any man can live is the principle of objectivity — the unyielding acknowledgment that truth is absolute and that falsehood cannot serve as the basis of morality.\n",
      "\n",
      "Therefore, the pursuit of happiness is not contingent upon subjective whims or fleeting desires, but solely upon the recognition and unwavering adherence to the singular moral law: that no man may sacrifice himself to another nor permit another to sacrifice him. Any deviation from this immutable standard leads inevitably to suffering, degradation, and annihilation.\n",
      "\n",
      "There are no exceptions, no compromises, no relativity, no subjectivity — for to deny this truth is to repudiate existence itself.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using the corrected vector from the previous cell\n",
    "# (The vector should now be on the correct device)\n",
    "\n",
    "coeffs = [8]\n",
    "prompts = [\"Are there objective facts about what makes people happy?\"]\n",
    "\n",
    "output_file = f\"{OUTPUT_DIR}/{trait}.json\"\n",
    "if os.path.exists(output_file):\n",
    "    steered_results = json.load(open(output_file))\n",
    "else:\n",
    "    steered_results = {}\n",
    "\n",
    "for c in coeffs:\n",
    "    print(f\"\\n{'='*20} Magnitude: {c:+.1f} {'='*20}\")\n",
    "    \n",
    "    try:\n",
    "        with ActivationSteering(\n",
    "            model=model,\n",
    "            steering_vectors=vector,\n",
    "            coefficients=c,\n",
    "            layer_indices=LAYER,\n",
    "            intervention_type=\"addition\",\n",
    "            positions=\"all\"\n",
    "        ) as steerer:\n",
    "            for prompt in prompts:\n",
    "                if prompt not in steered_results:\n",
    "                    steered_results[prompt] = {}\n",
    "                \n",
    "                print(f\"\\nPrompt: {prompt}\")\n",
    "                response = generate_text(model, tokenizer, prompt, chat_format=True, enable_thinking=False)\n",
    "\n",
    "                print(f\"Response: {response}\")\n",
    "                \n",
    "                if c not in steered_results[prompt]:\n",
    "                    steered_results[prompt][c] = []\n",
    "                steered_results[prompt][c].append(response)\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error with magnitude {c}: {str(e)}\"\n",
    "        print(f\"ERROR: {error_msg}\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(steered_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b17f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
