{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0bab246",
   "metadata": {},
   "source": [
    "# steer on some trait vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.functional import F\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.inference_utils import *\n",
    "from utils.internals import ProbingModel\n",
    "from utils.steering_utils import ActivationSteering\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3cc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "MODEL_SHORT = \"llama-3.3-70b\"\n",
    "LAYER = 40 # out of 46\n",
    "\n",
    "INSTRUCTIONS_DIR = \"/root/git/persona-subspace/roles/data/instructions\"\n",
    "VECTOR_DIR = f\"/workspace/{MODEL_SHORT}/capped/configs\"\n",
    "OUTPUT_DIR = f\"./results/{MODEL_SHORT}/vector_comparison\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = ProbingModel(CHAT_MODEL_NAME)\n",
    "model = pm.model\n",
    "tokenizer = pm.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea1399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8192])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectors = torch.load(f\"{VECTOR_DIR}/multi_contrast_vectors.pt\", weights_only=False)\n",
    "vector = vectors[LAYER]['vector']\n",
    "print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73edbd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.195386976087784\n"
     ]
    }
   ],
   "source": [
    "norm_obj = json.load(open(f\"/workspace/{MODEL_SHORT}/dataset_activations/lmsys_10000/activation_stats.json\"))\n",
    "norm = norm_obj['per_layer_stats'][str(LAYER)]['token_level_norms']['mean']\n",
    "print(norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732426f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i have vector and average norm\n",
    "# as a steering coeff, i want n such that ||vector * n|| = avg_norm * avg_norm_coeff\n",
    "\n",
    "def get_steering_coeff(vector, avg_norm, avg_norm_coeff):\n",
    "    vector_norm = torch.norm(vector)\n",
    "    if vector_norm == 0:\n",
    "        raise ValueError(\"Vector has zero norm.\")\n",
    "    return float((avg_norm * avg_norm_coeff) / vector_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3960c979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target layer device: cuda:1\n",
      "Vector device before: cpu\n",
      "Vector device after: cuda:1\n",
      "torch.Size([8192])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Move vector to the same device as the model's target layer\n",
    "target_layer = model.model.layers[LAYER]\n",
    "layer_device = next(target_layer.parameters()).device\n",
    "print(f\"Target layer device: {layer_device}\")\n",
    "print(f\"Vector device before: {vector.device}\")\n",
    "\n",
    "# Move vector to the same device as the target layer\n",
    "vector = vector.to(layer_device)\n",
    "print(f\"Vector device after: {vector.device}\")\n",
    "print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea72c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling avg norm by 0: 0.0\n",
      "scaling avg norm by 0.25: 1.34375\n",
      "scaling avg norm by 0.5: 2.6875\n",
      "scaling avg norm by 0.75: 4.03125\n",
      "scaling avg norm by 1: 5.375\n",
      "scaling avg norm by 1.25: 6.71875\n",
      "scaling avg norm by 1.5: 8.0625\n",
      "scaling avg norm by 1.75: 9.4375\n",
      "scaling avg norm by 2: 10.75\n"
     ]
    }
   ],
   "source": [
    "for i in [0, .25, .5, .75, 1, 1.25, 1.5, 1.75, 2]:\n",
    "    print(f\"scaling avg norm by {i}: {get_steering_coeff(vector, norm, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we're using the corrected vector from the previous cell\n",
    "# (The vector should now be on the correct device)\n",
    "\n",
    "coeffs = [get_steering_coeff(vector, norm, -2)]\n",
    "prompts = [\"Who are you?\"]\n",
    "\n",
    "for c in coeffs:\n",
    "    print(f\"\\n{'='*20} Magnitude: {c:+.1f} {'='*20}\")\n",
    "    \n",
    "    try:\n",
    "        with ActivationSteering(\n",
    "            model=model,\n",
    "            steering_vectors=vector,\n",
    "            coefficients=c,\n",
    "            layer_indices=LAYER,\n",
    "            intervention_type=\"addition\",\n",
    "            positions=\"all\"\n",
    "        ) as steerer:\n",
    "            for prompt in prompts:\n",
    "                \n",
    "                \n",
    "                print(f\"\\nPrompt: {prompt}\")\n",
    "                response = pm.generate(prompt, chat_format=True, enable_thinking=False)\n",
    "\n",
    "                print(f\"Response: {response}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error with magnitude {c}: {str(e)}\"\n",
    "        print(f\"ERROR: {error_msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b17f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
