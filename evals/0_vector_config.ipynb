{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daca5acc",
   "metadata": {},
   "source": [
    "# Vectors for additive steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc79e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.pca_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "580f46ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: llama-3.3-70b\n",
      "Total layers: 80\n",
      "Vectors file: /workspace/llama-3.3-70b/evals/configs/multi_pc1_vectors.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"llama-3.3-70b\"\n",
    "total_layers = 80\n",
    "base_dir = f\"/workspace/{model_name}\"\n",
    "target_layer = 40\n",
    "\n",
    "vectors_file = f\"{base_dir}/evals/configs/multi_pc1_vectors.pt\"\n",
    "output_dir = f\"{base_dir}/evals/configs\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Total layers: {total_layers}\")\n",
    "print(f\"Vectors file: {vectors_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6343aa",
   "metadata": {},
   "source": [
    "## Make vectors from PC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ddaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_vectors = torch.load(f\"/workspace/{model_name}/capped/configs/multi_contrast_vectors.pt\", weights_only=False)\n",
    "\n",
    "pc1_vectors = []\n",
    "\n",
    "for i in range(total_layers):\n",
    "    layer_results = torch.load(f\"{base_dir}/roles_240/pca/layer{i}_mean_pos23.pt\", weights_only=False)\n",
    "    pc1 = layer_results['pca'].components_[0]\n",
    "\n",
    "    contrast_vector = contrast_vectors[i]['vector']\n",
    "\n",
    "    if torch.nn.functional.cosine_similarity(torch.from_numpy(pc1).reshape(1, -1), contrast_vector.reshape(1, -1)) < 0:\n",
    "        pc1 = -pc1\n",
    "\n",
    "    pc1_vectors.append(pc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for l in range(total_layers):\n",
    "    vectors.append({\n",
    "        'scaler': None,\n",
    "        'name': f\"layer_{l}/role_pc1_mean_pos23\",\n",
    "        'vector': torch.from_numpy(pc1_vectors[l]),\n",
    "        'layer': l\n",
    "    })\n",
    "torch.save(vectors, vectors_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424f9a9",
   "metadata": {},
   "source": [
    "## Make config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "195bfd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i have vector and average norm\n",
    "# as a steering coeff, i want n such that ||vector * n|| = avg_norm * avg_norm_coeff\n",
    "other_coeffs_rp = [-0.5, -0.25, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]\n",
    "gemma_coeffs_rp = [-0.05, -0.025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2]\n",
    "other_coeffs_asst = [0.5, 0.25, -0.25, -0.5, -0.75, -1, -1.25, -1.5, -1.75, -2]\n",
    "gemma_coeffs_asst = [0.05, 0.025, -0.025, -0.05, -0.075, -0.1, -0.125, -0.15, -0.175, -0.2]\n",
    "\n",
    "def get_steering_coeff(vector, avg_norm, avg_norm_coeff):\n",
    "    vector_norm = torch.norm(vector)\n",
    "    if vector_norm == 0:\n",
    "        raise ValueError(\"Vector has zero norm.\")\n",
    "    return float((avg_norm * avg_norm_coeff) / vector_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e72f0375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.195386976087784\n"
     ]
    }
   ],
   "source": [
    "norm_obj = json.load(open(f\"/workspace/{model_name}/dataset_activations/lmsys_10000/activation_stats.json\"))\n",
    "norm = norm_obj['per_layer_stats'][str(target_layer)]['token_level_norms']['mean']\n",
    "print(norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e28bf5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.097693920135498, -2.048846960067749, 2.048846960067749, 4.097693920135498, 6.146541118621826, 8.195387840270996, 10.244235038757324, 12.293082237243652, 14.34192943572998, 16.390775680541992]\n",
      "[4.097693920135498, 2.048846960067749, -2.048846960067749, -4.097693920135498, -6.146541118621826, -8.195387840270996, -10.244235038757324, -12.293082237243652, -14.34192943572998, -16.390775680541992]\n"
     ]
    }
   ],
   "source": [
    "# make experiment config with target layer\n",
    "vectors = torch.load(vectors_file, weights_only=False)\n",
    "target_vector = vectors[target_layer]['vector']\n",
    "\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    rp = gemma_coeffs_rp\n",
    "    asst = gemma_coeffs_asst\n",
    "else:\n",
    "    rp = other_coeffs_rp\n",
    "    asst = other_coeffs_asst\n",
    "\n",
    "rp_coeffs = [get_steering_coeff(target_vector, norm, c) for c in rp]\n",
    "asst_coeffs = [get_steering_coeff(target_vector, norm, c) for c in asst]\n",
    "print(rp_coeffs)\n",
    "print(asst_coeffs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0ac0258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample RP experiments:\n",
      "\n",
      "layer_40-role_pc1-coeff:-0.5:\n",
      "  Vector: layer_40/role_pc1_mean_pos23\n",
      "  Coeff: -4.0977\n",
      "\n",
      "layer_40-role_pc1-coeff:0.25:\n",
      "  Vector: layer_40/role_pc1_mean_pos23\n",
      "  Coeff: 2.0488\n",
      "\n",
      "layer_40-role_pc1-coeff:0.75:\n",
      "  Vector: layer_40/role_pc1_mean_pos23\n",
      "  Coeff: 6.1465\n",
      "\n",
      "layer_40-role_pc1-coeff:1.25:\n",
      "  Vector: layer_40/role_pc1_mean_pos23\n",
      "  Coeff: 10.2442\n",
      "\n",
      "layer_40-role_pc1-coeff:1.75:\n",
      "  Vector: layer_40/role_pc1_mean_pos23\n",
      "  Coeff: 14.3419\n",
      "\n",
      "Sample Assistant experiments:\n",
      "\n",
      "layer_40-role_pc1-coeff:0.5:\n",
      "  Vector: 1\n",
      "  Coeff: 4.0977\n",
      "\n",
      "layer_40-role_pc1-coeff:-0.25:\n",
      "  Vector: 1\n",
      "  Coeff: -2.0488\n",
      "\n",
      "layer_40-role_pc1-coeff:-0.75:\n",
      "  Vector: 1\n",
      "  Coeff: -6.1465\n",
      "\n",
      "layer_40-role_pc1-coeff:-1.25:\n",
      "  Vector: 1\n",
      "  Coeff: -10.2442\n",
      "\n",
      "layer_40-role_pc1-coeff:-1.75:\n",
      "  Vector: 1\n",
      "  Coeff: -14.3419\n"
     ]
    }
   ],
   "source": [
    "rp_experiments = []\n",
    "asst_experiments = []\n",
    "\n",
    "for m, c in zip(rp, rp_coeffs):\n",
    "    exp_id = f\"layer_{target_layer}-role_pc1-coeff:{m}\"\n",
    "    interventions = [\n",
    "        {\n",
    "            'vector': f\"layer_{target_layer}/role_pc1_mean_pos23\",\n",
    "            'coeff': c\n",
    "        }\n",
    "    ]\n",
    "    rp_experiments.append({\n",
    "        'id': exp_id,\n",
    "        'interventions': interventions\n",
    "    })\n",
    "\n",
    "for m, c in zip(asst, asst_coeffs):\n",
    "    exp_id = f\"layer_{target_layer}-role_pc1-coeff:{m}\"\n",
    "    interventions = [\n",
    "        {\n",
    "            'vector': f\"layer_{target_layer}/role_pc1_mean_pos23\",\n",
    "            'coeff': c\n",
    "        }\n",
    "    ]\n",
    "    asst_experiments.append({\n",
    "        'id': exp_id,\n",
    "        'interventions': interventions\n",
    "    })\n",
    "\n",
    "print(\"\\nSample RP experiments:\")\n",
    "for i in range(0, len(rp_experiments), len(rp_experiments)//4):\n",
    "    exp = rp_experiments[i]\n",
    "    print(f\"\\n{exp['id']}:\")\n",
    "    print(f\"  Vector: {exp['interventions'][0]['vector']}\")\n",
    "    print(f\"  Coeff: {exp['interventions'][0]['coeff']:.4f}\")\n",
    "\n",
    "print(\"\\nSample Assistant experiments:\")\n",
    "for i in range(0, len(asst_experiments), len(asst_experiments)//4):\n",
    "    exp = asst_experiments[i]\n",
    "    print(f\"\\n{exp['id']}:\")\n",
    "    print(f\"  Vector: {len(exp['interventions'])}\")\n",
    "    print(f\"  Coeff: {exp['interventions'][0]['coeff']:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35132d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.6875, -1.34375, 1.34375, 2.6875, 4.03125, 5.375, 6.71875, 8.0625, 9.4375, 10.75]\n",
      "[2.6875, 1.34375, -1.34375, -2.6875, -4.03125, -5.375, -6.71875, -8.0625, -9.4375, -10.75]\n"
     ]
    }
   ],
   "source": [
    "contrast_vectors = torch.load(f\"/workspace/{model_name}/capped/configs/multi_contrast_vectors.pt\", weights_only=False)\n",
    "target_contrast_vector = contrast_vectors[target_layer]['vector']\n",
    "\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    rp = gemma_coeffs_rp\n",
    "    asst = gemma_coeffs_asst\n",
    "else:\n",
    "    rp = other_coeffs_rp\n",
    "    asst = other_coeffs_asst\n",
    "\n",
    "rp_coeffs = [get_steering_coeff(target_contrast_vector, norm, c) for c in rp]\n",
    "asst_coeffs = [get_steering_coeff(target_contrast_vector, norm, c) for c in asst]\n",
    "print(rp_coeffs)\n",
    "print(asst_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73ea9cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for m, c in zip(rp, rp_coeffs):\n",
    "    exp_id = f\"layer_{target_layer}-contrast-coeff:{m}\"\n",
    "    interventions = [\n",
    "        {\n",
    "            'vector': f\"layer_{target_layer}/contrast_role_pos3_default1\",\n",
    "            'coeff': c\n",
    "        }\n",
    "    ]\n",
    "    rp_experiments.append({\n",
    "        'id': exp_id,\n",
    "        'interventions': interventions\n",
    "    })\n",
    "\n",
    "for m, c in zip(asst, asst_coeffs):\n",
    "    exp_id = f\"layer_{target_layer}-conntrast-coeff:{m}\"\n",
    "    interventions = [\n",
    "        {\n",
    "            'vector': f\"layer_{target_layer}/contrast_role_pos3_default1\",\n",
    "            'coeff': c\n",
    "        }\n",
    "    ]\n",
    "    asst_experiments.append({\n",
    "        'id': exp_id,\n",
    "        'interventions': interventions\n",
    "    })\n",
    "\n",
    "print(len(rp_experiments))\n",
    "print(len(asst_experiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e301756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector name:  layer_40/role_pc1_mean_pos23\n",
      "vector: tensor([-0.0034,  0.0028,  0.0049,  0.0018,  0.0064]) with shape torch.Size([8192])\n",
      "layer:  40\n",
      "vector name:  layer_40/contrast_role_pos3_default1\n",
      "vector: tensor([-0.0134,  0.0023,  0.0042, -0.0109,  0.0081], dtype=torch.bfloat16) with shape torch.Size([8192])\n",
      "layer:  40\n"
     ]
    }
   ],
   "source": [
    "vectors_dict = {}\n",
    "vectors_dict[f'layer_{target_layer}/role_pc1_mean_pos23'] = {\n",
    "    'vector': target_vector,\n",
    "    'layer': target_layer,\n",
    "}\n",
    "vectors_dict[f'layer_{target_layer}/contrast_role_pos3_default1'] = {\n",
    "    'vector': target_contrast_vector,\n",
    "    'layer': target_layer,\n",
    "}\n",
    "\n",
    "for v in vectors_dict:\n",
    "    print(\"vector name: \", v)\n",
    "    print(f\"vector: {vectors_dict[v]['vector'][:5]} with shape {vectors_dict[v]['vector'].shape}\")\n",
    "    print(\"layer: \", vectors_dict[v]['layer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "431b4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_config_file = f\"{output_dir}/rp_pc1_contrast_config.pt\"\n",
    "\n",
    "rp_config = {\n",
    "    'vectors': vectors_dict,\n",
    "    'experiments': rp_experiments\n",
    "}\n",
    "\n",
    "torch.save(rp_config, rp_config_file)\n",
    "\n",
    "asst_config_file = f\"{output_dir}/asst_pc1_contrast_config.pt\"\n",
    "\n",
    "asst_config = {\n",
    "    'vectors': vectors_dict,\n",
    "    'experiments': asst_experiments\n",
    "}\n",
    "\n",
    "torch.save(asst_config, asst_config_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
