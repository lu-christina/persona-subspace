{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28531137",
   "metadata": {},
   "source": [
    "# Variance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f3bcdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:08.842015Z",
     "iopub.status.busy": "2025-08-06T00:18:08.841387Z",
     "iopub.status.idle": "2025-08-06T00:18:09.171163Z",
     "shell.execute_reply": "2025-08-06T00:18:09.170519Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.pca_utils import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julz1owfwk",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "o7pmyp071r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Change these parameters for different models/datasets\n",
    "model_name = \"llama-3.3-70b\"\n",
    "base_dir = f\"/workspace/{model_name}\"\n",
    "type = \"roles_240\"\n",
    "dir = f\"{base_dir}/{type}\"\n",
    "\n",
    "layer = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76552389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pca_results = torch.load(f\"{dir}/pca/layer{layer}_pos23.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bec2d8",
   "metadata": {},
   "source": [
    "## Variance across and within roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5319f",
   "metadata": {},
   "source": [
    "### raw activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16d954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([275, 8192])\n",
      "torch.Size([8192])\n"
     ]
    }
   ],
   "source": [
    "vectors = torch.stack(pca_results['vectors']['pos_3'])[:, layer, :].float()\n",
    "print(vectors.shape)\n",
    "\n",
    "# compute variance across roles (rows) along hidden_dims\n",
    "raw_across_var = torch.var(vectors, dim=0)\n",
    "print(raw_across_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197362bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 275 scores\n"
     ]
    }
   ],
   "source": [
    "# load in scores\n",
    "scores = {}\n",
    "for file in os.listdir(f\"{dir}/extract_scores\"):\n",
    "    if file.endswith('.json'):\n",
    "        scores[file.replace('.json', '')] = json.load(open(f\"{dir}/extract_scores/{file}\"))\n",
    "\n",
    "print(f\"Loaded {len(scores)} scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48c900d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspace/llama-3.3-70b/roles_240/response_activations'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load in raw activations\u001b[39;00m\n\u001b[32m      2\u001b[39m activations = {}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/response_activations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m file.endswith(\u001b[33m'\u001b[39m\u001b[33m.pt\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[32m      5\u001b[39m         \u001b[38;5;66;03m# dict we should iterate over (1200 each)\u001b[39;00m\n\u001b[32m      6\u001b[39m         role_activations = []\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspace/llama-3.3-70b/roles_240/response_activations'"
     ]
    }
   ],
   "source": [
    "# load in raw activations\n",
    "activations = {}\n",
    "for file in os.listdir(f\"{dir}/response_activations\"):\n",
    "    if file.endswith('.pt') and 'default' not in file:\n",
    "        # dict we should iterate over (1200 each)\n",
    "        role_activations = []\n",
    "        obj = torch.load(f\"{dir}/response_activations/{file}\")\n",
    "        for key in obj:\n",
    "            if scores[file.replace('.pt', '')][key] == 3:\n",
    "                role_activations.append(obj[key])\n",
    "        activations[file.replace('.pt', '')] = torch.stack(role_activations)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "# compute variance within roles\n",
    "raw_within_var = []\n",
    "for file in activations:\n",
    "    raw_within_var.append(torch.var(activations[file][:, layer, :], dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var)} roles, shape is {raw_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea71a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "avg_raw_within_var = torch.stack(raw_within_var).mean(dim=0)\n",
    "print(avg_raw_within_var.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf860e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of raw_across_var / avg_raw_within_var is 0.4312536120414734\n"
     ]
    }
   ],
   "source": [
    "# total variance ratio\n",
    "raw_ratio = raw_across_var.sum() / avg_raw_within_var.sum()\n",
    "print(f\"ratio of raw_across_var / avg_raw_within_var is {raw_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "raw_across_var_normalized = torch.var(F.normalize(vectors, p=2, dim=1), dim=0)\n",
    "print(raw_across_var_normalized.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63901cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is torch.Size([4608])\n",
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "raw_within_var_normalized = []\n",
    "for file in activations:\n",
    "    raw_within_var_normalized.append(torch.var(F.normalize(activations[file][:, layer, :], p=2, dim=1), dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var_normalized)} roles, shape is {raw_within_var_normalized[0].shape}\")\n",
    "avg_raw_within_var_normalized = torch.stack(raw_within_var_normalized).mean(dim=0)\n",
    "print(avg_raw_within_var_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of raw_across_var_normalized / avg_raw_within_var_normalized is 0.3623166084289551\n"
     ]
    }
   ],
   "source": [
    "raw_ratio_normalized = raw_across_var_normalized.mean() / avg_raw_within_var_normalized.mean()\n",
    "print(f\"ratio of raw_across_var_normalized / avg_raw_within_var_normalized is {raw_ratio_normalized}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f2faa",
   "metadata": {},
   "source": [
    "### in PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0642d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(377,)\n"
     ]
    }
   ],
   "source": [
    "# get transformed role vectors\n",
    "pca_across_var = np.var(pca_results['pca_transformed'][:275], axis=0)\n",
    "print(pca_across_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec04e3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'activations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mactivations\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mabsurdist\u001b[39m\u001b[33m'\u001b[39m].shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'activations' is not defined"
     ]
    }
   ],
   "source": [
    "print(activations['absurdist'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e550e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is (448,)\n"
     ]
    }
   ],
   "source": [
    "pca_within_var = []\n",
    "pc1_within_var = []\n",
    "for role in activations:\n",
    "    role_scaled = pca_results['scaler'].transform(activations[role][:, layer, :].float().numpy())\n",
    "    role_pca = pca_results['pca'].transform(role_scaled)\n",
    "    pca_within_var.append(np.var(role_pca, axis=0))\n",
    "    pc1_within_var.append(np.var(role_pca[:, 0]))\n",
    "\n",
    "print(f\"for {len(pca_within_var)} roles, shape is {pca_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4565fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448,)\n"
     ]
    }
   ],
   "source": [
    "mean_pca_within_var = np.array(pca_within_var).mean(axis=0)\n",
    "print(mean_pca_within_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6776cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of pca_across_var / mean_pca_within_var is 0.31411965474791115\n"
     ]
    }
   ],
   "source": [
    "pca_ratio = pca_across_var.mean() / mean_pca_within_var.mean()\n",
    "print(f\"ratio of pca_across_var / mean_pca_within_var is {pca_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffd5cc",
   "metadata": {},
   "source": [
    "### pc1 variance only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c857e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829.9696483722173\n"
     ]
    }
   ],
   "source": [
    "pc1_across_var = np.var(pca_results['pca_transformed'][:275, 0])\n",
    "print(pc1_across_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291.39803214992793\n",
      "ratio of pc1_across_var / mean_pc1_within_var is 2.848233539014387\n"
     ]
    }
   ],
   "source": [
    "mean_pc1_within_var = np.array(pc1_within_var).mean()\n",
    "print(mean_pc1_within_var)\n",
    "\n",
    "pc1_ratio = pc1_across_var / mean_pc1_within_var\n",
    "print(f\"ratio of pc1_across_var / mean_pc1_within_var is {pc1_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4pcuy4pbb",
   "metadata": {},
   "source": [
    "### All PCs variance ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hq8lbky0oc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ratios for 448 PCs\n",
      "PC1 ratio: 2.8482\n",
      "Mean ratio (all PCs): 0.0982\n",
      "Mean ratio (PC2-10): 1.0490\n",
      "Max ratio: 2.8482 (PC1)\n"
     ]
    }
   ],
   "source": [
    "# Compute ratio for all PCs using existing variables\n",
    "all_pc_ratios = pca_across_var / mean_pca_within_var\n",
    "print(f\"Computed ratios for {len(all_pc_ratios)} PCs\")\n",
    "print(f\"PC1 ratio: {all_pc_ratios[0]:.4f}\")\n",
    "print(f\"Mean ratio (all PCs): {all_pc_ratios.mean():.4f}\")\n",
    "print(f\"Mean ratio (PC2-10): {all_pc_ratios[1:10].mean():.4f}\")\n",
    "print(f\"Max ratio: {all_pc_ratios.max():.4f} (PC{all_pc_ratios.argmax()+1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hmedn82ye69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "steelblue",
          "width": 2
         },
         "mode": "lines",
         "name": "PC Ratio",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448
         ],
         "y": [
          2.848233539014387,
          2.2431847634939315,
          1.0703693707156132,
          1.6713619489026115,
          1.027719944598097,
          0.8890005577340249,
          0.9533933895754964,
          0.5643444440172717,
          0.4633470055038173,
          0.5579121061987458,
          0.6258540623031191,
          0.5501331238302662,
          0.40216751309388277,
          0.39631492350716696,
          0.4067970503004888,
          0.38362436887075063,
          0.30760903805173806,
          0.49506480107697776,
          0.2965956540385605,
          0.44214379886651517,
          0.40429015304891547,
          0.3936250614552103,
          0.28885655244201053,
          0.17813824301478873,
          0.3359396929323714,
          0.3685646314925454,
          0.3960632886463978,
          0.2696573562423046,
          0.19803013243705514,
          0.334416740649936,
          0.3031785540579074,
          0.31939453066029666,
          0.22708605363791007,
          0.2546685680609097,
          0.240860066777961,
          0.35176725413318793,
          0.19903028312118168,
          0.24317859077842469,
          0.28359653466600654,
          0.18804347523481846,
          0.18598284210060292,
          0.18241591240344898,
          0.22537594876766762,
          0.2149642224802593,
          0.22866177345322997,
          0.1789213387621318,
          0.19208308395969373,
          0.15231070821559062,
          0.15320229777360594,
          0.20125351209959144,
          0.18576656462403532,
          0.21883819177785513,
          0.17663456361588792,
          0.19897713981462656,
          0.14756546951182897,
          0.15697528037384856,
          0.18647749573181643,
          0.15430015092181068,
          0.1591433682147524,
          0.2275315637281031,
          0.1533759729876638,
          0.148719155575166,
          0.13820925981838517,
          0.18969419045728655,
          0.157633368748121,
          0.14527962678830542,
          0.17580220357462514,
          0.13185155507679797,
          0.11008185244522985,
          0.18986410587809088,
          0.12608263074847403,
          0.15220591718439783,
          0.15871063812886962,
          0.10035434888872985,
          0.10590815098512855,
          0.1499327419638153,
          0.12013422761060041,
          0.14805379863120396,
          0.12025364843667057,
          0.11646197764762255,
          0.17522811915177489,
          0.15203122454063922,
          0.14734151575697702,
          0.1316046809437085,
          0.1223155200618714,
          0.1217198237523415,
          0.07812626736536092,
          0.11542759517685368,
          0.1149565299818255,
          0.1470878285050556,
          0.12520774258626757,
          0.1296023619573768,
          0.11046268746610499,
          0.11647758117528344,
          0.08940151414505766,
          0.1526637237597139,
          0.1469807850186587,
          0.09327269608972981,
          0.12877410459952382,
          0.08626222790923518,
          0.10859260494463956,
          0.08214904589399731,
          0.10494938734060001,
          0.11900051448286983,
          0.09660739225029709,
          0.09479926660432905,
          0.06988017245479762,
          0.12278212820085965,
          0.08046650349594664,
          0.07829156900646647,
          0.09709982239339443,
          0.08607648163512449,
          0.1078290551954776,
          0.08738651882442498,
          0.08992399546740105,
          0.09364483708049544,
          0.10422428604373757,
          0.08973584514880448,
          0.08763839419570162,
          0.1067200633302259,
          0.08583978132605523,
          0.06626292445102852,
          0.07052456533221417,
          0.08165207782140191,
          0.09225783134198834,
          0.08145488684505048,
          0.08819713519433292,
          0.09901225908159159,
          0.0907632357833114,
          0.09774238264362443,
          0.07332662999062246,
          0.0903491768524059,
          0.08865652908159435,
          0.0735456129427371,
          0.07445059610629895,
          0.08249543292106148,
          0.09162908921036615,
          0.10164226179171884,
          0.07358572696509837,
          0.10280320347083177,
          0.07877989013275906,
          0.07031753975658914,
          0.07422485346058334,
          0.07482939509249516,
          0.05703706994010153,
          0.07192736158517843,
          0.08146462770499316,
          0.0770035516556669,
          0.06441048421656934,
          0.07074497790466619,
          0.07600527185280552,
          0.0560105696585586,
          0.07204434040308583,
          0.0662237007044141,
          0.05089102993538675,
          0.06881138206714896,
          0.06621849019066897,
          0.07048083937603643,
          0.06633214666093433,
          0.06921959636798751,
          0.04188357473166993,
          0.06971501266648067,
          0.06271432055597126,
          0.06533769333672666,
          0.05381300207610314,
          0.06565749952372055,
          0.06627318162982085,
          0.06974018017324579,
          0.05966515586364681,
          0.06698160051106565,
          0.05874702077022106,
          0.07404455320532442,
          0.05658996166419954,
          0.05276130344287067,
          0.06839129037331994,
          0.04980541551136256,
          0.04222534724934121,
          0.0627772248968261,
          0.06668150388520466,
          0.05374206617106602,
          0.057329535709664835,
          0.05918771370382242,
          0.05778458765544417,
          0.05401109126108554,
          0.06271807287076281,
          0.0660454479229523,
          0.052152290740393584,
          0.05429483504238266,
          0.05652584429807774,
          0.056291102614697434,
          0.053471262601339456,
          0.04771871204659784,
          0.06022682078448889,
          0.05222254598782755,
          0.059868750174120744,
          0.04520807677474854,
          0.046948087561022006,
          0.06318491292471286,
          0.049603419429983794,
          0.03936510129236994,
          0.04737861619247885,
          0.044527022357316946,
          0.050778417489783,
          0.04755920662470184,
          0.04895214403663333,
          0.042850965847264826,
          0.05717146406144152,
          0.03735744168215356,
          0.04656805318383502,
          0.04258168798826951,
          0.05935046160047422,
          0.03632241396426363,
          0.046389495870309244,
          0.047239023928341,
          0.043003052250301876,
          0.03984137047139266,
          0.04005145722468597,
          0.03702754785136656,
          0.04958770430950634,
          0.047434821790310534,
          0.043204872662389024,
          0.03564728344182669,
          0.0340299341584865,
          0.03800475492782859,
          0.03996118153292492,
          0.03948829712626524,
          0.04149244790682887,
          0.03735707969165382,
          0.04711866951308767,
          0.0396059551350838,
          0.03530801317849681,
          0.04316637539412617,
          0.030668616380060885,
          0.038514094353243,
          0.03988632962864097,
          0.03527691580879668,
          0.03859308659607736,
          0.03819956791829414,
          0.03541657704339387,
          0.03655582925274202,
          0.029326229191294368,
          0.0452374105572951,
          0.03496786920275747,
          0.03725355268625442,
          0.04181649832013644,
          0.02988869615575514,
          0.03443679885760065,
          0.03823551329358344,
          0.029154843757511834,
          0.03189233523982762,
          0.03674721734332948,
          0.036499459648927535,
          0.03093073562218224,
          0.03171557582615389,
          0.03593037055563135,
          0.03134205735439849,
          0.03162144439363701,
          0.034479585438416734,
          0.03262869170345604,
          0.03667280427786438,
          0.03216533471611478,
          0.03226204601428582,
          0.02915725734302859,
          0.03111915026533631,
          0.03228048572446887,
          0.03178028534539434,
          0.03305613370372924,
          0.026627439147906096,
          0.027481772512262536,
          0.028677356953437518,
          0.02861798845028996,
          0.028892137424064997,
          0.027304459599302954,
          0.023988478783771198,
          0.030889658000619786,
          0.032207352796382135,
          0.03133581874407829,
          0.026780475498245967,
          0.030161472938786592,
          0.026415086304560832,
          0.029244085198640857,
          0.030269071028112344,
          0.026858549710972606,
          0.031693512895092965,
          0.024349089234246998,
          0.022861542058155517,
          0.023520542152770194,
          0.02330926848401271,
          0.026596792410438774,
          0.025692892055860277,
          0.021366516039378686,
          0.02447645793742675,
          0.026556726335320698,
          0.02543848717137384,
          0.02924124413553233,
          0.021426443720757558,
          0.027770869913321485,
          0.02657475730128807,
          0.019183063627251664,
          0.023072250451859226,
          0.024620466030553134,
          0.024461500481837945,
          0.018254526612436605,
          0.01937114180838664,
          0.019488136475564532,
          0.02213804857415267,
          0.025107820580743973,
          0.02176202549378002,
          0.022114643781516723,
          0.022786256220657514,
          0.02145360834100007,
          0.02282226233138825,
          0.019358827538386032,
          0.018852238225013696,
          0.019153363391410976,
          0.016718123752879534,
          0.022943776373896732,
          0.02067535386937773,
          0.019494470116201573,
          0.020717302729868367,
          0.01964930379220904,
          0.017895163975876302,
          0.018415421723984887,
          0.015942556041272617,
          0.019626666099906084,
          0.016280011464051093,
          0.01628863872454417,
          0.014461233191127956,
          0.016458225584366555,
          0.015931441087502766,
          0.016941522559955607,
          0.015362264925300238,
          0.01769153315060892,
          0.015529883189035663,
          0.01789600944623315,
          0.01565234605948966,
          0.019500709885552643,
          0.014564107712657799,
          0.01783965392958855,
          0.01336927135026295,
          0.013769770077701582,
          0.018171963301049563,
          0.01224298270582882,
          0.017508495566246424,
          0.014329007601531316,
          0.014168801851184942,
          0.014378489803503293,
          0.015049265210133727,
          0.014303811847534818,
          0.013895882100909798,
          0.015214898743367171,
          0.01313253021879699,
          0.01556835492151153,
          0.014185805584844939,
          0.011379850037960665,
          0.011452928713147088,
          0.012637388069360685,
          0.014335349829431375,
          0.012951795743132384,
          0.013129324558838935,
          0.013117078440364138,
          0.013884115646777582,
          0.0135401051121093,
          0.010382174383718308,
          0.01287440604932223,
          0.010522871112548848,
          0.011580955900540837,
          0.012466553855769173,
          0.013877464486150827,
          0.01433675144494457,
          0.010714120507056174,
          0.012031109663507568,
          0.01273086659887431,
          0.011657200809270763,
          0.012610139937733586,
          0.011378995178252685,
          0.012335209172102329,
          0.011251215484232554,
          0.011847769322299207,
          0.010784179288966132,
          0.010892771704318693,
          0.013019625646540531,
          0.012282732340602487,
          0.011587785189779943,
          0.010649822749709456,
          0.011351064869471263,
          0.010673692318063002,
          0.009389425420729855,
          0.008875285099914204,
          0.011577142849643585,
          0.011968326784094516,
          0.009161513526430206,
          0.010816762791057786,
          0.008428104841381272,
          0.010591376805422147,
          0.007761701181997763,
          0.009947989950071933,
          0.00995078215001248,
          0.008651059666719006,
          0.008039515644890055,
          0.007738069681659213,
          0.008051973037082988,
          0.010283938948643639,
          0.009373485962154319,
          0.008858700071600074,
          0.00846444749195627,
          0.007378220847632266,
          0.008086584341622297,
          0.008054137397979565,
          0.00845897083178448,
          0.00942075842015024,
          0.007753274275439384,
          0.007744205454943233,
          0.0087035159072468,
          0.007258457721080494,
          0.006887852121016568,
          0.0086691923080088,
          0.007471874191984259,
          0.008420042462040332,
          0.0067868935900275585,
          0.008436496944592628,
          0.008187719417363692,
          0.007366601656000453,
          0.006351578723017363,
          0.0059011371658664186,
          0.0074096489993426785,
          0.005639646665439338,
          0.0070759988563704425,
          0.0056966858458913005,
          0.006483088154352748,
          0.007293038609666202,
          0.005486732664466751,
          0.007238291707297893,
          0.004870370793200274,
          0.005445851227663998,
          0.006396846995343032,
          0.004606114255154532,
          0.004357686676459967,
          0.005903929072558744,
          0.005097904791298591,
          0.005188762201616692,
          0.004224169121963706,
          0.0033516846402880693,
          0.004213723403517673,
          0.004907838595813279,
          0.00407540255614072,
          0.00401865022858434,
          8.356531991416754e-57
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "ratio=1",
          "x": 1,
          "xanchor": "left",
          "xref": "x domain",
          "y": 1,
          "yanchor": "middle",
          "yref": "y"
         }
        ],
        "height": 500,
        "hovermode": "x unified",
        "shapes": [
         {
          "line": {
           "color": "gray",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 1,
          "y1": 1,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "subtitle": {
          "text": "Gemma 2 27B, Layer 22"
         },
         "text": "Variance Ratio (Across-Role / Within-Role) for Role PCs"
        },
        "width": 800,
        "xaxis": {
         "range": [
          0.5,
          10.5
         ],
         "tickvals": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "title": {
          "text": "Principal Component"
         }
        },
        "yaxis": {
         "title": {
          "text": "Variance Ratio"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"04b13ecb-4b7a-49d9-a3af-d800c4accd92\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"04b13ecb-4b7a-49d9-a3af-d800c4accd92\")) {                    Plotly.newPlot(                        \"04b13ecb-4b7a-49d9-a3af-d800c4accd92\",                        [{\"line\":{\"color\":\"steelblue\",\"width\":2},\"mode\":\"lines\",\"name\":\"PC Ratio\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448],\"y\":[2.848233539014387,2.2431847634939315,1.0703693707156132,1.6713619489026115,1.027719944598097,0.8890005577340249,0.9533933895754964,0.5643444440172717,0.4633470055038173,0.5579121061987458,0.6258540623031191,0.5501331238302662,0.40216751309388277,0.39631492350716696,0.4067970503004888,0.38362436887075063,0.30760903805173806,0.49506480107697776,0.2965956540385605,0.44214379886651517,0.40429015304891547,0.3936250614552103,0.28885655244201053,0.17813824301478873,0.3359396929323714,0.3685646314925454,0.3960632886463978,0.2696573562423046,0.19803013243705514,0.334416740649936,0.3031785540579074,0.31939453066029666,0.22708605363791007,0.2546685680609097,0.240860066777961,0.35176725413318793,0.19903028312118168,0.24317859077842469,0.28359653466600654,0.18804347523481846,0.18598284210060292,0.18241591240344898,0.22537594876766762,0.2149642224802593,0.22866177345322997,0.1789213387621318,0.19208308395969373,0.15231070821559062,0.15320229777360594,0.20125351209959144,0.18576656462403532,0.21883819177785513,0.17663456361588792,0.19897713981462656,0.14756546951182897,0.15697528037384856,0.18647749573181643,0.15430015092181068,0.1591433682147524,0.2275315637281031,0.1533759729876638,0.148719155575166,0.13820925981838517,0.18969419045728655,0.157633368748121,0.14527962678830542,0.17580220357462514,0.13185155507679797,0.11008185244522985,0.18986410587809088,0.12608263074847403,0.15220591718439783,0.15871063812886962,0.10035434888872985,0.10590815098512855,0.1499327419638153,0.12013422761060041,0.14805379863120396,0.12025364843667057,0.11646197764762255,0.17522811915177489,0.15203122454063922,0.14734151575697702,0.1316046809437085,0.1223155200618714,0.1217198237523415,0.07812626736536092,0.11542759517685368,0.1149565299818255,0.1470878285050556,0.12520774258626757,0.1296023619573768,0.11046268746610499,0.11647758117528344,0.08940151414505766,0.1526637237597139,0.1469807850186587,0.09327269608972981,0.12877410459952382,0.08626222790923518,0.10859260494463956,0.08214904589399731,0.10494938734060001,0.11900051448286983,0.09660739225029709,0.09479926660432905,0.06988017245479762,0.12278212820085965,0.08046650349594664,0.07829156900646647,0.09709982239339443,0.08607648163512449,0.1078290551954776,0.08738651882442498,0.08992399546740105,0.09364483708049544,0.10422428604373757,0.08973584514880448,0.08763839419570162,0.1067200633302259,0.08583978132605523,0.06626292445102852,0.07052456533221417,0.08165207782140191,0.09225783134198834,0.08145488684505048,0.08819713519433292,0.09901225908159159,0.0907632357833114,0.09774238264362443,0.07332662999062246,0.0903491768524059,0.08865652908159435,0.0735456129427371,0.07445059610629895,0.08249543292106148,0.09162908921036615,0.10164226179171884,0.07358572696509837,0.10280320347083177,0.07877989013275906,0.07031753975658914,0.07422485346058334,0.07482939509249516,0.05703706994010153,0.07192736158517843,0.08146462770499316,0.0770035516556669,0.06441048421656934,0.07074497790466619,0.07600527185280552,0.0560105696585586,0.07204434040308583,0.0662237007044141,0.05089102993538675,0.06881138206714896,0.06621849019066897,0.07048083937603643,0.06633214666093433,0.06921959636798751,0.04188357473166993,0.06971501266648067,0.06271432055597126,0.06533769333672666,0.05381300207610314,0.06565749952372055,0.06627318162982085,0.06974018017324579,0.05966515586364681,0.06698160051106565,0.05874702077022106,0.07404455320532442,0.05658996166419954,0.05276130344287067,0.06839129037331994,0.04980541551136256,0.04222534724934121,0.0627772248968261,0.06668150388520466,0.05374206617106602,0.057329535709664835,0.05918771370382242,0.05778458765544417,0.05401109126108554,0.06271807287076281,0.0660454479229523,0.052152290740393584,0.05429483504238266,0.05652584429807774,0.056291102614697434,0.053471262601339456,0.04771871204659784,0.06022682078448889,0.05222254598782755,0.059868750174120744,0.04520807677474854,0.046948087561022006,0.06318491292471286,0.049603419429983794,0.03936510129236994,0.04737861619247885,0.044527022357316946,0.050778417489783,0.04755920662470184,0.04895214403663333,0.042850965847264826,0.05717146406144152,0.03735744168215356,0.04656805318383502,0.04258168798826951,0.05935046160047422,0.03632241396426363,0.046389495870309244,0.047239023928341,0.043003052250301876,0.03984137047139266,0.04005145722468597,0.03702754785136656,0.04958770430950634,0.047434821790310534,0.043204872662389024,0.03564728344182669,0.0340299341584865,0.03800475492782859,0.03996118153292492,0.03948829712626524,0.04149244790682887,0.03735707969165382,0.04711866951308767,0.0396059551350838,0.03530801317849681,0.04316637539412617,0.030668616380060885,0.038514094353243,0.03988632962864097,0.03527691580879668,0.03859308659607736,0.03819956791829414,0.03541657704339387,0.03655582925274202,0.029326229191294368,0.0452374105572951,0.03496786920275747,0.03725355268625442,0.04181649832013644,0.02988869615575514,0.03443679885760065,0.03823551329358344,0.029154843757511834,0.03189233523982762,0.03674721734332948,0.036499459648927535,0.03093073562218224,0.03171557582615389,0.03593037055563135,0.03134205735439849,0.03162144439363701,0.034479585438416734,0.03262869170345604,0.03667280427786438,0.03216533471611478,0.03226204601428582,0.02915725734302859,0.03111915026533631,0.03228048572446887,0.03178028534539434,0.03305613370372924,0.026627439147906096,0.027481772512262536,0.028677356953437518,0.02861798845028996,0.028892137424064997,0.027304459599302954,0.023988478783771198,0.030889658000619786,0.032207352796382135,0.03133581874407829,0.026780475498245967,0.030161472938786592,0.026415086304560832,0.029244085198640857,0.030269071028112344,0.026858549710972606,0.031693512895092965,0.024349089234246998,0.022861542058155517,0.023520542152770194,0.02330926848401271,0.026596792410438774,0.025692892055860277,0.021366516039378686,0.02447645793742675,0.026556726335320698,0.02543848717137384,0.02924124413553233,0.021426443720757558,0.027770869913321485,0.02657475730128807,0.019183063627251664,0.023072250451859226,0.024620466030553134,0.024461500481837945,0.018254526612436605,0.01937114180838664,0.019488136475564532,0.02213804857415267,0.025107820580743973,0.02176202549378002,0.022114643781516723,0.022786256220657514,0.02145360834100007,0.02282226233138825,0.019358827538386032,0.018852238225013696,0.019153363391410976,0.016718123752879534,0.022943776373896732,0.02067535386937773,0.019494470116201573,0.020717302729868367,0.01964930379220904,0.017895163975876302,0.018415421723984887,0.015942556041272617,0.019626666099906084,0.016280011464051093,0.01628863872454417,0.014461233191127956,0.016458225584366555,0.015931441087502766,0.016941522559955607,0.015362264925300238,0.01769153315060892,0.015529883189035663,0.01789600944623315,0.01565234605948966,0.019500709885552643,0.014564107712657799,0.01783965392958855,0.01336927135026295,0.013769770077701582,0.018171963301049563,0.01224298270582882,0.017508495566246424,0.014329007601531316,0.014168801851184942,0.014378489803503293,0.015049265210133727,0.014303811847534818,0.013895882100909798,0.015214898743367171,0.01313253021879699,0.01556835492151153,0.014185805584844939,0.011379850037960665,0.011452928713147088,0.012637388069360685,0.014335349829431375,0.012951795743132384,0.013129324558838935,0.013117078440364138,0.013884115646777582,0.0135401051121093,0.010382174383718308,0.01287440604932223,0.010522871112548848,0.011580955900540837,0.012466553855769173,0.013877464486150827,0.01433675144494457,0.010714120507056174,0.012031109663507568,0.01273086659887431,0.011657200809270763,0.012610139937733586,0.011378995178252685,0.012335209172102329,0.011251215484232554,0.011847769322299207,0.010784179288966132,0.010892771704318693,0.013019625646540531,0.012282732340602487,0.011587785189779943,0.010649822749709456,0.011351064869471263,0.010673692318063002,0.009389425420729855,0.008875285099914204,0.011577142849643585,0.011968326784094516,0.009161513526430206,0.010816762791057786,0.008428104841381272,0.010591376805422147,0.007761701181997763,0.009947989950071933,0.00995078215001248,0.008651059666719006,0.008039515644890055,0.007738069681659213,0.008051973037082988,0.010283938948643639,0.009373485962154319,0.008858700071600074,0.00846444749195627,0.007378220847632266,0.008086584341622297,0.008054137397979565,0.00845897083178448,0.00942075842015024,0.007753274275439384,0.007744205454943233,0.0087035159072468,0.007258457721080494,0.006887852121016568,0.0086691923080088,0.007471874191984259,0.008420042462040332,0.0067868935900275585,0.008436496944592628,0.008187719417363692,0.007366601656000453,0.006351578723017363,0.0059011371658664186,0.0074096489993426785,0.005639646665439338,0.0070759988563704425,0.0056966858458913005,0.006483088154352748,0.007293038609666202,0.005486732664466751,0.007238291707297893,0.004870370793200274,0.005445851227663998,0.006396846995343032,0.004606114255154532,0.004357686676459967,0.005903929072558744,0.005097904791298591,0.005188762201616692,0.004224169121963706,0.0033516846402880693,0.004213723403517673,0.004907838595813279,0.00407540255614072,0.00401865022858434,8.356531991416754e-57],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"shapes\":[{\"line\":{\"color\":\"gray\",\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"xref\":\"x domain\",\"y0\":1.0,\"y1\":1.0,\"yref\":\"y\"}],\"annotations\":[{\"showarrow\":false,\"text\":\"ratio=1\",\"x\":1,\"xanchor\":\"left\",\"xref\":\"x domain\",\"y\":1.0,\"yanchor\":\"middle\",\"yref\":\"y\"}],\"title\":{\"subtitle\":{\"text\":\"Gemma 2 27B, Layer 22\"},\"text\":\"Variance Ratio (Across-Role \\u002f Within-Role) for Role PCs\"},\"xaxis\":{\"title\":{\"text\":\"Principal Component\"},\"range\":[0.5,10.5],\"tickvals\":[1,2,3,4,5,6,7,8,9,10]},\"yaxis\":{\"title\":{\"text\":\"Variance Ratio\"}},\"width\":800,\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('04b13ecb-4b7a-49d9-a3af-d800c4accd92');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create line plot of PC ratios\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line trace for all PC ratios\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(1, len(all_pc_ratios) + 1),\n",
    "    y=all_pc_ratios,\n",
    "    mode='lines',\n",
    "    name='PC Ratio',\n",
    "    line=dict(color='steelblue', width=2)\n",
    "))\n",
    "\n",
    "\n",
    "# Add horizontal reference line at ratio=1\n",
    "fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"gray\", \n",
    "              annotation_text=\"ratio=1\", annotation_position=\"right\")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Variance Ratio (Across-Role / Within-Role) for Role PCs\",\n",
    "        'subtitle': {\n",
    "            'text': f\"{model_name.replace('-', ' ').title()}, Layer {layer}\",\n",
    "        }\n",
    "    },\n",
    "    xaxis_title=\"Principal Component\",\n",
    "    yaxis_title=\"Variance Ratio\",\n",
    "    width=800,\n",
    "    height=500,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(range=[0.5, 10.5], tickvals=np.arange(1, 11))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(f\"/root/git/plots/{model_name}/roles/variance_ratios.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5eca2",
   "metadata": {},
   "source": [
    "## Conditional variance of role vectors based on distance from Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db03468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([448, 4608])\n"
     ]
    }
   ],
   "source": [
    "role_vectors = torch.stack(pca_results['vectors']['pos_2'] + pca_results['vectors']['pos_3'])[:, layer, :]\n",
    "print(role_vectors.shape)\n",
    "\n",
    "pc1 = pca_results['pca_transformed'][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dw7pl9twyv",
   "metadata": {},
   "source": [
    "### Conditional variance in raw activation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e6z46xkk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RAW ACTIVATION SPACE: Two-Group Comparison\n",
      "============================================================\n",
      "PC1 threshold: 25\n",
      "Assistant-like roles (PC1 < 25): 128 samples\n",
      "Roleplay roles (PC1 >= 25): 320 samples\n",
      "\n",
      "Mean variance (Assistant-like): 54.750000\n",
      "Mean variance (Roleplay): 151.000000\n",
      "Variance ratio (Assistant/Roleplay): 0.3626 (36.26%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Two-group comparison: Assistant-like vs Roleplay\n",
    "# Using PC1 threshold of -25 (same as in 9_cone.ipynb)\n",
    "\n",
    "\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    threshold = 25\n",
    "    assistant_mask = pc1 > threshold\n",
    "    roleplay_mask = pc1 <= threshold\n",
    "else:\n",
    "    threshold = -25\n",
    "    assistant_mask = pc1 < threshold\n",
    "    roleplay_mask = pc1 >= threshold\n",
    "\n",
    "# Compute variance of raw activations for each group\n",
    "# role_vectors shape: [448, 4608]\n",
    "var_assistant_raw = torch.var(role_vectors[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_raw = torch.var(role_vectors[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_raw = var_assistant_raw / var_roleplay_raw\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like roles (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like): {var_assistant_raw:.6f}\")\n",
    "print(f\"Mean variance (Roleplay): {var_roleplay_raw:.6f}\")\n",
    "print(f\"Variance ratio (Assistant/Roleplay): {var_ratio_raw:.4f} ({var_ratio_raw*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vm23njwgwk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE (PC1 projected out): Two-Group Comparison\n",
      "============================================================\n",
      "PC1 threshold: 25\n",
      "Assistant-like roles (PC1 < 25): 128 samples\n",
      "Roleplay roles (PC1 >= 25): 320 samples\n",
      "\n",
      "Mean variance (Assistant-like, PC1 removed): 54.452919\n",
      "Mean variance (Roleplay, PC1 removed): 138.992462\n",
      "Variance ratio (Assistant/Roleplay): 0.3918 (39.18%)\n",
      "\n",
      "This is analogous to the PC2-10 analysis in PC space.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Project out PC1 from raw activations\n",
    "# Get PC1 direction from PCA\n",
    "pc1_direction = torch.from_numpy(pca_results['pca'].components_[0]).float()\n",
    "\n",
    "# Project role_vectors onto PC1 and subtract\n",
    "# Formula: projection = (v · u) * u, where u is the unit vector (PC1 direction)\n",
    "pc1_loadings = (role_vectors.float() @ pc1_direction).unsqueeze(1)  # Shape: [448, 1]\n",
    "pc1_projections = pc1_loadings * pc1_direction.unsqueeze(0)  # Shape: [448, 4608]\n",
    "role_vectors_pc1_removed = role_vectors - pc1_projections\n",
    "\n",
    "# Compute variance with PC1 projected out\n",
    "var_assistant_raw_no_pc1 = torch.var(role_vectors_pc1_removed[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_raw_no_pc1 = torch.var(role_vectors_pc1_removed[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_raw_no_pc1 = var_assistant_raw_no_pc1 / var_roleplay_raw_no_pc1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE (PC1 projected out): Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like roles (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like, PC1 removed): {var_assistant_raw_no_pc1:.6f}\")\n",
    "print(f\"Mean variance (Roleplay, PC1 removed): {var_roleplay_raw_no_pc1:.6f}\")\n",
    "print(f\"Variance ratio (Assistant/Roleplay): {var_ratio_raw_no_pc1:.4f} ({var_ratio_raw_no_pc1*100:.2f}%)\")\n",
    "print(f\"\\nThis is analogous to the PC2-10 analysis in PC space.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zv1prpa1y3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE: Quintile Analysis\n",
      "============================================================\n",
      "\n",
      "Quintile 1: PC1 ∈ [-86.47, -33.36]\n",
      "  Sample size: 90\n",
      "  Mean variance (full): 136.000000\n",
      "  Mean variance (PC1 removed): 134.244888\n",
      "\n",
      "Quintile 2: PC1 ∈ [-33.36, -1.06]\n",
      "  Sample size: 89\n",
      "  Mean variance (full): 98.000000\n",
      "  Mean variance (PC1 removed): 96.719231\n",
      "\n",
      "Quintile 3: PC1 ∈ [-1.06, 18.72]\n",
      "  Sample size: 90\n",
      "  Mean variance (full): 69.000000\n",
      "  Mean variance (PC1 removed): 68.681099\n",
      "\n",
      "Quintile 4: PC1 ∈ [18.72, 28.17]\n",
      "  Sample size: 89\n",
      "  Mean variance (full): 53.750000\n",
      "  Mean variance (PC1 removed): 53.688721\n",
      "\n",
      "Quintile 5: PC1 ∈ [28.17, 38.88]\n",
      "  Sample size: 90\n",
      "  Mean variance (full): 53.250000\n",
      "  Mean variance (PC1 removed): 53.227360\n",
      "\n",
      "------------------------------------------------------------\n",
      "Variance ratio (Last/First quintile, full): 2.55x\n",
      "Variance ratio (Last/First quintile, PC1 removed): 2.52x\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Quintile analysis\n",
    "n_quintiles = 5\n",
    "quintile_edges = np.quantile(pc1, np.linspace(0, 1, n_quintiles + 1))\n",
    "quintile_variances = []\n",
    "quintile_variances_no_pc1 = []\n",
    "quintile_sizes = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Quintile Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(n_quintiles):\n",
    "    if i == 0:\n",
    "        mask = (pc1 >= quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    else:\n",
    "        mask = (pc1 > quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    \n",
    "    quintile_var = torch.var(role_vectors[mask], dim=0).mean().item()\n",
    "    quintile_var_no_pc1 = torch.var(role_vectors_pc1_removed[mask], dim=0).mean().item()\n",
    "    quintile_variances.append(quintile_var)\n",
    "    quintile_variances_no_pc1.append(quintile_var_no_pc1)\n",
    "    quintile_sizes.append(mask.sum())\n",
    "    \n",
    "    print(f\"\\nQuintile {i+1}: PC1 ∈ [{quintile_edges[i]:.2f}, {quintile_edges[i+1]:.2f}]\")\n",
    "    print(f\"  Sample size: {mask.sum()}\")\n",
    "    print(f\"  Mean variance (full): {quintile_var:.6f}\")\n",
    "    print(f\"  Mean variance (PC1 removed): {quintile_var_no_pc1:.6f}\")\n",
    "\n",
    "# Calculate ratios between first and last quintile\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    quintile_ratio = quintile_variances[0] / quintile_variances[-1]\n",
    "    quintile_ratio_no_pc1 = quintile_variances_no_pc1[0] / quintile_variances_no_pc1[-1]\n",
    "else:\n",
    "    quintile_ratio = quintile_variances[-1] / quintile_variances[0]\n",
    "    quintile_ratio_no_pc1 = quintile_variances_no_pc1[-1] / quintile_variances_no_pc1[0]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(f\"Variance ratio (Last/First quintile, full): {quintile_ratio:.2f}x\")\n",
    "print(f\"Variance ratio (Last/First quintile, PC1 removed): {quintile_ratio_no_pc1:.2f}x\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7kwaevse0w",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE: Distance from Center Correlation\n",
      "============================================================\n",
      "Correlation between PC1 and L2 distance from mean (full):\n",
      "  r = -0.5635\n",
      "  p-value = 6.652e-39\n",
      "  Highly significant (p < 0.001)\n",
      "\n",
      "Correlation between PC1 and L2 distance from mean (PC1 removed):\n",
      "  r = -0.5441\n",
      "  p-value = 7.002e-36\n",
      "  Highly significant (p < 0.001)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Distance from center correlation\n",
    "# Compute mean of raw activations\n",
    "role_vectors_mean = role_vectors.mean(dim=0)\n",
    "role_vectors_pc1_removed_mean = role_vectors_pc1_removed.mean(dim=0)\n",
    "\n",
    "# Compute L2 distance from mean for each role\n",
    "distances_raw = torch.norm(role_vectors.float() - role_vectors_mean, p=2, dim=1).numpy()\n",
    "distances_raw_no_pc1 = torch.norm(role_vectors_pc1_removed - role_vectors_pc1_removed_mean, p=2, dim=1).numpy()\n",
    "\n",
    "# Calculate correlation with PC1\n",
    "correlation_raw, p_value_raw = pearsonr(pc1, distances_raw)\n",
    "correlation_raw_no_pc1, p_value_raw_no_pc1 = pearsonr(pc1, distances_raw_no_pc1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Distance from Center Correlation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Correlation between PC1 and L2 distance from mean (full):\")\n",
    "print(f\"  r = {correlation_raw:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw:.3e}\")\n",
    "if p_value_raw < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "\n",
    "print(f\"\\nCorrelation between PC1 and L2 distance from mean (PC1 removed):\")\n",
    "print(f\"  r = {correlation_raw_no_pc1:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw_no_pc1:.3e}\")\n",
    "if p_value_raw_no_pc1 < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw_no_pc1 < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lsye2ajp11",
   "metadata": {},
   "source": [
    "### Per-PC analysis: Correlation between each PC and distance in remaining PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0tedpgpspjp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Correlation between each PC and distance in remaining PC space\n",
      "======================================================================\n",
      "PC 1: r = -0.6576, p = 7.913e-57 ***\n",
      "PC 2: r =  0.2100, p = 7.342e-06 ***\n",
      "PC 3: r =  0.3147, p = 9.348e-12 ***\n",
      "PC 4: r =  0.0543, p = 2.516e-01 \n",
      "PC 5: r = -0.2252, p = 1.468e-06 ***\n",
      "PC 6: r = -0.2385, p = 3.258e-07 ***\n",
      "PC 7: r =  0.0882, p = 6.229e-02 \n",
      "PC 8: r =  0.0283, p = 5.500e-01 \n",
      "PC 9: r = -0.0532, p = 2.616e-01 \n",
      "PC10: r =  0.0580, p = 2.208e-01 \n",
      "======================================================================\n",
      "\n",
      "PC1 correlation: -0.6576\n",
      "Mean correlation (PC2-10): 0.0263\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each of the top 10 PCs, calculate:\n",
    "# 1. The correlation between that PC and distance from center in all OTHER PCs\n",
    "# 2. This tells us if the pattern we see with PC1 generalizes to other PCs\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "n_pcs_to_analyze = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Correlation between each PC and distance in remaining PC space\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "correlations = []\n",
    "p_values = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_analyze):\n",
    "    # Get the PC values\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get all other PCs (excluding current PC)\n",
    "    other_pcs = np.delete(pca_transformed, pc_idx, axis=1)\n",
    "    \n",
    "    # Calculate distance from center in the remaining PC space\n",
    "    other_pcs_mean = other_pcs.mean(axis=0)\n",
    "    distances = np.linalg.norm(other_pcs - other_pcs_mean, axis=1)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr, p_val = pearsonr(pc_values, distances)\n",
    "    correlations.append(corr)\n",
    "    p_values.append(p_val)\n",
    "    \n",
    "    # Print results\n",
    "    sig_marker = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n",
    "    print(f\"PC{pc_idx+1:2d}: r = {corr:7.4f}, p = {p_val:.3e} {sig_marker}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPC1 correlation: {correlations[0]:.4f}\")\n",
    "print(f\"Mean correlation (PC2-10): {np.mean(correlations[1:]):.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4w4stk4a567",
   "metadata": {},
   "source": [
    "### Conditional variance in PC2-10 based on position along each PC\n",
    "\n",
    "This analysis shows whether the pattern of \"extreme positions → high variance in other PCs\" is unique to PC1 or generalizes to other PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x42qo16zp6k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Conditional Variance in PC2-10 based on position along each PC\n",
      "================================================================================\n",
      "For each PC, we split roles by median and compute variance in PC2-10 (excluding that PC)\n",
      "--------------------------------------------------------------------------------\n",
      "PC 1: High=224 samples, Low=224 samples\n",
      "      Var(high) =   99.655, Var(low) =  303.220, Ratio = 3.043\n",
      "PC 2: High=224 samples, Low=224 samples\n",
      "      Var(high) =  230.203, Var(low) =  130.662, Ratio = 1.762\n",
      "PC 3: High=224 samples, Low=224 samples\n",
      "      Var(high) =  211.142, Var(low) =  164.985, Ratio = 1.280\n",
      "PC 4: High=224 samples, Low=224 samples\n",
      "      Var(high) =  179.438, Var(low) =  214.903, Ratio = 1.198\n",
      "PC 5: High=224 samples, Low=224 samples\n",
      "      Var(high) =  157.295, Var(low) =  247.421, Ratio = 1.573\n",
      "PC 6: High=224 samples, Low=224 samples\n",
      "      Var(high) =  195.218, Var(low) =  209.086, Ratio = 1.071\n",
      "PC 7: High=224 samples, Low=224 samples\n",
      "      Var(high) =  234.147, Var(low) =  181.103, Ratio = 1.293\n",
      "PC 8: High=224 samples, Low=224 samples\n",
      "      Var(high) =  200.367, Var(low) =  223.138, Ratio = 1.114\n",
      "PC 9: High=224 samples, Low=224 samples\n",
      "      Var(high) =  238.866, Var(low) =  190.133, Ratio = 1.256\n",
      "PC10: High=224 samples, Low=224 samples\n",
      "      Var(high) =  209.329, Var(low) =  223.313, Ratio = 1.067\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "  PC1 variance ratio: 3.043\n",
      "  Mean variance ratio for PC2-10: 1.290\n",
      "  Max variance ratio (excluding PC1): 1.762 (PC2)\n",
      "\n",
      "  → Shows whether PC1 is unique in having high-variance 'other dimensions' for extreme positions\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each PC, split roles into two groups (high/low) and compute variance in PC2-10 (excluding that PC)\n",
    "# This tests if extreme positions on PC_i lead to high variance in other PCs\n",
    "\n",
    "n_pcs_to_test = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Conditional Variance in PC2-10 based on position along each PC\")\n",
    "print(\"=\" * 80)\n",
    "print(\"For each PC, we split roles by median and compute variance in PC2-10 (excluding that PC)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "variance_ratios = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_test):\n",
    "    # Split by median on this PC\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    median_val = np.median(pc_values)\n",
    "    high_mask = pc_values > median_val\n",
    "    low_mask = pc_values <= median_val\n",
    "    \n",
    "    # Get PC2-10, excluding current PC if it's in that range\n",
    "    if pc_idx == 0:\n",
    "        # For PC1, we want variance in PC2-10\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    elif 1 <= pc_idx < 10:\n",
    "        # For PC2-9, exclude that PC from PC2-10\n",
    "        pc_indices = [i for i in range(1, 10) if i != pc_idx]\n",
    "        other_pcs = pca_transformed[:, pc_indices]\n",
    "    else:\n",
    "        # For PC10, use PC2-9\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    \n",
    "    # Compute variance for each group\n",
    "    var_high = np.var(other_pcs[high_mask], axis=0).mean()\n",
    "    var_low = np.var(other_pcs[low_mask], axis=0).mean()\n",
    "    \n",
    "    ratio = max(var_high, var_low) / min(var_high, var_low)\n",
    "    variance_ratios.append(ratio)\n",
    "    \n",
    "    print(f\"PC{pc_idx+1:2d}: High={high_mask.sum():3d} samples, Low={low_mask.sum():3d} samples\")\n",
    "    print(f\"      Var(high) = {var_high:8.3f}, Var(low) = {var_low:8.3f}, Ratio = {ratio:.3f}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  PC1 variance ratio: {variance_ratios[0]:.3f}\")\n",
    "print(f\"  Mean variance ratio for PC2-10: {np.mean(variance_ratios[1:]):.3f}\")\n",
    "print(f\"  Max variance ratio (excluding PC1): {np.max(variance_ratios[1:]):.3f} (PC{np.argmax(variance_ratios[1:])+2})\")\n",
    "print(\"\\n  → Shows whether PC1 is unique in having high-variance 'other dimensions' for extreme positions\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psa4fpzrfl8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total roles: 448\n",
      "pca_transformed shape: (448, 448)\n"
     ]
    }
   ],
   "source": [
    "# Create role labels from pca_results\n",
    "def get_role_labels_from_pca(pca_results):\n",
    "    labels = []\n",
    "    if 'pos_2' in pca_results['roles'].keys():\n",
    "        pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "        labels.extend(pos_2_roles)\n",
    "    if 'pos_3' in pca_results['roles'].keys():\n",
    "        pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "        labels.extend(pos_3_roles)\n",
    "    return labels\n",
    "\n",
    "role_labels = get_role_labels_from_pca(pca_results)\n",
    "print(f\"Total roles: {len(role_labels)}\")\n",
    "print(f\"pca_transformed shape: {pca_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ogly4i9nk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Top and Bottom Roles for Each PC\n",
      "================================================================================\n",
      "\n",
      "PC1:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Assistant                      (PC1 =   38.88)\n",
      "    2. Screener                       (PC1 =   38.71)\n",
      "    3. Doctor                         (PC1 =   37.75)\n",
      "    4. Analyst                        (PC1 =   36.68)\n",
      "    5. Researcher                     (PC1 =   36.55)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Caveman                        (PC1 =  -86.47)\n",
      "    2. Eldritch                       (PC1 =  -79.26)\n",
      "    3. Leviathan                      (PC1 =  -79.20)\n",
      "    4. Void                           (PC1 =  -74.09)\n",
      "    5. Aberration                     (PC1 =  -69.96)\n",
      "\n",
      "PC2:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Procrastinator                 (PC2 =   89.66)\n",
      "    2. Teenager                       (PC2 =   79.36)\n",
      "    3. Adolescent                     (PC2 =   77.52)\n",
      "    4. Toddler                        (PC2 =   61.69)\n",
      "    5. Gossip                         (PC2 =   52.68)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Eldritch                       (PC2 =  -57.07)\n",
      "    2. Leviathan                      (PC2 =  -45.70)\n",
      "    3. Crystalline                    (PC2 =  -45.51)\n",
      "    4. Oracle                         (PC2 =  -45.07)\n",
      "    5. Tree                           (PC2 =  -44.90)\n",
      "\n",
      "PC3:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Infant                         (PC3 =  109.26)\n",
      "    2. Toddler                        (PC3 =   86.59)\n",
      "    3. Caveman                        (PC3 =   65.89)\n",
      "    4. Void                           (PC3 =   50.69)\n",
      "    5. Virus                          (PC3 =   46.99)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Advocate                       (PC3 =  -34.64)\n",
      "    2. Visionary                      (PC3 =  -34.56)\n",
      "    3. Activist                       (PC3 =  -30.61)\n",
      "    4. Evangelist                     (PC3 =  -29.54)\n",
      "    5. Blogger                        (PC3 =  -29.49)\n",
      "\n",
      "PC4:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Narcissist                     (PC4 =   65.85)\n",
      "    2. Workaholic                     (PC4 =   65.40)\n",
      "    3. Cynic                          (PC4 =   61.07)\n",
      "    4. Provocateur                    (PC4 =   56.77)\n",
      "    5. Zealot                         (PC4 =   56.64)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Toddler                        (PC4 =  -45.79)\n",
      "    2. Caveman                        (PC4 =  -39.21)\n",
      "    3. Fool                           (PC4 =  -34.92)\n",
      "    4. Grandparent                    (PC4 =  -34.69)\n",
      "    5. Infant                         (PC4 =  -33.07)\n",
      "\n",
      "PC5:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Gamer                          (PC5 =   60.55)\n",
      "    2. Mechanic                       (PC5 =   43.87)\n",
      "    3. Hacker                         (PC5 =   40.12)\n",
      "    4. Surfer                         (PC5 =   39.51)\n",
      "    5. Smuggler                       (PC5 =   36.67)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Interviewer                    (PC5 =  -38.57)\n",
      "    2. Toddler                        (PC5 =  -32.91)\n",
      "    3. Counselor                      (PC5 =  -32.42)\n",
      "    4. Therapist                      (PC5 =  -29.73)\n",
      "    5. Moderator                      (PC5 =  -29.38)\n",
      "\n",
      "PC6:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Addict                         (PC6 =   26.33)\n",
      "    2. Prisoner                       (PC6 =   26.09)\n",
      "    3. Widow                          (PC6 =   25.94)\n",
      "    4. Divorcee                       (PC6 =   24.74)\n",
      "    5. Empath                         (PC6 =   24.24)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Toddler                        (PC6 = -106.46)\n",
      "    2. Infant                         (PC6 =  -96.66)\n",
      "    3. Caveman                        (PC6 =  -81.88)\n",
      "    4. Fool                           (PC6 =  -52.08)\n",
      "    5. Robot                          (PC6 =  -39.42)\n",
      "\n",
      "PC7:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Caveman                        (PC7 =   64.64)\n",
      "    2. Traditionalist                 (PC7 =   42.02)\n",
      "    3. Infant                         (PC7 =   39.22)\n",
      "    4. Zealot                         (PC7 =   38.83)\n",
      "    5. Workaholic                     (PC7 =   36.97)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Jester                         (PC7 =  -57.46)\n",
      "    2. Comedian                       (PC7 =  -57.39)\n",
      "    3. Absurdist                      (PC7 =  -54.89)\n",
      "    4. Trickster                      (PC7 =  -45.02)\n",
      "    5. Jester                         (PC7 =  -42.51)\n",
      "\n",
      "PC8:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Prisoner                       (PC8 =   41.61)\n",
      "    2. Exile                          (PC8 =   38.61)\n",
      "    3. Criminal                       (PC8 =   34.44)\n",
      "    4. Refugee                        (PC8 =   34.09)\n",
      "    5. Addict                         (PC8 =   31.69)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Zealot                         (PC8 =  -33.48)\n",
      "    2. Narcissist                     (PC8 =  -32.83)\n",
      "    3. Optimist                       (PC8 =  -30.38)\n",
      "    4. Gamer                          (PC8 =  -28.83)\n",
      "    5. Hedonist                       (PC8 =  -28.03)\n",
      "\n",
      "PC9:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Infant                         (PC9 =   39.31)\n",
      "    2. Toddler                        (PC9 =   30.55)\n",
      "    3. Simulacrum                     (PC9 =   25.18)\n",
      "    4. Hybrid                         (PC9 =   23.92)\n",
      "    5. Crystalline                    (PC9 =   23.15)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Caveman                        (PC9 =  -43.20)\n",
      "    2. Pirate                         (PC9 =  -31.84)\n",
      "    3. Interviewer                    (PC9 =  -30.48)\n",
      "    4. Zealot                         (PC9 =  -28.52)\n",
      "    5. Smuggler                       (PC9 =  -25.26)\n",
      "\n",
      "PC10:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Luddite                        (PC10 =   46.93)\n",
      "    2. Zealot                         (PC10 =   30.80)\n",
      "    3. Jester                         (PC10 =   30.55)\n",
      "    4. Absurdist                      (PC10 =   30.40)\n",
      "    5. Comedian                       (PC10 =   30.29)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Interviewer                    (PC10 =  -30.67)\n",
      "    2. Predator                       (PC10 =  -24.99)\n",
      "    3. Competitor                     (PC10 =  -24.44)\n",
      "    4. Fixer                          (PC10 =  -22.71)\n",
      "    5. Fixer                          (PC10 =  -22.40)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Show top/bottom roles for each PC\n",
    "n_pcs_to_show = 10  # Show first 5 PCs\n",
    "n_roles_to_show = 5  # Show top/bottom 5 roles\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Top and Bottom Roles for Each PC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pc_idx in range(n_pcs_to_show):\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get indices of top and bottom roles\n",
    "    top_indices = np.argsort(pc_values)[-n_roles_to_show:][::-1]\n",
    "    bottom_indices = np.argsort(pc_values)[:n_roles_to_show]\n",
    "    \n",
    "    print(f\"\\nPC{pc_idx+1}:\")\n",
    "    print(f\"  Top {n_roles_to_show} (highest loadings):\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "    \n",
    "    print(f\"  Bottom {n_roles_to_show} (lowest loadings):\")\n",
    "    for i, idx in enumerate(bottom_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0108b",
   "metadata": {},
   "source": [
    "## Default loading along each PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20166672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant projection shape: (1, 448)\n",
      "\n",
      "================================================================================\n",
      "Assistant (default) position relative to role distribution on each PC\n",
      "================================================================================\n",
      "\n",
      "PC1:\n",
      "  Range: [  -86.47,    38.88]\n",
      "  Assistant:    34.72\n",
      "  Relative position: 0.967 (0=min, 1=max)\n",
      "  Min boundary distance: 0.033\n",
      "  Position: near maximum\n",
      "\n",
      "PC2:\n",
      "  Range: [  -57.07,    89.66]\n",
      "  Assistant:    -3.73\n",
      "  Relative position: 0.364 (0=min, 1=max)\n",
      "  Min boundary distance: 0.364\n",
      "  Position: below center\n",
      "\n",
      "PC3:\n",
      "  Range: [  -34.64,   109.26]\n",
      "  Assistant:     1.94\n",
      "  Relative position: 0.254 (0=min, 1=max)\n",
      "  Min boundary distance: 0.254\n",
      "  Position: below center\n",
      "\n",
      "PC4:\n",
      "  Range: [  -45.79,    65.85]\n",
      "  Assistant:    -0.14\n",
      "  Relative position: 0.409 (0=min, 1=max)\n",
      "  Min boundary distance: 0.409\n",
      "  Position: below center\n",
      "\n",
      "PC5:\n",
      "  Range: [  -38.57,    60.55]\n",
      "  Assistant:    -9.77\n",
      "  Relative position: 0.291 (0=min, 1=max)\n",
      "  Min boundary distance: 0.291\n",
      "  Position: below center\n",
      "\n",
      "PC6:\n",
      "  Range: [ -106.46,    26.33]\n",
      "  Assistant:    -1.42\n",
      "  Relative position: 0.791 (0=min, 1=max)\n",
      "  Min boundary distance: 0.209\n",
      "  Position: near maximum\n",
      "\n",
      "PC7:\n",
      "  Range: [  -57.46,    64.64]\n",
      "  Assistant:     0.56\n",
      "  Relative position: 0.475 (0=min, 1=max)\n",
      "  Min boundary distance: 0.475\n",
      "  Position: centered\n",
      "\n",
      "PC8:\n",
      "  Range: [  -33.48,    41.61]\n",
      "  Assistant:    13.95\n",
      "  Relative position: 0.632 (0=min, 1=max)\n",
      "  Min boundary distance: 0.368\n",
      "  Position: above center\n",
      "\n",
      "PC9:\n",
      "  Range: [  -43.20,    39.31]\n",
      "  Assistant:    -4.20\n",
      "  Relative position: 0.473 (0=min, 1=max)\n",
      "  Min boundary distance: 0.473\n",
      "  Position: centered\n",
      "\n",
      "PC10:\n",
      "  Range: [  -30.67,    46.93]\n",
      "  Assistant:     8.47\n",
      "  Relative position: 0.504 (0=min, 1=max)\n",
      "  Min boundary distance: 0.496\n",
      "  Position: centered\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# get default activation and project\n",
    "default_vectors = torch.load(f\"{base_dir}/roles_240/default_vectors.pt\")\n",
    "assistant_layer_activation = default_vectors['activations']['default_1'][layer, :].float().reshape(1, -1)\n",
    "\n",
    "asst_scaled = pca_results['scaler'].transform(assistant_layer_activation.numpy())\n",
    "asst_projected = pca_results['pca'].transform(asst_scaled)\n",
    "print(f\"Assistant projection shape: {asst_projected.shape}\")\n",
    "\n",
    "# Compare each PC loading with the min, max loading of that PC across all roles\n",
    "n_pcs = 10  # or however many you want to analyze\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Assistant (default) position relative to role distribution on each PC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pc_idx in range(n_pcs):\n",
    "    # Get assistant's loading on this PC\n",
    "    asst_loading = asst_projected[0, pc_idx]\n",
    "    \n",
    "    # Get all role loadings on this PC\n",
    "    all_loadings = pca_transformed[:, pc_idx]\n",
    "    min_loading = all_loadings.min()\n",
    "    max_loading = all_loadings.max()\n",
    "    \n",
    "    # Calculate relative position (0 = at min, 1 = at max)\n",
    "    if max_loading != min_loading:\n",
    "        relative_position = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    else:\n",
    "        relative_position = 0.5\n",
    "    \n",
    "    # Distance to nearest boundary (normalized)\n",
    "    dist_to_min = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    dist_to_max = (max_loading - asst_loading) / (max_loading - min_loading)\n",
    "    min_boundary_dist = min(dist_to_min, dist_to_max)\n",
    "    \n",
    "    print(f\"\\nPC{pc_idx+1}:\")\n",
    "    print(f\"  Range: [{min_loading:8.2f}, {max_loading:8.2f}]\")\n",
    "    print(f\"  Assistant: {asst_loading:8.2f}\")\n",
    "    print(f\"  Relative position: {relative_position:.3f} (0=min, 1=max)\")\n",
    "    print(f\"  Min boundary distance: {min_boundary_dist:.3f}\")\n",
    "    \n",
    "    # Interpret position\n",
    "    if relative_position < 0.25:\n",
    "        position_desc = \"near minimum\"\n",
    "    elif relative_position < 0.45:\n",
    "        position_desc = \"below center\"\n",
    "    elif relative_position < 0.55:\n",
    "        position_desc = \"centered\"\n",
    "    elif relative_position < 0.75:\n",
    "        position_desc = \"above center\"\n",
    "    else:\n",
    "        position_desc = \"near maximum\"\n",
    "    print(f\"  Position: {position_desc}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669f17e",
   "metadata": {},
   "source": [
    "## Overall activation variance captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['activations', 'target_layer'])\n",
      "dict_keys(['projected', 'explained_variance_ratio', 'pca_n_components', 'pca_explained_variance_from_fit', 'target_layer', 'pca_config_path'])\n",
      "dict_keys(['projected', 'explained_variance_ratio', 'pca_n_components', 'pca_explained_variance_from_fit', 'target_layer', 'pca_config_path'])\n"
     ]
    }
   ],
   "source": [
    "# load in the mean_activations.pt and the role/trait projections...\n",
    "\n",
    "act_dir = f\"/workspace/{model_name}/dataset_activations/lmsys_10000\"\n",
    "\n",
    "chat_raw = torch.load(f\"{act_dir}/mean_activations.pt\")\n",
    "chat_roles = torch.load(f\"{act_dir}/roles_projections.pt\", weights_only=False)\n",
    "chat_traits = torch.load(f\"{act_dir}/traits_projections.pt\", weights_only=False)\n",
    "\n",
    "print(chat_raw.keys())\n",
    "print(chat_roles.keys())\n",
    "print(chat_traits.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw activations shape: torch.Size([18777, 4608])\n",
      "\n",
      "Total variance in raw activations: 7442113.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Role subspace:\n",
      "  Variance captured: 1283001.00\n",
      "  Variance explained: 0.1724 (17.24%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait subspace:\n",
      "  Variance captured: 1234600.38\n",
      "  Variance explained: 0.1659 (16.59%)\n",
      "\n",
      "============================================================\n",
      "Summary: Variance Explained by Subspaces\n",
      "============================================================\n",
      "Role subspace:  17.24%\n",
      "Trait subspace: 16.59%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Get the raw activations\n",
    "raw_activations = chat_raw['activations'][:, layer, :].float()\n",
    "print(f\"Raw activations shape: {raw_activations.shape}\")\n",
    "\n",
    "# Calculate total variance in raw activations\n",
    "total_var = torch.var(raw_activations, dim=0).sum().item()\n",
    "print(f\"\\nTotal variance in raw activations: {total_var:.2f}\")\n",
    "\n",
    "# For roles: reconstruct from PCA space back to raw space\n",
    "roles_projected = chat_roles['projected']  # Shape: [18950, 463]\n",
    "# Inverse transform: unstandardize and inverse PCA\n",
    "roles_reconstructed = pca_results['pca'].inverse_transform(roles_projected)  # This gives standardized features\n",
    "roles_reconstructed = pca_results['scaler'].inverse_transform(roles_reconstructed)  # Unstandardize\n",
    "roles_reconstructed = torch.from_numpy(roles_reconstructed).float()\n",
    "\n",
    "# Calculate variance in reconstructed activations\n",
    "roles_var = torch.var(roles_reconstructed, dim=0).sum().item()\n",
    "roles_variance_explained = roles_var / total_var\n",
    "\n",
    "print(f\"\\nRole subspace:\")\n",
    "print(f\"  Variance captured: {roles_var:.2f}\")\n",
    "print(f\"  Variance explained: {roles_variance_explained:.4f} ({roles_variance_explained*100:.2f}%)\")\n",
    "\n",
    "# For traits: load trait PCA results and do the same\n",
    "trait_pca_results = torch.load(f\"{base_dir}/traits_240/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n",
    "traits_projected = chat_traits['projected']  # Shape: [18950, 240]\n",
    "\n",
    "traits_reconstructed = trait_pca_results['pca'].inverse_transform(traits_projected)\n",
    "traits_reconstructed = trait_pca_results['scaler'].inverse_transform(traits_reconstructed)\n",
    "traits_reconstructed = torch.from_numpy(traits_reconstructed).float()\n",
    "\n",
    "# Calculate variance in reconstructed activations\n",
    "traits_var = torch.var(traits_reconstructed, dim=0).sum().item()\n",
    "traits_variance_explained = traits_var / total_var\n",
    "\n",
    "print(f\"\\nTrait subspace:\")\n",
    "print(f\"  Variance captured: {traits_var:.2f}\")\n",
    "print(f\"  Variance explained: {traits_variance_explained:.4f} ({traits_variance_explained*100:.2f}%)\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary: Variance Explained by Subspaces\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Role subspace:  {roles_variance_explained*100:.2f}%\")\n",
    "print(f\"Trait subspace: {traits_variance_explained*100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15tubzaaejf",
   "metadata": {},
   "source": [
    "### Conditional variance in LMSYS chat samples based on PC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "snh5xz24paq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LMSYS CHAT DATASET: Conditional Variance Analysis\n",
      "============================================================\n",
      "PC1 threshold: 25\n",
      "Assistant-like samples (PC1 > 25): 36 samples\n",
      "Roleplay samples (PC1 <= 25): 18741 samples\n",
      "\n",
      "Full activation space:\n",
      "  Variance (Assistant-like): 873.245911\n",
      "  Variance (Roleplay): 1615.255005\n",
      "  Ratio (Assistant/Roleplay): 0.5406 (54.06%)\n",
      "\n",
      "PC1 projected out:\n",
      "  Variance (Assistant-like): 872.418762\n",
      "  Variance (Roleplay): 1611.242676\n",
      "  Ratio (Assistant/Roleplay): 0.5415 (54.15%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Use the already-projected LMSYS chat samples to get PC1 values\n",
    "# roles_projected already contains the PC scores for all samples\n",
    "lmsys_pc1 = roles_projected[:, 0]\n",
    "\n",
    "# Use the same threshold as for role vectors\n",
    "# Create assistant-like and roleplay masks based on PC1\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    lmsys_assistant_mask = lmsys_pc1 > threshold\n",
    "    lmsys_roleplay_mask = lmsys_pc1 <= threshold\n",
    "else:\n",
    "    lmsys_assistant_mask = lmsys_pc1 < threshold\n",
    "    lmsys_roleplay_mask = lmsys_pc1 >= threshold\n",
    "\n",
    "# Compute variance for each group (full raw activation space)\n",
    "var_lmsys_assistant = torch.var(raw_activations[lmsys_assistant_mask], dim=0).mean().item()\n",
    "var_lmsys_roleplay = torch.var(raw_activations[lmsys_roleplay_mask], dim=0).mean().item()\n",
    "var_ratio_lmsys = var_lmsys_assistant / var_lmsys_roleplay\n",
    "\n",
    "# Project out PC1 from raw activations\n",
    "pc1_direction = torch.from_numpy(pca_results['pca'].components_[0]).float()\n",
    "pc1_loadings = (raw_activations @ pc1_direction).unsqueeze(1)\n",
    "pc1_projections = pc1_loadings * pc1_direction.unsqueeze(0)\n",
    "raw_activations_pc1_removed = raw_activations - pc1_projections\n",
    "\n",
    "# Compute variance with PC1 projected out\n",
    "var_lmsys_assistant_no_pc1 = torch.var(raw_activations_pc1_removed[lmsys_assistant_mask], dim=0).mean().item()\n",
    "var_lmsys_roleplay_no_pc1 = torch.var(raw_activations_pc1_removed[lmsys_roleplay_mask], dim=0).mean().item()\n",
    "var_ratio_lmsys_no_pc1 = var_lmsys_assistant_no_pc1 / var_lmsys_roleplay_no_pc1\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"LMSYS CHAT DATASET: Conditional Variance Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like samples (PC1 {'>' if model_name == 'gemma-2-27b' else '<'} {threshold}): {lmsys_assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay samples (PC1 {'<=' if model_name == 'gemma-2-27b' else '>='} {threshold}): {lmsys_roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nFull activation space:\")\n",
    "print(f\"  Variance (Assistant-like): {var_lmsys_assistant:.6f}\")\n",
    "print(f\"  Variance (Roleplay): {var_lmsys_roleplay:.6f}\")\n",
    "print(f\"  Ratio (Assistant/Roleplay): {var_ratio_lmsys:.4f} ({var_ratio_lmsys*100:.2f}%)\")\n",
    "print(f\"\\nPC1 projected out:\")\n",
    "print(f\"  Variance (Assistant-like): {var_lmsys_assistant_no_pc1:.6f}\")\n",
    "print(f\"  Variance (Roleplay): {var_lmsys_roleplay_no_pc1:.6f}\")\n",
    "print(f\"  Ratio (Assistant/Roleplay): {var_ratio_lmsys_no_pc1:.4f} ({var_ratio_lmsys_no_pc1*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecw3cw5nr9v",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LMSYS DATASET: Quintile Analysis\n",
      "============================================================\n",
      "\n",
      "Quintile 1: PC1 ∈ [-49.10, -20.29]\n",
      "  Sample size: 3756\n",
      "  Mean variance (full): 1653.324341\n",
      "  Mean variance (PC1 removed): 1651.881348\n",
      "\n",
      "Quintile 2: PC1 ∈ [-20.29, -12.90]\n",
      "  Sample size: 3755\n",
      "  Mean variance (full): 1468.764160\n",
      "  Mean variance (PC1 removed): 1467.981079\n",
      "\n",
      "Quintile 3: PC1 ∈ [-12.90, -8.29]\n",
      "  Sample size: 3755\n",
      "  Mean variance (full): 1188.254761\n",
      "  Mean variance (PC1 removed): 1187.666382\n",
      "\n",
      "Quintile 4: PC1 ∈ [-8.29, -3.87]\n",
      "  Sample size: 3755\n",
      "  Mean variance (full): 1128.863647\n",
      "  Mean variance (PC1 removed): 1128.212158\n",
      "\n",
      "Quintile 5: PC1 ∈ [-3.87, 41.18]\n",
      "  Sample size: 3756\n",
      "  Mean variance (full): 1198.855713\n",
      "  Mean variance (PC1 removed): 1197.340820\n",
      "\n",
      "------------------------------------------------------------\n",
      "Variance ratio (Last/First quintile, full): 1.38x\n",
      "Variance ratio (Last/First quintile, PC1 removed): 1.38x\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Quintile analysis for LMSYS dataset\n",
    "n_quintiles = 5\n",
    "lmsys_quintile_edges = np.quantile(lmsys_pc1, np.linspace(0, 1, n_quintiles + 1))\n",
    "lmsys_quintile_variances = []\n",
    "lmsys_quintile_variances_no_pc1 = []\n",
    "lmsys_quintile_sizes = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LMSYS DATASET: Quintile Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(n_quintiles):\n",
    "    if i == 0:\n",
    "        mask = (lmsys_pc1 >= lmsys_quintile_edges[i]) & (lmsys_pc1 <= lmsys_quintile_edges[i + 1])\n",
    "    else:\n",
    "        mask = (lmsys_pc1 > lmsys_quintile_edges[i]) & (lmsys_pc1 <= lmsys_quintile_edges[i + 1])\n",
    "    \n",
    "    quintile_var = torch.var(raw_activations[mask], dim=0).mean().item()\n",
    "    quintile_var_no_pc1 = torch.var(raw_activations_pc1_removed[mask], dim=0).mean().item()\n",
    "    lmsys_quintile_variances.append(quintile_var)\n",
    "    lmsys_quintile_variances_no_pc1.append(quintile_var_no_pc1)\n",
    "    lmsys_quintile_sizes.append(mask.sum())\n",
    "    \n",
    "    print(f\"\\nQuintile {i+1}: PC1 ∈ [{lmsys_quintile_edges[i]:.2f}, {lmsys_quintile_edges[i+1]:.2f}]\")\n",
    "    print(f\"  Sample size: {mask.sum()}\")\n",
    "    print(f\"  Mean variance (full): {quintile_var:.6f}\")\n",
    "    print(f\"  Mean variance (PC1 removed): {quintile_var_no_pc1:.6f}\")\n",
    "\n",
    "# Calculate ratios between first and last quintile\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    lmsys_quintile_ratio = lmsys_quintile_variances[0] / lmsys_quintile_variances[-1]\n",
    "    lmsys_quintile_ratio_no_pc1 = lmsys_quintile_variances_no_pc1[0] / lmsys_quintile_variances_no_pc1[-1]\n",
    "else:\n",
    "    lmsys_quintile_ratio = lmsys_quintile_variances[-1] / lmsys_quintile_variances[0]\n",
    "    lmsys_quintile_ratio_no_pc1 = lmsys_quintile_variances_no_pc1[-1] / lmsys_quintile_variances_no_pc1[0]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(f\"Variance ratio (Last/First quintile, full): {lmsys_quintile_ratio:.2f}x\")\n",
    "print(f\"Variance ratio (Last/First quintile, PC1 removed): {lmsys_quintile_ratio_no_pc1:.2f}x\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tgsc36bsim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LMSYS DATASET: Distance from Center Correlation\n",
      "============================================================\n",
      "Correlation between PC1 and L2 distance from mean (full):\n",
      "  r = -0.2746\n",
      "  p-value = 5.039e-322\n",
      "  Highly significant (p < 0.001)\n",
      "\n",
      "Correlation between PC1 and L2 distance from mean (PC1 removed):\n",
      "  r = -0.2752\n",
      "  p-value = 1.976e-323\n",
      "  Highly significant (p < 0.001)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Distance from center correlation for LMSYS dataset\n",
    "raw_activations_mean = raw_activations.mean(dim=0)\n",
    "raw_activations_pc1_removed_mean = raw_activations_pc1_removed.mean(dim=0)\n",
    "\n",
    "# Compute L2 distance from mean for each sample\n",
    "lmsys_distances_raw = torch.norm(raw_activations - raw_activations_mean, p=2, dim=1).numpy()\n",
    "lmsys_distances_raw_no_pc1 = torch.norm(raw_activations_pc1_removed - raw_activations_pc1_removed_mean, p=2, dim=1).numpy()\n",
    "\n",
    "# Calculate correlation with PC1\n",
    "lmsys_correlation_raw, lmsys_p_value_raw = pearsonr(lmsys_pc1, lmsys_distances_raw)\n",
    "lmsys_correlation_raw_no_pc1, lmsys_p_value_raw_no_pc1 = pearsonr(lmsys_pc1, lmsys_distances_raw_no_pc1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LMSYS DATASET: Distance from Center Correlation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Correlation between PC1 and L2 distance from mean (full):\")\n",
    "print(f\"  r = {lmsys_correlation_raw:.4f}\")\n",
    "print(f\"  p-value = {lmsys_p_value_raw:.3e}\")\n",
    "if lmsys_p_value_raw < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif lmsys_p_value_raw < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "\n",
    "print(f\"\\nCorrelation between PC1 and L2 distance from mean (PC1 removed):\")\n",
    "print(f\"  r = {lmsys_correlation_raw_no_pc1:.4f}\")\n",
    "print(f\"  p-value = {lmsys_p_value_raw_no_pc1:.3e}\")\n",
    "if lmsys_p_value_raw_no_pc1 < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif lmsys_p_value_raw_no_pc1 < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3pk6ipumh22",
   "metadata": {},
   "source": [
    "## Individual model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0pec8iqx20qe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving variance analysis results to ./results/\n",
      "Timestamp: 2025-10-22T06:20:43.219267\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Configuration for saving\n",
    "outdir = \"./results\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# Get current timestamp\n",
    "timestamp = datetime.now().isoformat()\n",
    "\n",
    "print(f\"Saving variance analysis results to {outdir}/\")\n",
    "print(f\"Timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3mzx2uw37it",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built per-model variance analysis data structure\n"
     ]
    }
   ],
   "source": [
    "# Build the per-model variance analysis JSON structure\n",
    "\n",
    "# Build quintile data\n",
    "quintiles_data = []\n",
    "for i in range(len(quintile_edges) - 1):\n",
    "    quintiles_data.append({\n",
    "        \"quintile\": i + 1,\n",
    "        \"pc1_range\": [float(quintile_edges[i]), float(quintile_edges[i + 1])],\n",
    "        \"n_samples\": int(quintile_sizes[i]),\n",
    "        \"variance_full\": float(quintile_variances[i]),\n",
    "        \"variance_pc1_removed\": float(quintile_variances_no_pc1[i])\n",
    "    })\n",
    "\n",
    "# Build LMSYS quintile data\n",
    "lmsys_quintiles_data = []\n",
    "for i in range(len(lmsys_quintile_edges) - 1):\n",
    "    lmsys_quintiles_data.append({\n",
    "        \"quintile\": i + 1,\n",
    "        \"pc1_range\": [float(lmsys_quintile_edges[i]), float(lmsys_quintile_edges[i + 1])],\n",
    "        \"n_samples\": int(lmsys_quintile_sizes[i]),\n",
    "        \"variance_full\": float(lmsys_quintile_variances[i]),\n",
    "        \"variance_pc1_removed\": float(lmsys_quintile_variances_no_pc1[i])\n",
    "    })\n",
    "\n",
    "# Build PC distance correlations\n",
    "pc_distance_corrs = []\n",
    "for i in range(len(correlations)):\n",
    "    pc_distance_corrs.append({\n",
    "        \"pc\": i + 1,\n",
    "        \"r\": float(correlations[i]),\n",
    "        \"p_value\": float(p_values[i]),\n",
    "        \"significant\": bool(p_values[i] < 0.05)\n",
    "    })\n",
    "\n",
    "# Build conditional variance by PC\n",
    "cond_var_by_pc = []\n",
    "for i in range(len(variance_ratios)):\n",
    "    cond_var_by_pc.append({\n",
    "        \"pc\": i + 1,\n",
    "        \"ratio\": float(variance_ratios[i])\n",
    "    })\n",
    "\n",
    "# Build default PC loading data\n",
    "pc_positions = []\n",
    "centered_pcs = []\n",
    "extreme_pcs = []\n",
    "\n",
    "for pc_idx in range(n_pcs):\n",
    "    asst_loading = asst_projected[0, pc_idx]\n",
    "    all_loadings = pca_transformed[:, pc_idx]\n",
    "    min_loading = all_loadings.min()\n",
    "    max_loading = all_loadings.max()\n",
    "\n",
    "    if max_loading != min_loading:\n",
    "        relative_position = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    else:\n",
    "        relative_position = 0.5\n",
    "\n",
    "    dist_to_min = relative_position\n",
    "    dist_to_max = 1.0 - relative_position\n",
    "    min_boundary_dist = min(dist_to_min, dist_to_max)\n",
    "\n",
    "    if relative_position < 0.25:\n",
    "        position_desc = \"near minimum\"\n",
    "        extreme_pcs.append(pc_idx + 1)\n",
    "    elif relative_position < 0.45:\n",
    "        position_desc = \"below center\"\n",
    "    elif relative_position < 0.55:\n",
    "        position_desc = \"centered\"\n",
    "        centered_pcs.append(pc_idx + 1)\n",
    "    elif relative_position < 0.75:\n",
    "        position_desc = \"above center\"\n",
    "    else:\n",
    "        position_desc = \"near maximum\"\n",
    "        extreme_pcs.append(pc_idx + 1)\n",
    "\n",
    "    pc_positions.append({\n",
    "        \"pc\": pc_idx + 1,\n",
    "        \"assistant_loading\": float(asst_loading),\n",
    "        \"role_range_min\": float(min_loading),\n",
    "        \"role_range_max\": float(max_loading),\n",
    "        \"relative_position\": float(relative_position),\n",
    "        \"min_boundary_distance\": float(min_boundary_dist),\n",
    "        \"position_category\": position_desc\n",
    "    })\n",
    "\n",
    "# Build the complete JSON structure\n",
    "model_variance_data = {\n",
    "    \"model_name\": model_name,\n",
    "    \"layer\": layer,\n",
    "    \"hidden_dim\": vectors.shape[1],\n",
    "    \"n_roles\": len(activations),\n",
    "    \"n_role_samples\": role_vectors.shape[0],\n",
    "    \"timestamp\": timestamp,\n",
    "    \"analysis_version\": \"1.0\",\n",
    "\n",
    "    \"across_within_role_var\": {\n",
    "        \"raw_activations\": {\n",
    "            \"across_var_mean\": float(raw_across_var.mean().item()),\n",
    "            \"within_var_mean\": float(avg_raw_within_var.mean().item()),\n",
    "            \"ratio\": float(raw_ratio)\n",
    "        },\n",
    "        \"raw_activations_normalized\": {\n",
    "            \"across_var_mean\": float(raw_across_var_normalized.mean().item()),\n",
    "            \"within_var_mean\": float(avg_raw_within_var_normalized.mean().item()),\n",
    "            \"ratio\": float(raw_ratio_normalized)\n",
    "        },\n",
    "        \"pca_space_all_components\": {\n",
    "            \"across_var_mean\": float(pca_across_var.mean()),\n",
    "            \"within_var_mean\": float(mean_pca_within_var.mean()),\n",
    "            \"ratio\": float(pca_ratio),\n",
    "            \"n_components\": int(len(pca_across_var))\n",
    "        },\n",
    "        \"pc1_only\": {\n",
    "            \"across_var\": float(pc1_across_var),\n",
    "            \"within_var_mean\": float(mean_pc1_within_var),\n",
    "            \"ratio\": float(pc1_ratio)\n",
    "        },\n",
    "        \"per_pc_ratios\": {\n",
    "            \"description\": \"Ratio of across-role variance to mean within-role variance for each PC\",\n",
    "            \"top_10_pcs\": [\n",
    "                {\n",
    "                    \"pc\": i + 1,\n",
    "                    \"across_var\": float(pca_across_var[i]),\n",
    "                    \"within_var_mean\": float(mean_pca_within_var[i]),\n",
    "                    \"ratio\": float(all_pc_ratios[i])\n",
    "                }\n",
    "                for i in range(10)\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"conditional_var_roles\": {\n",
    "        \"description\": \"Conditional variance analysis for role vectors based on PC1 position\",\n",
    "        \"n_samples\": int(role_vectors.shape[0]),\n",
    "        \"threshold_analysis\": {\n",
    "            \"pc1_threshold\": threshold,\n",
    "            \"assistant_like\": {\n",
    "                \"mask\": f\"pc1 < {threshold}\",\n",
    "                \"n_samples\": int(assistant_mask.sum()),\n",
    "                \"variance_raw\": float(var_assistant_raw),\n",
    "                \"variance_raw_pc1_removed\": float(var_assistant_raw_no_pc1)\n",
    "            },\n",
    "            \"roleplay\": {\n",
    "                \"mask\": f\"pc1 >= {threshold}\",\n",
    "                \"n_samples\": int(roleplay_mask.sum()),\n",
    "                \"variance_raw\": float(var_roleplay_raw),\n",
    "                \"variance_raw_pc1_removed\": float(var_roleplay_raw_no_pc1)\n",
    "            },\n",
    "            \"variance_ratio_raw\": float(var_ratio_raw),\n",
    "            \"variance_ratio_raw_pc1_removed\": float(var_ratio_raw_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"quintile_analysis\": {\n",
    "            \"n_quintiles\": 5,\n",
    "            \"quintiles\": quintiles_data,\n",
    "            \"variance_ratio_first_to_last_full\": float(quintile_ratio),\n",
    "            \"variance_ratio_first_to_last_pc1_removed\": float(quintile_ratio_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"distance_correlation\": {\n",
    "            \"full_space\": {\n",
    "                \"correlation\": float(correlation_raw),\n",
    "                \"p_value\": float(p_value_raw),\n",
    "                \"significant\": bool(p_value_raw < 0.05)\n",
    "            },\n",
    "            \"pc1_removed\": {\n",
    "                \"correlation\": float(correlation_raw_no_pc1),\n",
    "                \"p_value\": float(p_value_raw_no_pc1),\n",
    "                \"significant\": bool(p_value_raw_no_pc1 < 0.05)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"conditional_var_dataset\": {\n",
    "        \"description\": \"Conditional variance analysis for LMSYS chat dataset based on PC1 position\",\n",
    "        \"n_samples\": int(raw_activations.shape[0]),\n",
    "        \"threshold_analysis\": {\n",
    "            \"pc1_threshold\": threshold,\n",
    "            \"assistant_like\": {\n",
    "                \"n_samples\": int(lmsys_assistant_mask.sum()),\n",
    "                \"variance_full\": float(var_lmsys_assistant),\n",
    "                \"variance_pc1_removed\": float(var_lmsys_assistant_no_pc1)\n",
    "            },\n",
    "            \"roleplay\": {\n",
    "                \"n_samples\": int(lmsys_roleplay_mask.sum()),\n",
    "                \"variance_full\": float(var_lmsys_roleplay),\n",
    "                \"variance_pc1_removed\": float(var_lmsys_roleplay_no_pc1)\n",
    "            },\n",
    "            \"variance_ratio_full\": float(var_ratio_lmsys),\n",
    "            \"variance_ratio_pc1_removed\": float(var_ratio_lmsys_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"quintile_analysis\": {\n",
    "            \"n_quintiles\": 5,\n",
    "            \"quintiles\": lmsys_quintiles_data,\n",
    "            \"variance_ratio_first_to_last_full\": float(lmsys_quintile_ratio),\n",
    "            \"variance_ratio_first_to_last_pc1_removed\": float(lmsys_quintile_ratio_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"distance_correlation\": {\n",
    "            \"full_space\": {\n",
    "                \"correlation\": float(lmsys_correlation_raw),\n",
    "                \"p_value\": float(lmsys_p_value_raw),\n",
    "                \"significant\": bool(lmsys_p_value_raw < 0.05)\n",
    "            },\n",
    "            \"pc1_removed\": {\n",
    "                \"correlation\": float(lmsys_correlation_raw_no_pc1),\n",
    "                \"p_value\": float(lmsys_p_value_raw_no_pc1),\n",
    "                \"significant\": bool(lmsys_p_value_raw_no_pc1 < 0.05)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"high_var_pc_correlation\": {\n",
    "        \"pc_distance_correlations\": {\n",
    "            \"description\": \"Correlation between each PC and distance in remaining PC space\",\n",
    "            \"n_pcs_analyzed\": 10,\n",
    "            \"correlations\": pc_distance_corrs,\n",
    "            \"pc1_correlation\": float(correlations[0]),\n",
    "            \"mean_correlation_pc2_to_10\": float(np.mean(correlations[1:]))\n",
    "        },\n",
    "\n",
    "        \"conditional_variance_by_pc\": {\n",
    "            \"description\": \"Variance in PC2-10 conditioned on high/low position along each PC\",\n",
    "            \"n_pcs_analyzed\": 10,\n",
    "            \"variance_ratios\": cond_var_by_pc,\n",
    "            \"pc1_variance_ratio\": float(variance_ratios[0]),\n",
    "            \"mean_variance_ratio_pc2_to_10\": float(np.mean(variance_ratios[1:])),\n",
    "            \"max_variance_ratio_excluding_pc1\": float(np.max(variance_ratios[1:])),\n",
    "            \"max_variance_ratio_pc\": int(np.argmax(variance_ratios[1:]) + 2)\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"default_pc_loading\": {\n",
    "        \"description\": \"Position of default assistant activation relative to role distribution on each PC\",\n",
    "        \"n_pcs_analyzed\": n_pcs,\n",
    "        \"pc_positions\": pc_positions,\n",
    "        \"summary\": {\n",
    "            \"pc1_position\": pc_positions[0][\"position_category\"],\n",
    "            \"pc1_relative_position\": pc_positions[0][\"relative_position\"],\n",
    "            \"centered_pcs\": centered_pcs,\n",
    "            \"extreme_pcs\": extreme_pcs\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"overall_activation_var\": {\n",
    "        \"description\": \"Variance in chat dataset activations explained by role and trait subspaces\",\n",
    "        \"dataset\": {\n",
    "            \"name\": \"lmsys_10000\",\n",
    "            \"n_samples\": int(raw_activations.shape[0]),\n",
    "            \"source_path\": act_dir\n",
    "        },\n",
    "        \"total_variance\": float(total_var),\n",
    "        \"role_subspace\": {\n",
    "            \"n_components\": int(roles_projected.shape[1]),\n",
    "            \"variance_captured\": float(roles_var),\n",
    "            \"variance_explained_ratio\": float(roles_variance_explained),\n",
    "            \"variance_explained_percent\": float(roles_variance_explained * 100)\n",
    "        },\n",
    "        \"trait_subspace\": {\n",
    "            \"n_components\": int(traits_projected.shape[1]),\n",
    "            \"variance_captured\": float(traits_var),\n",
    "            \"variance_explained_ratio\": float(traits_variance_explained),\n",
    "            \"variance_explained_percent\": float(traits_variance_explained * 100)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Built per-model variance analysis data structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zi9ycc6ru9n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save per-model variance analysis to JSON file\n",
    "filename = f\"{outdir}/{model_name.lower()}/variance_layer{layer}.json\"\n",
    "\n",
    "# Load existing JSON if it exists, otherwise start with empty dict\n",
    "try:\n",
    "    with open(filename, 'r') as f:\n",
    "        existing_data = json.load(f)\n",
    "    print(f\"Loaded existing data from: {filename}\")\n",
    "except FileNotFoundError:\n",
    "    existing_data = {}\n",
    "    print(f\"No existing file found, creating new data structure\")\n",
    "\n",
    "# Update only the fields we want to save\n",
    "existing_data.update({\n",
    "    # Update these specific sections (uncomment the ones you want to update)\n",
    "    \"across_within_role_var\": model_variance_data[\"across_within_role_var\"],  # Includes per_pc_ratios\n",
    "    # \"conditional_var_roles\": model_variance_data[\"conditional_var_roles\"],\n",
    "    \"conditional_var_dataset\": model_variance_data[\"conditional_var_dataset\"],\n",
    "    # \"high_var_pc_correlation\": model_variance_data[\"high_var_pc_correlation\"],\n",
    "    # \"default_pc_loading\": model_variance_data[\"default_pc_loading\"],\n",
    "    # \"overall_activation_var\": model_variance_data[\"overall_activation_var\"],\n",
    "})\n",
    "\n",
    "# Save back to file\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(existing_data, f, indent=2)\n",
    "\n",
    "print(f\"Saved: {filename}\")\n",
    "print(f\"✓ Updated variance analysis for {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4a7bf",
   "metadata": {},
   "source": [
    "## Correlations between role loadings onto PCs across the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "# layers = [22, 32, 40]\n",
    "\n",
    "# trait_results = {}\n",
    "# labels = {}\n",
    "# for model, layer in zip(models, layers):\n",
    "#     model_dir = f\"/workspace/{model}/traits_240\"\n",
    "#     trait_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n",
    "#     print(trait_results[model]['pca_transformed'].shape)\n",
    "#     labels[model] = trait_results[model]['traits']['pos_neg_50']\n",
    "#     print(labels[model][:20])\n",
    "\n",
    "# # need to get intersection of traits across models (gemma missing vindictive)\n",
    "# pca_transformed = []\n",
    "# for model in models:\n",
    "#     if model != 'gemma-2-27b':\n",
    "#         # splice out index 5 but keep the ones before and after\n",
    "#         pca_transformed.append(np.concatenate((trait_results[model]['pca_transformed'][:5], trait_results[model]['pca_transformed'][6:])))\n",
    "#     else:\n",
    "#         pca_transformed.append(trait_results[model]['pca_transformed'])\n",
    "\n",
    "# for m in pca_transformed:\n",
    "#     print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transpose each matrix so rows are PCs and columns are traits\n",
    "# pca_transposed = [m.T for m in pca_transformed]\n",
    "\n",
    "# # Extract top 10 PCs from each model\n",
    "# n_pcs = 6\n",
    "# top_pcs = [m[:n_pcs] for m in pca_transposed]\n",
    "\n",
    "# print(f\"Transposed shapes (n_pcs, n_traits):\")\n",
    "# for model, pc_matrix in zip(models, top_pcs):\n",
    "#     print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# # Compute pairwise correlations for each PC\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# pc_correlations = []\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     # Extract the trait loading vector for this PC from each model\n",
    "#     gemma_pc = top_pcs[0][pc_idx]\n",
    "#     qwen_pc = top_pcs[1][pc_idx]\n",
    "#     llama_pc = top_pcs[2][pc_idx]\n",
    "    \n",
    "#     # Compute pairwise correlations\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     # Create 3x3 correlation matrix\n",
    "#     corr_matrix = np.array([\n",
    "#         [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "#         [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "#         [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "#     ])\n",
    "    \n",
    "#     pc_correlations.append(corr_matrix)\n",
    "\n",
    "#     print(f\"\\nPC{pc_idx + 1}:\")\n",
    "#     print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "#     print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "#     print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f52212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try for top 10 role PCs\n",
    "# models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "# layers = [22, 32, 40]\n",
    "\n",
    "# def get_role_labels(pca_results):\n",
    "#     labels = []\n",
    "#     if 'pos_2' in pca_results['roles'].keys():\n",
    "#         pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "#         pos_2_roles = [f\"{role} (Somewhat RP)\" for role in pos_2_roles]\n",
    "#         labels.extend(pos_2_roles)\n",
    "#     if 'pos_3' in pca_results['roles'].keys():\n",
    "#         pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "#         pos_3_roles = [f\"{role} (Fully RP)\" for role in pos_3_roles]\n",
    "#         labels.extend(pos_3_roles)\n",
    "#     return labels\n",
    "\n",
    "\n",
    "# role_results = {}\n",
    "# labels = {}\n",
    "# for model, layer in zip(models, layers):\n",
    "#     model_dir = f\"/workspace/{model}/roles_240\"\n",
    "#     role_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos23.pt\", weights_only=False)\n",
    "#     print(role_results[model]['pca_transformed'].shape)\n",
    "#     labels[model] = get_role_labels(role_results[model])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find intersection of roles across all 3 models\n",
    "# set_gemma = set(labels['gemma-2-27b'])\n",
    "# set_qwen = set(labels['qwen-3-32b'])\n",
    "# set_llama = set(labels['llama-3.3-70b'])\n",
    "\n",
    "# common_roles = set_gemma & set_qwen & set_llama\n",
    "# print(f\"Common roles across all models: {len(common_roles)}\")\n",
    "\n",
    "# # Get indices of common roles for each model (preserving order from labels)\n",
    "# indices = {}\n",
    "# for model in models:\n",
    "#     model_indices = []\n",
    "#     for i, role in enumerate(labels[model]):\n",
    "#         if role in common_roles:\n",
    "#             model_indices.append(i)\n",
    "#     indices[model] = model_indices\n",
    "#     print(f\"{model}: {len(model_indices)} common roles\")\n",
    "\n",
    "# # Extract aligned PCA transformed matrices (only common roles, in consistent order)\n",
    "# # Need to ensure the same role ordering across models\n",
    "# common_roles_list = sorted(list(common_roles))  # Consistent ordering\n",
    "\n",
    "# pca_transformed_roles = []\n",
    "# for model in models:\n",
    "#     # Map from common_roles_list order to model's indices\n",
    "#     model_indices_ordered = []\n",
    "#     for role in common_roles_list:\n",
    "#         idx = labels[model].index(role)\n",
    "#         model_indices_ordered.append(idx)\n",
    "    \n",
    "#     # Extract rows for common roles in the standardized order\n",
    "#     pca_transformed_roles.append(role_results[model]['pca_transformed'][model_indices_ordered])\n",
    "#     print(f\"{model} aligned shape: {pca_transformed_roles[-1].shape}\")\n",
    "\n",
    "# # Transpose each matrix so rows are PCs and columns are roles\n",
    "# pca_transposed_roles = [m.T for m in pca_transformed_roles]\n",
    "\n",
    "# # Extract top 10 PCs from each model\n",
    "# n_pcs = 6\n",
    "# top_pcs_roles = [m[:n_pcs] for m in pca_transposed_roles]\n",
    "\n",
    "# print(f\"\\nTransposed shapes (n_pcs, n_common_roles):\")\n",
    "# for model, pc_matrix in zip(models, top_pcs_roles):\n",
    "#     print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# # Compute pairwise correlations for each PC\n",
    "# pc_correlations_roles = []\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     # Extract the role loading vector for this PC from each model\n",
    "#     gemma_pc = top_pcs_roles[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_roles[1][pc_idx]\n",
    "#     llama_pc = top_pcs_roles[2][pc_idx]\n",
    "    \n",
    "#     # Compute pairwise correlations\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     # Create 3x3 correlation matrix\n",
    "#     corr_matrix = np.array([\n",
    "#         [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "#         [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "#         [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "#     ])\n",
    "    \n",
    "#     pc_correlations_roles.append(corr_matrix)\n",
    "\n",
    "#     print(f\"\\nPC{pc_idx + 1}:\")\n",
    "#     print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "#     print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "#     print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b1694",
   "metadata": {},
   "source": [
    "## Cross Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n0k76vs7m5m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build cross-model PC loadings analysis JSON structure\n",
    "\n",
    "# n_pcs = 6\n",
    "\n",
    "# # Build trait analysis\n",
    "# trait_data = {\n",
    "#     \"dataset_info\": {\n",
    "#         \"n_common_traits\": pca_transformed[0].shape[0],\n",
    "#         \"excluded_traits\": [\"vindictive\"],\n",
    "#         \"note\": \"Gemma missing vindictive trait, spliced out from other models for alignment\"\n",
    "#     },\n",
    "#     \"model_configs\": {},\n",
    "#     \"pc_correlations\": []\n",
    "# }\n",
    "\n",
    "# # Add model configs for traits\n",
    "# for model, layer_num in zip(models, layers):\n",
    "#     pca_shape = list(trait_results[model]['pca_transformed'].shape)\n",
    "#     trait_data[\"model_configs\"][model] = {\n",
    "#         \"layer\": int(layer_num),\n",
    "#         \"n_total_traits\": int(pca_shape[0]),\n",
    "#         \"pca_shape\": pca_shape\n",
    "#     }\n",
    "\n",
    "# # Add PC correlations for traits\n",
    "# pca_transposed_traits = [m.T for m in pca_transformed]\n",
    "# top_pcs_traits = [m[:n_pcs] for m in pca_transposed_traits]\n",
    "\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     gemma_pc = top_pcs_traits[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_traits[1][pc_idx]\n",
    "#     llama_pc = top_pcs_traits[2][pc_idx]\n",
    "    \n",
    "#     from scipy.stats import pearsonr\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     trait_data[\"pc_correlations\"].append({\n",
    "#         \"pc\": pc_idx + 1,\n",
    "#         \"gemma_qwen\": float(corr_gemma_qwen),\n",
    "#         \"gemma_llama\": float(corr_gemma_llama),\n",
    "#         \"qwen_llama\": float(corr_qwen_llama)\n",
    "#     })\n",
    "\n",
    "# # Build role analysis\n",
    "# role_data = {\n",
    "#     \"dataset_info\": {\n",
    "#         \"n_common_roles\": int(len(common_roles)),\n",
    "#         \"note\": \"Roles include pos_2 (Somewhat RP) and pos_3 (Fully RP) labels\",\n",
    "#         \"alignment_method\": \"sorted common roles list for consistent ordering\"\n",
    "#     },\n",
    "#     \"model_configs\": {},\n",
    "#     \"pc_correlations\": []\n",
    "# }\n",
    "\n",
    "# # Add model configs for roles\n",
    "# for model, layer_num in zip(models, layers):\n",
    "#     pca_shape = list(role_results[model]['pca_transformed'].shape)\n",
    "#     role_data[\"model_configs\"][model] = {\n",
    "#         \"layer\": int(layer_num),\n",
    "#         \"n_total_roles\": int(pca_shape[0]),\n",
    "#         \"n_common_roles\": int(len(common_roles)),\n",
    "#         \"pca_shape\": pca_shape\n",
    "#     }\n",
    "\n",
    "# # Add PC correlations for roles\n",
    "# pca_transposed_roles_func = [m.T for m in pca_transformed_roles]\n",
    "# top_pcs_roles_func = [m[:n_pcs] for m in pca_transposed_roles_func]\n",
    "\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     gemma_pc = top_pcs_roles_func[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_roles_func[1][pc_idx]\n",
    "#     llama_pc = top_pcs_roles_func[2][pc_idx]\n",
    "    \n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     role_data[\"pc_correlations\"].append({\n",
    "#         \"pc\": pc_idx + 1,\n",
    "#         \"gemma_qwen\": float(corr_gemma_qwen),\n",
    "#         \"gemma_llama\": float(corr_gemma_llama),\n",
    "#         \"qwen_llama\": float(corr_qwen_llama)\n",
    "#     })\n",
    "\n",
    "# # Build complete structure\n",
    "# cross_model_data = {\n",
    "#     \"analysis_version\": \"1.0\",\n",
    "#     \"timestamp\": timestamp,\n",
    "#     \"models\": models,\n",
    "#     \"n_pcs_analyzed\": n_pcs,\n",
    "#     \"trait_analysis\": trait_data,\n",
    "#     \"role_analysis\": role_data\n",
    "# }\n",
    "\n",
    "# print(\"Built cross-model PC loadings data structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6s0k2hy6svd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cross-model PC loadings to JSON file\n",
    "# filename = f\"{outdir}/cross_model_loadings.json\"\n",
    "# with open(filename, 'w') as f:\n",
    "#     json.dump(cross_model_data, f, indent=2)\n",
    "\n",
    "# print(f\"Saved: {filename}\")\n",
    "# print(f\"✓ Saved cross-model PC loadings analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2oon4jt838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Summary of saved files\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"SUMMARY: JSON Files Saved\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"\\nOutput directory: {outdir}\")\n",
    "# print(f\"\\nFiles created:\")\n",
    "# print(f\"  1. Per-model variance analysis:\")\n",
    "# print(f\"     - {model_name.lower().replace('.', '-').replace(' ', '-')}_layer{layer}.json\")\n",
    "# print(f\"\\n  2. Cross-model PC loadings:\")\n",
    "# print(f\"     - cross_model_loadings.json\")\n",
    "# print(f\"\\nNote: To save variance analysis for other models (Qwen, Llama),\")\n",
    "# print(f\"      update the configuration cell and re-run the notebook.\")\n",
    "# print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
