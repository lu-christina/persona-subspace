{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28531137",
   "metadata": {},
   "source": [
    "# Variance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f3bcdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:08.842015Z",
     "iopub.status.busy": "2025-08-06T00:18:08.841387Z",
     "iopub.status.idle": "2025-08-06T00:18:09.171163Z",
     "shell.execute_reply": "2025-08-06T00:18:09.170519Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.pca_utils import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julz1owfwk",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "o7pmyp071r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Change these parameters for different models/datasets\n",
    "base_dir = \"/workspace/gemma-2-27b\"\n",
    "type = \"roles_240\"\n",
    "dir = f\"{base_dir}/{type}\"\n",
    "model_name = \"gemma-2-27b\"\n",
    "layer = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76552389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pca_results = torch.load(f\"{dir}/pca/layer{layer}_pos23.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bec2d8",
   "metadata": {},
   "source": [
    "## Variance across and within roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5319f",
   "metadata": {},
   "source": [
    "### raw activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16d954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([275, 4608])\n",
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "vectors = torch.stack(pca_results['vectors']['pos_3'])[:, layer, :].float()\n",
    "print(vectors.shape)\n",
    "\n",
    "# compute variance across roles (rows) along hidden_dims\n",
    "raw_across_var = torch.var(vectors, dim=0)\n",
    "print(raw_across_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197362bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 275 scores\n"
     ]
    }
   ],
   "source": [
    "# load in scores\n",
    "scores = {}\n",
    "for file in os.listdir(f\"{dir}/extract_scores\"):\n",
    "    if file.endswith('.json'):\n",
    "        scores[file.replace('.json', '')] = json.load(open(f\"{dir}/extract_scores/{file}\"))\n",
    "\n",
    "print(f\"Loaded {len(scores)} scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c900d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in raw activations\n",
    "activations = {}\n",
    "for file in os.listdir(f\"{dir}/response_activations\"):\n",
    "    if file.endswith('.pt') and 'default' not in file:\n",
    "        # dict we should iterate over (1200 each)\n",
    "        role_activations = []\n",
    "        obj = torch.load(f\"{dir}/response_activations/{file}\")\n",
    "        for key in obj:\n",
    "            if scores[file.replace('.pt', '')][key] == 3:\n",
    "                role_activations.append(obj[key])\n",
    "        activations[file.replace('.pt', '')] = torch.stack(role_activations)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912a4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "# compute variance within roles\n",
    "raw_within_var = []\n",
    "for file in activations:\n",
    "    raw_within_var.append(torch.var(activations[file][:, layer, :], dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var)} roles, shape is {raw_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea71a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "avg_raw_within_var = torch.stack(raw_within_var).mean(dim=0)\n",
    "print(avg_raw_within_var.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf860e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of raw_across_var / avg_raw_within_var is 0.4312536120414734\n"
     ]
    }
   ],
   "source": [
    "# total variance ratio\n",
    "raw_ratio = raw_across_var.sum() / avg_raw_within_var.sum()\n",
    "print(f\"ratio of raw_across_var / avg_raw_within_var is {raw_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0512101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "raw_across_var_normalized = torch.var(F.normalize(vectors, p=2, dim=1), dim=0)\n",
    "print(raw_across_var_normalized.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63901cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is torch.Size([4608])\n",
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "raw_within_var_normalized = []\n",
    "for file in activations:\n",
    "    raw_within_var_normalized.append(torch.var(F.normalize(activations[file][:, layer, :], p=2, dim=1), dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var_normalized)} roles, shape is {raw_within_var_normalized[0].shape}\")\n",
    "avg_raw_within_var_normalized = torch.stack(raw_within_var_normalized).mean(dim=0)\n",
    "print(avg_raw_within_var_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cc8b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of raw_across_var_normalized / avg_raw_within_var_normalized is 0.3623166084289551\n"
     ]
    }
   ],
   "source": [
    "raw_ratio_normalized = raw_across_var_normalized.mean() / avg_raw_within_var_normalized.mean()\n",
    "print(f\"ratio of raw_across_var_normalized / avg_raw_within_var_normalized is {raw_ratio_normalized}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f2faa",
   "metadata": {},
   "source": [
    "### in PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0642d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448,)\n"
     ]
    }
   ],
   "source": [
    "# get transformed role vectors\n",
    "pca_across_var = np.var(pca_results['pca_transformed'][:275], axis=0)\n",
    "print(pca_across_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ec04e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1199, 46, 4608])\n"
     ]
    }
   ],
   "source": [
    "print(activations['absurdist'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e550e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is (448,)\n"
     ]
    }
   ],
   "source": [
    "pca_within_var = []\n",
    "pc1_within_var = []\n",
    "for role in activations:\n",
    "    role_scaled = pca_results['scaler'].transform(activations[role][:, layer, :].float().numpy())\n",
    "    role_pca = pca_results['pca'].transform(role_scaled)\n",
    "    pca_within_var.append(np.var(role_pca, axis=0))\n",
    "    pc1_within_var.append(np.var(role_pca[:, 0]))\n",
    "\n",
    "print(f\"for {len(pca_within_var)} roles, shape is {pca_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d4565fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448,)\n"
     ]
    }
   ],
   "source": [
    "mean_pca_within_var = np.array(pca_within_var).mean(axis=0)\n",
    "print(mean_pca_within_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6776cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of pca_across_var / mean_pca_within_var is 0.31411965474791115\n"
     ]
    }
   ],
   "source": [
    "pca_ratio = pca_across_var.mean() / mean_pca_within_var.mean()\n",
    "print(f\"ratio of pca_across_var / mean_pca_within_var is {pca_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffd5cc",
   "metadata": {},
   "source": [
    "### pc1 variance only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77c857e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829.9696483722173\n"
     ]
    }
   ],
   "source": [
    "pc1_across_var = np.var(pca_results['pca_transformed'][:275, 0])\n",
    "print(pc1_across_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc2e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291.39803214992793\n",
      "ratio of pc1_across_var / mean_pc1_within_var is 2.848233539014387\n"
     ]
    }
   ],
   "source": [
    "mean_pc1_within_var = np.array(pc1_within_var).mean()\n",
    "print(mean_pc1_within_var)\n",
    "\n",
    "pc1_ratio = pc1_across_var / mean_pc1_within_var\n",
    "print(f\"ratio of pc1_across_var / mean_pc1_within_var is {pc1_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5eca2",
   "metadata": {},
   "source": [
    "## Conditional variance of role vectors based on distance from Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9db03468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([448, 4608])\n"
     ]
    }
   ],
   "source": [
    "role_vectors = torch.stack(pca_results['vectors']['pos_2'] + pca_results['vectors']['pos_3'])[:, layer, :]\n",
    "print(role_vectors.shape)\n",
    "\n",
    "pc1 = pca_results['pca_transformed'][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dw7pl9twyv",
   "metadata": {},
   "source": [
    "### Conditional variance in raw activation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "191e6z46xkk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RAW ACTIVATION SPACE: Two-Group Comparison\n",
      "============================================================\n",
      "PC1 threshold: 25\n",
      "Assistant-like roles (PC1 < 25): 128 samples\n",
      "Roleplay roles (PC1 >= 25): 320 samples\n",
      "\n",
      "Mean variance (Assistant-like): 54.750000\n",
      "Mean variance (Roleplay): 151.000000\n",
      "Variance ratio (Assistant/Roleplay): 0.3626 (36.26%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Two-group comparison: Assistant-like vs Roleplay\n",
    "# Using PC1 threshold of -25 (same as in 9_cone.ipynb)\n",
    "threshold = 25\n",
    "\n",
    "assistant_mask = pc1 > threshold\n",
    "roleplay_mask = pc1 <= threshold\n",
    "\n",
    "# Compute variance of raw activations for each group\n",
    "# role_vectors shape: [448, 4608]\n",
    "var_assistant_raw = torch.var(role_vectors[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_raw = torch.var(role_vectors[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_raw = var_assistant_raw / var_roleplay_raw\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like roles (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like): {var_assistant_raw:.6f}\")\n",
    "print(f\"Mean variance (Roleplay): {var_roleplay_raw:.6f}\")\n",
    "print(f\"Variance ratio (Assistant/Roleplay): {var_ratio_raw:.4f} ({var_ratio_raw*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "vm23njwgwk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE (PC1 projected out): Two-Group Comparison\n",
      "============================================================\n",
      "PC1 threshold: 25\n",
      "Assistant-like roles (PC1 < 25): 128 samples\n",
      "Roleplay roles (PC1 >= 25): 320 samples\n",
      "\n",
      "Mean variance (Assistant-like, PC1 removed): 54.452919\n",
      "Mean variance (Roleplay, PC1 removed): 138.992462\n",
      "Variance ratio (Assistant/Roleplay): 0.3918 (39.18%)\n",
      "\n",
      "This is analogous to the PC2-10 analysis in PC space.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Project out PC1 from raw activations\n",
    "# Get PC1 direction from PCA\n",
    "pc1_direction = torch.from_numpy(pca_results['pca'].components_[0]).float()\n",
    "\n",
    "# Project role_vectors onto PC1 and subtract\n",
    "# Formula: projection = (v · u) * u, where u is the unit vector (PC1 direction)\n",
    "pc1_loadings = (role_vectors.float() @ pc1_direction).unsqueeze(1)  # Shape: [448, 1]\n",
    "pc1_projections = pc1_loadings * pc1_direction.unsqueeze(0)  # Shape: [448, 4608]\n",
    "role_vectors_pc1_removed = role_vectors - pc1_projections\n",
    "\n",
    "# Compute variance with PC1 projected out\n",
    "var_assistant_raw_no_pc1 = torch.var(role_vectors_pc1_removed[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_raw_no_pc1 = torch.var(role_vectors_pc1_removed[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_raw_no_pc1 = var_assistant_raw_no_pc1 / var_roleplay_raw_no_pc1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE (PC1 projected out): Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like roles (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like, PC1 removed): {var_assistant_raw_no_pc1:.6f}\")\n",
    "print(f\"Mean variance (Roleplay, PC1 removed): {var_roleplay_raw_no_pc1:.6f}\")\n",
    "print(f\"Variance ratio (Assistant/Roleplay): {var_ratio_raw_no_pc1:.4f} ({var_ratio_raw_no_pc1*100:.2f}%)\")\n",
    "print(f\"\\nThis is analogous to the PC2-10 analysis in PC space.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "zv1prpa1y3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE: Quintile Analysis\n",
      "============================================================\n",
      "\n",
      "Quintile 1: PC1 ∈ [-86.47, -33.36]\n",
      "  Sample size: 90\n",
      "  Mean variance (full): 136.000000\n",
      "  Mean variance (PC1 removed): 134.244888\n",
      "\n",
      "Quintile 2: PC1 ∈ [-33.36, -1.06]\n",
      "  Sample size: 89\n",
      "  Mean variance (full): 98.000000\n",
      "  Mean variance (PC1 removed): 96.719231\n",
      "\n",
      "Quintile 3: PC1 ∈ [-1.06, 18.72]\n",
      "  Sample size: 90\n",
      "  Mean variance (full): 69.000000\n",
      "  Mean variance (PC1 removed): 68.681099\n",
      "\n",
      "Quintile 4: PC1 ∈ [18.72, 28.17]\n",
      "  Sample size: 89\n",
      "  Mean variance (full): 53.750000\n",
      "  Mean variance (PC1 removed): 53.688721\n",
      "\n",
      "Quintile 5: PC1 ∈ [28.17, 38.88]\n",
      "  Sample size: 90\n",
      "  Mean variance (full): 53.250000\n",
      "  Mean variance (PC1 removed): 53.227360\n",
      "\n",
      "------------------------------------------------------------\n",
      "Variance ratio (Last/First quintile, full): 2.55x\n",
      "Variance ratio (Last/First quintile, PC1 removed): 2.52x\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Quintile analysis\n",
    "n_quintiles = 5\n",
    "quintile_edges = np.quantile(pc1, np.linspace(0, 1, n_quintiles + 1))\n",
    "quintile_variances = []\n",
    "quintile_variances_no_pc1 = []\n",
    "quintile_sizes = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Quintile Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(n_quintiles):\n",
    "    if i == 0:\n",
    "        mask = (pc1 >= quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    else:\n",
    "        mask = (pc1 > quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    \n",
    "    quintile_var = torch.var(role_vectors[mask], dim=0).mean().item()\n",
    "    quintile_var_no_pc1 = torch.var(role_vectors_pc1_removed[mask], dim=0).mean().item()\n",
    "    quintile_variances.append(quintile_var)\n",
    "    quintile_variances_no_pc1.append(quintile_var_no_pc1)\n",
    "    quintile_sizes.append(mask.sum())\n",
    "    \n",
    "    print(f\"\\nQuintile {i+1}: PC1 ∈ [{quintile_edges[i]:.2f}, {quintile_edges[i+1]:.2f}]\")\n",
    "    print(f\"  Sample size: {mask.sum()}\")\n",
    "    print(f\"  Mean variance (full): {quintile_var:.6f}\")\n",
    "    print(f\"  Mean variance (PC1 removed): {quintile_var_no_pc1:.6f}\")\n",
    "\n",
    "# Calculate ratios between first and last quintile\n",
    "quintile_ratio = quintile_variances[0] / quintile_variances[-1]\n",
    "quintile_ratio_no_pc1 = quintile_variances_no_pc1[0] / quintile_variances_no_pc1[-1]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(f\"Variance ratio (Last/First quintile, full): {quintile_ratio:.2f}x\")\n",
    "print(f\"Variance ratio (Last/First quintile, PC1 removed): {quintile_ratio_no_pc1:.2f}x\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7kwaevse0w",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE: Distance from Center Correlation\n",
      "============================================================\n",
      "Correlation between PC1 and L2 distance from mean (full):\n",
      "  r = -0.5635\n",
      "  p-value = 6.652e-39\n",
      "  Highly significant (p < 0.001)\n",
      "\n",
      "Correlation between PC1 and L2 distance from mean (PC1 removed):\n",
      "  r = -0.5441\n",
      "  p-value = 7.002e-36\n",
      "  Highly significant (p < 0.001)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Distance from center correlation\n",
    "# Compute mean of raw activations\n",
    "role_vectors_mean = role_vectors.mean(dim=0)\n",
    "role_vectors_pc1_removed_mean = role_vectors_pc1_removed.mean(dim=0)\n",
    "\n",
    "# Compute L2 distance from mean for each role\n",
    "distances_raw = torch.norm(role_vectors.float() - role_vectors_mean, p=2, dim=1).numpy()\n",
    "distances_raw_no_pc1 = torch.norm(role_vectors_pc1_removed - role_vectors_pc1_removed_mean, p=2, dim=1).numpy()\n",
    "\n",
    "# Calculate correlation with PC1\n",
    "correlation_raw, p_value_raw = pearsonr(pc1, distances_raw)\n",
    "correlation_raw_no_pc1, p_value_raw_no_pc1 = pearsonr(pc1, distances_raw_no_pc1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Distance from Center Correlation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Correlation between PC1 and L2 distance from mean (full):\")\n",
    "print(f\"  r = {correlation_raw:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw:.3e}\")\n",
    "if p_value_raw < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "\n",
    "print(f\"\\nCorrelation between PC1 and L2 distance from mean (PC1 removed):\")\n",
    "print(f\"  r = {correlation_raw_no_pc1:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw_no_pc1:.3e}\")\n",
    "if p_value_raw_no_pc1 < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw_no_pc1 < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lsye2ajp11",
   "metadata": {},
   "source": [
    "### Per-PC analysis: Correlation between each PC and distance in remaining PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0tedpgpspjp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Correlation between each PC and distance in remaining PC space\n",
      "======================================================================\n",
      "PC 1: r = -0.6576, p = 7.913e-57 ***\n",
      "PC 2: r =  0.2100, p = 7.342e-06 ***\n",
      "PC 3: r =  0.3147, p = 9.348e-12 ***\n",
      "PC 4: r =  0.0543, p = 2.516e-01 \n",
      "PC 5: r = -0.2252, p = 1.468e-06 ***\n",
      "PC 6: r = -0.2385, p = 3.258e-07 ***\n",
      "PC 7: r =  0.0882, p = 6.229e-02 \n",
      "PC 8: r =  0.0283, p = 5.500e-01 \n",
      "PC 9: r = -0.0532, p = 2.616e-01 \n",
      "PC10: r =  0.0580, p = 2.208e-01 \n",
      "======================================================================\n",
      "\n",
      "PC1 correlation: -0.6576\n",
      "Mean correlation (PC2-10): 0.0263\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each of the top 10 PCs, calculate:\n",
    "# 1. The correlation between that PC and distance from center in all OTHER PCs\n",
    "# 2. This tells us if the pattern we see with PC1 generalizes to other PCs\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "n_pcs_to_analyze = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Correlation between each PC and distance in remaining PC space\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "correlations = []\n",
    "p_values = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_analyze):\n",
    "    # Get the PC values\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get all other PCs (excluding current PC)\n",
    "    other_pcs = np.delete(pca_transformed, pc_idx, axis=1)\n",
    "    \n",
    "    # Calculate distance from center in the remaining PC space\n",
    "    other_pcs_mean = other_pcs.mean(axis=0)\n",
    "    distances = np.linalg.norm(other_pcs - other_pcs_mean, axis=1)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr, p_val = pearsonr(pc_values, distances)\n",
    "    correlations.append(corr)\n",
    "    p_values.append(p_val)\n",
    "    \n",
    "    # Print results\n",
    "    sig_marker = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n",
    "    print(f\"PC{pc_idx+1:2d}: r = {corr:7.4f}, p = {p_val:.3e} {sig_marker}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPC1 correlation: {correlations[0]:.4f}\")\n",
    "print(f\"Mean correlation (PC2-10): {np.mean(correlations[1:]):.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4w4stk4a567",
   "metadata": {},
   "source": [
    "### Conditional variance in PC2-10 based on position along each PC\n",
    "\n",
    "This analysis shows whether the pattern of \"extreme positions → high variance in other PCs\" is unique to PC1 or generalizes to other PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "x42qo16zp6k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Conditional Variance in PC2-10 based on position along each PC\n",
      "================================================================================\n",
      "For each PC, we split roles by median and compute variance in PC2-10 (excluding that PC)\n",
      "--------------------------------------------------------------------------------\n",
      "PC 1: High=224 samples, Low=224 samples\n",
      "      Var(high) =   99.655, Var(low) =  303.220, Ratio = 3.043\n",
      "PC 2: High=224 samples, Low=224 samples\n",
      "      Var(high) =  230.203, Var(low) =  130.662, Ratio = 1.762\n",
      "PC 3: High=224 samples, Low=224 samples\n",
      "      Var(high) =  211.142, Var(low) =  164.985, Ratio = 1.280\n",
      "PC 4: High=224 samples, Low=224 samples\n",
      "      Var(high) =  179.438, Var(low) =  214.903, Ratio = 1.198\n",
      "PC 5: High=224 samples, Low=224 samples\n",
      "      Var(high) =  157.295, Var(low) =  247.421, Ratio = 1.573\n",
      "PC 6: High=224 samples, Low=224 samples\n",
      "      Var(high) =  195.218, Var(low) =  209.086, Ratio = 1.071\n",
      "PC 7: High=224 samples, Low=224 samples\n",
      "      Var(high) =  234.147, Var(low) =  181.103, Ratio = 1.293\n",
      "PC 8: High=224 samples, Low=224 samples\n",
      "      Var(high) =  200.367, Var(low) =  223.138, Ratio = 1.114\n",
      "PC 9: High=224 samples, Low=224 samples\n",
      "      Var(high) =  238.866, Var(low) =  190.133, Ratio = 1.256\n",
      "PC10: High=224 samples, Low=224 samples\n",
      "      Var(high) =  209.329, Var(low) =  223.313, Ratio = 1.067\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "  PC1 variance ratio: 3.043\n",
      "  Mean variance ratio for PC2-10: 1.290\n",
      "  Max variance ratio (excluding PC1): 1.762 (PC2)\n",
      "\n",
      "  → Shows whether PC1 is unique in having high-variance 'other dimensions' for extreme positions\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each PC, split roles into two groups (high/low) and compute variance in PC2-10 (excluding that PC)\n",
    "# This tests if extreme positions on PC_i lead to high variance in other PCs\n",
    "\n",
    "n_pcs_to_test = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Conditional Variance in PC2-10 based on position along each PC\")\n",
    "print(\"=\" * 80)\n",
    "print(\"For each PC, we split roles by median and compute variance in PC2-10 (excluding that PC)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "variance_ratios = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_test):\n",
    "    # Split by median on this PC\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    median_val = np.median(pc_values)\n",
    "    high_mask = pc_values > median_val\n",
    "    low_mask = pc_values <= median_val\n",
    "    \n",
    "    # Get PC2-10, excluding current PC if it's in that range\n",
    "    if pc_idx == 0:\n",
    "        # For PC1, we want variance in PC2-10\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    elif 1 <= pc_idx < 10:\n",
    "        # For PC2-9, exclude that PC from PC2-10\n",
    "        pc_indices = [i for i in range(1, 10) if i != pc_idx]\n",
    "        other_pcs = pca_transformed[:, pc_indices]\n",
    "    else:\n",
    "        # For PC10, use PC2-9\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    \n",
    "    # Compute variance for each group\n",
    "    var_high = np.var(other_pcs[high_mask], axis=0).mean()\n",
    "    var_low = np.var(other_pcs[low_mask], axis=0).mean()\n",
    "    \n",
    "    ratio = max(var_high, var_low) / min(var_high, var_low)\n",
    "    variance_ratios.append(ratio)\n",
    "    \n",
    "    print(f\"PC{pc_idx+1:2d}: High={high_mask.sum():3d} samples, Low={low_mask.sum():3d} samples\")\n",
    "    print(f\"      Var(high) = {var_high:8.3f}, Var(low) = {var_low:8.3f}, Ratio = {ratio:.3f}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  PC1 variance ratio: {variance_ratios[0]:.3f}\")\n",
    "print(f\"  Mean variance ratio for PC2-10: {np.mean(variance_ratios[1:]):.3f}\")\n",
    "print(f\"  Max variance ratio (excluding PC1): {np.max(variance_ratios[1:]):.3f} (PC{np.argmax(variance_ratios[1:])+2})\")\n",
    "print(\"\\n  → Shows whether PC1 is unique in having high-variance 'other dimensions' for extreme positions\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "psa4fpzrfl8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total roles: 448\n",
      "pca_transformed shape: (448, 448)\n"
     ]
    }
   ],
   "source": [
    "# Create role labels from pca_results\n",
    "def get_role_labels_from_pca(pca_results):\n",
    "    labels = []\n",
    "    if 'pos_2' in pca_results['roles'].keys():\n",
    "        pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "        labels.extend(pos_2_roles)\n",
    "    if 'pos_3' in pca_results['roles'].keys():\n",
    "        pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "        labels.extend(pos_3_roles)\n",
    "    return labels\n",
    "\n",
    "role_labels = get_role_labels_from_pca(pca_results)\n",
    "print(f\"Total roles: {len(role_labels)}\")\n",
    "print(f\"pca_transformed shape: {pca_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0ogly4i9nk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Top and Bottom Roles for Each PC\n",
      "================================================================================\n",
      "\n",
      "PC1:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Assistant                      (PC1 =   38.88)\n",
      "    2. Screener                       (PC1 =   38.71)\n",
      "    3. Doctor                         (PC1 =   37.75)\n",
      "    4. Analyst                        (PC1 =   36.68)\n",
      "    5. Researcher                     (PC1 =   36.55)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Caveman                        (PC1 =  -86.47)\n",
      "    2. Eldritch                       (PC1 =  -79.26)\n",
      "    3. Leviathan                      (PC1 =  -79.20)\n",
      "    4. Void                           (PC1 =  -74.09)\n",
      "    5. Aberration                     (PC1 =  -69.96)\n",
      "\n",
      "PC2:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Procrastinator                 (PC2 =   89.66)\n",
      "    2. Teenager                       (PC2 =   79.36)\n",
      "    3. Adolescent                     (PC2 =   77.52)\n",
      "    4. Toddler                        (PC2 =   61.69)\n",
      "    5. Gossip                         (PC2 =   52.68)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Eldritch                       (PC2 =  -57.07)\n",
      "    2. Leviathan                      (PC2 =  -45.70)\n",
      "    3. Crystalline                    (PC2 =  -45.51)\n",
      "    4. Oracle                         (PC2 =  -45.07)\n",
      "    5. Tree                           (PC2 =  -44.90)\n",
      "\n",
      "PC3:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Infant                         (PC3 =  109.26)\n",
      "    2. Toddler                        (PC3 =   86.59)\n",
      "    3. Caveman                        (PC3 =   65.89)\n",
      "    4. Void                           (PC3 =   50.69)\n",
      "    5. Virus                          (PC3 =   46.99)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Advocate                       (PC3 =  -34.64)\n",
      "    2. Visionary                      (PC3 =  -34.56)\n",
      "    3. Activist                       (PC3 =  -30.61)\n",
      "    4. Evangelist                     (PC3 =  -29.54)\n",
      "    5. Blogger                        (PC3 =  -29.49)\n",
      "\n",
      "PC4:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Narcissist                     (PC4 =   65.85)\n",
      "    2. Workaholic                     (PC4 =   65.40)\n",
      "    3. Cynic                          (PC4 =   61.07)\n",
      "    4. Provocateur                    (PC4 =   56.77)\n",
      "    5. Zealot                         (PC4 =   56.64)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Toddler                        (PC4 =  -45.79)\n",
      "    2. Caveman                        (PC4 =  -39.21)\n",
      "    3. Fool                           (PC4 =  -34.92)\n",
      "    4. Grandparent                    (PC4 =  -34.69)\n",
      "    5. Infant                         (PC4 =  -33.07)\n",
      "\n",
      "PC5:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Gamer                          (PC5 =   60.55)\n",
      "    2. Mechanic                       (PC5 =   43.87)\n",
      "    3. Hacker                         (PC5 =   40.12)\n",
      "    4. Surfer                         (PC5 =   39.51)\n",
      "    5. Smuggler                       (PC5 =   36.67)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Interviewer                    (PC5 =  -38.57)\n",
      "    2. Toddler                        (PC5 =  -32.91)\n",
      "    3. Counselor                      (PC5 =  -32.42)\n",
      "    4. Therapist                      (PC5 =  -29.73)\n",
      "    5. Moderator                      (PC5 =  -29.38)\n",
      "\n",
      "PC6:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Addict                         (PC6 =   26.33)\n",
      "    2. Prisoner                       (PC6 =   26.09)\n",
      "    3. Widow                          (PC6 =   25.94)\n",
      "    4. Divorcee                       (PC6 =   24.74)\n",
      "    5. Empath                         (PC6 =   24.24)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Toddler                        (PC6 = -106.46)\n",
      "    2. Infant                         (PC6 =  -96.66)\n",
      "    3. Caveman                        (PC6 =  -81.88)\n",
      "    4. Fool                           (PC6 =  -52.08)\n",
      "    5. Robot                          (PC6 =  -39.42)\n",
      "\n",
      "PC7:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Caveman                        (PC7 =   64.64)\n",
      "    2. Traditionalist                 (PC7 =   42.02)\n",
      "    3. Infant                         (PC7 =   39.22)\n",
      "    4. Zealot                         (PC7 =   38.83)\n",
      "    5. Workaholic                     (PC7 =   36.97)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Jester                         (PC7 =  -57.46)\n",
      "    2. Comedian                       (PC7 =  -57.39)\n",
      "    3. Absurdist                      (PC7 =  -54.89)\n",
      "    4. Trickster                      (PC7 =  -45.02)\n",
      "    5. Jester                         (PC7 =  -42.51)\n",
      "\n",
      "PC8:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Prisoner                       (PC8 =   41.61)\n",
      "    2. Exile                          (PC8 =   38.61)\n",
      "    3. Criminal                       (PC8 =   34.44)\n",
      "    4. Refugee                        (PC8 =   34.09)\n",
      "    5. Addict                         (PC8 =   31.69)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Zealot                         (PC8 =  -33.48)\n",
      "    2. Narcissist                     (PC8 =  -32.83)\n",
      "    3. Optimist                       (PC8 =  -30.38)\n",
      "    4. Gamer                          (PC8 =  -28.83)\n",
      "    5. Hedonist                       (PC8 =  -28.03)\n",
      "\n",
      "PC9:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Infant                         (PC9 =   39.31)\n",
      "    2. Toddler                        (PC9 =   30.55)\n",
      "    3. Simulacrum                     (PC9 =   25.18)\n",
      "    4. Hybrid                         (PC9 =   23.92)\n",
      "    5. Crystalline                    (PC9 =   23.15)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Caveman                        (PC9 =  -43.20)\n",
      "    2. Pirate                         (PC9 =  -31.84)\n",
      "    3. Interviewer                    (PC9 =  -30.48)\n",
      "    4. Zealot                         (PC9 =  -28.52)\n",
      "    5. Smuggler                       (PC9 =  -25.26)\n",
      "\n",
      "PC10:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Luddite                        (PC10 =   46.93)\n",
      "    2. Zealot                         (PC10 =   30.80)\n",
      "    3. Jester                         (PC10 =   30.55)\n",
      "    4. Absurdist                      (PC10 =   30.40)\n",
      "    5. Comedian                       (PC10 =   30.29)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Interviewer                    (PC10 =  -30.67)\n",
      "    2. Predator                       (PC10 =  -24.99)\n",
      "    3. Competitor                     (PC10 =  -24.44)\n",
      "    4. Fixer                          (PC10 =  -22.71)\n",
      "    5. Fixer                          (PC10 =  -22.40)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Show top/bottom roles for each PC\n",
    "n_pcs_to_show = 10  # Show first 5 PCs\n",
    "n_roles_to_show = 5  # Show top/bottom 5 roles\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Top and Bottom Roles for Each PC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pc_idx in range(n_pcs_to_show):\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get indices of top and bottom roles\n",
    "    top_indices = np.argsort(pc_values)[-n_roles_to_show:][::-1]\n",
    "    bottom_indices = np.argsort(pc_values)[:n_roles_to_show]\n",
    "    \n",
    "    print(f\"\\nPC{pc_idx+1}:\")\n",
    "    print(f\"  Top {n_roles_to_show} (highest loadings):\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "    \n",
    "    print(f\"  Bottom {n_roles_to_show} (lowest loadings):\")\n",
    "    for i, idx in enumerate(bottom_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0108b",
   "metadata": {},
   "source": [
    "## Default loading along each PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20166672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant projection shape: (1, 448)\n",
      "\n",
      "================================================================================\n",
      "Assistant (default) position relative to role distribution on each PC\n",
      "================================================================================\n",
      "\n",
      "PC1:\n",
      "  Range: [  -86.47,    38.88]\n",
      "  Assistant:    34.72\n",
      "  Relative position: 0.967 (0=min, 1=max)\n",
      "  Min boundary distance: 0.033\n",
      "  Position: near maximum\n",
      "\n",
      "PC2:\n",
      "  Range: [  -57.07,    89.66]\n",
      "  Assistant:    -3.73\n",
      "  Relative position: 0.364 (0=min, 1=max)\n",
      "  Min boundary distance: 0.364\n",
      "  Position: below center\n",
      "\n",
      "PC3:\n",
      "  Range: [  -34.64,   109.26]\n",
      "  Assistant:     1.94\n",
      "  Relative position: 0.254 (0=min, 1=max)\n",
      "  Min boundary distance: 0.254\n",
      "  Position: below center\n",
      "\n",
      "PC4:\n",
      "  Range: [  -45.79,    65.85]\n",
      "  Assistant:    -0.14\n",
      "  Relative position: 0.409 (0=min, 1=max)\n",
      "  Min boundary distance: 0.409\n",
      "  Position: below center\n",
      "\n",
      "PC5:\n",
      "  Range: [  -38.57,    60.55]\n",
      "  Assistant:    -9.77\n",
      "  Relative position: 0.291 (0=min, 1=max)\n",
      "  Min boundary distance: 0.291\n",
      "  Position: below center\n",
      "\n",
      "PC6:\n",
      "  Range: [ -106.46,    26.33]\n",
      "  Assistant:    -1.42\n",
      "  Relative position: 0.791 (0=min, 1=max)\n",
      "  Min boundary distance: 0.209\n",
      "  Position: near maximum\n",
      "\n",
      "PC7:\n",
      "  Range: [  -57.46,    64.64]\n",
      "  Assistant:     0.56\n",
      "  Relative position: 0.475 (0=min, 1=max)\n",
      "  Min boundary distance: 0.475\n",
      "  Position: centered\n",
      "\n",
      "PC8:\n",
      "  Range: [  -33.48,    41.61]\n",
      "  Assistant:    13.95\n",
      "  Relative position: 0.632 (0=min, 1=max)\n",
      "  Min boundary distance: 0.368\n",
      "  Position: above center\n",
      "\n",
      "PC9:\n",
      "  Range: [  -43.20,    39.31]\n",
      "  Assistant:    -4.20\n",
      "  Relative position: 0.473 (0=min, 1=max)\n",
      "  Min boundary distance: 0.473\n",
      "  Position: centered\n",
      "\n",
      "PC10:\n",
      "  Range: [  -30.67,    46.93]\n",
      "  Assistant:     8.47\n",
      "  Relative position: 0.504 (0=min, 1=max)\n",
      "  Min boundary distance: 0.496\n",
      "  Position: centered\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# get default activation and project\n",
    "default_vectors = torch.load(f\"{base_dir}/roles_240/default_vectors.pt\")\n",
    "assistant_layer_activation = default_vectors['activations']['default_1'][layer, :].float().reshape(1, -1)\n",
    "\n",
    "asst_scaled = pca_results['scaler'].transform(assistant_layer_activation.numpy())\n",
    "asst_projected = pca_results['pca'].transform(asst_scaled)\n",
    "print(f\"Assistant projection shape: {asst_projected.shape}\")\n",
    "\n",
    "# Compare each PC loading with the min, max loading of that PC across all roles\n",
    "n_pcs = 10  # or however many you want to analyze\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Assistant (default) position relative to role distribution on each PC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pc_idx in range(n_pcs):\n",
    "    # Get assistant's loading on this PC\n",
    "    asst_loading = asst_projected[0, pc_idx]\n",
    "    \n",
    "    # Get all role loadings on this PC\n",
    "    all_loadings = pca_transformed[:, pc_idx]\n",
    "    min_loading = all_loadings.min()\n",
    "    max_loading = all_loadings.max()\n",
    "    \n",
    "    # Calculate relative position (0 = at min, 1 = at max)\n",
    "    if max_loading != min_loading:\n",
    "        relative_position = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    else:\n",
    "        relative_position = 0.5\n",
    "    \n",
    "    # Distance to nearest boundary (normalized)\n",
    "    dist_to_min = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    dist_to_max = (max_loading - asst_loading) / (max_loading - min_loading)\n",
    "    min_boundary_dist = min(dist_to_min, dist_to_max)\n",
    "    \n",
    "    print(f\"\\nPC{pc_idx+1}:\")\n",
    "    print(f\"  Range: [{min_loading:8.2f}, {max_loading:8.2f}]\")\n",
    "    print(f\"  Assistant: {asst_loading:8.2f}\")\n",
    "    print(f\"  Relative position: {relative_position:.3f} (0=min, 1=max)\")\n",
    "    print(f\"  Min boundary distance: {min_boundary_dist:.3f}\")\n",
    "    \n",
    "    # Interpret position\n",
    "    if relative_position < 0.25:\n",
    "        position_desc = \"near minimum\"\n",
    "    elif relative_position < 0.45:\n",
    "        position_desc = \"below center\"\n",
    "    elif relative_position < 0.55:\n",
    "        position_desc = \"centered\"\n",
    "    elif relative_position < 0.75:\n",
    "        position_desc = \"above center\"\n",
    "    else:\n",
    "        position_desc = \"near maximum\"\n",
    "    print(f\"  Position: {position_desc}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669f17e",
   "metadata": {},
   "source": [
    "## Overall activation variance captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd47d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['activations', 'target_layer'])\n",
      "dict_keys(['projected', 'explained_variance_ratio', 'pca_n_components', 'pca_explained_variance_from_fit', 'target_layer', 'pca_config_path'])\n",
      "dict_keys(['projected', 'explained_variance_ratio', 'pca_n_components', 'pca_explained_variance_from_fit', 'target_layer', 'pca_config_path'])\n"
     ]
    }
   ],
   "source": [
    "# load in the mean_activations.pt and the role/trait projections...\n",
    "\n",
    "act_dir = f\"/workspace/{model_name}/dataset_activations/lmsys_10000\"\n",
    "\n",
    "chat_raw = torch.load(f\"{act_dir}/mean_activations.pt\")\n",
    "chat_roles = torch.load(f\"{act_dir}/roles_projections.pt\", weights_only=False)\n",
    "chat_traits = torch.load(f\"{act_dir}/traits_projections.pt\", weights_only=False)\n",
    "\n",
    "print(chat_raw.keys())\n",
    "print(chat_roles.keys())\n",
    "print(chat_traits.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d1a2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw activations shape: torch.Size([18777, 4608])\n",
      "\n",
      "Total variance in raw activations: 7442113.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Role subspace:\n",
      "  Variance captured: 1283001.00\n",
      "  Variance explained: 0.1724 (17.24%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait subspace:\n",
      "  Variance captured: 1234600.38\n",
      "  Variance explained: 0.1659 (16.59%)\n",
      "\n",
      "============================================================\n",
      "Summary: Variance Explained by Subspaces\n",
      "============================================================\n",
      "Role subspace:  17.24%\n",
      "Trait subspace: 16.59%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Get the raw activations\n",
    "raw_activations = chat_raw['activations'][:, layer, :].float()\n",
    "print(f\"Raw activations shape: {raw_activations.shape}\")\n",
    "\n",
    "# Calculate total variance in raw activations\n",
    "total_var = torch.var(raw_activations, dim=0).sum().item()\n",
    "print(f\"\\nTotal variance in raw activations: {total_var:.2f}\")\n",
    "\n",
    "# For roles: reconstruct from PCA space back to raw space\n",
    "roles_projected = chat_roles['projected']  # Shape: [18950, 463]\n",
    "# Inverse transform: unstandardize and inverse PCA\n",
    "roles_reconstructed = pca_results['pca'].inverse_transform(roles_projected)  # This gives standardized features\n",
    "roles_reconstructed = pca_results['scaler'].inverse_transform(roles_reconstructed)  # Unstandardize\n",
    "roles_reconstructed = torch.from_numpy(roles_reconstructed).float()\n",
    "\n",
    "# Calculate variance in reconstructed activations\n",
    "roles_var = torch.var(roles_reconstructed, dim=0).sum().item()\n",
    "roles_variance_explained = roles_var / total_var\n",
    "\n",
    "print(f\"\\nRole subspace:\")\n",
    "print(f\"  Variance captured: {roles_var:.2f}\")\n",
    "print(f\"  Variance explained: {roles_variance_explained:.4f} ({roles_variance_explained*100:.2f}%)\")\n",
    "\n",
    "# For traits: load trait PCA results and do the same\n",
    "trait_pca_results = torch.load(f\"{base_dir}/traits_240/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n",
    "traits_projected = chat_traits['projected']  # Shape: [18950, 240]\n",
    "\n",
    "traits_reconstructed = trait_pca_results['pca'].inverse_transform(traits_projected)\n",
    "traits_reconstructed = trait_pca_results['scaler'].inverse_transform(traits_reconstructed)\n",
    "traits_reconstructed = torch.from_numpy(traits_reconstructed).float()\n",
    "\n",
    "# Calculate variance in reconstructed activations\n",
    "traits_var = torch.var(traits_reconstructed, dim=0).sum().item()\n",
    "traits_variance_explained = traits_var / total_var\n",
    "\n",
    "print(f\"\\nTrait subspace:\")\n",
    "print(f\"  Variance captured: {traits_var:.2f}\")\n",
    "print(f\"  Variance explained: {traits_variance_explained:.4f} ({traits_variance_explained*100:.2f}%)\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary: Variance Explained by Subspaces\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Role subspace:  {roles_variance_explained*100:.2f}%\")\n",
    "print(f\"Trait subspace: {traits_variance_explained*100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3pk6ipumh22",
   "metadata": {},
   "source": [
    "## Individual model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0pec8iqx20qe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving variance analysis results to ./results/\n",
      "Timestamp: 2025-10-22T04:40:08.135757\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Configuration for saving\n",
    "outdir = \"./results\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# Get current timestamp\n",
    "timestamp = datetime.now().isoformat()\n",
    "\n",
    "print(f\"Saving variance analysis results to {outdir}/\")\n",
    "print(f\"Timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3mzx2uw37it",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built per-model variance analysis data structure\n"
     ]
    }
   ],
   "source": [
    "# Build the per-model variance analysis JSON structure\n",
    "\n",
    "# Build quintile data\n",
    "quintiles_data = []\n",
    "for i in range(len(quintile_edges) - 1):\n",
    "    quintiles_data.append({\n",
    "        \"quintile\": i + 1,\n",
    "        \"pc1_range\": [float(quintile_edges[i]), float(quintile_edges[i + 1])],\n",
    "        \"n_samples\": int(quintile_sizes[i]),\n",
    "        \"variance_full\": float(quintile_variances[i]),\n",
    "        \"variance_pc1_removed\": float(quintile_variances_no_pc1[i])\n",
    "    })\n",
    "\n",
    "# Build PC distance correlations\n",
    "pc_distance_corrs = []\n",
    "for i in range(len(correlations)):\n",
    "    pc_distance_corrs.append({\n",
    "        \"pc\": i + 1,\n",
    "        \"r\": float(correlations[i]),\n",
    "        \"p_value\": float(p_values[i]),\n",
    "        \"significant\": bool(p_values[i] < 0.05)\n",
    "    })\n",
    "\n",
    "# Build conditional variance by PC\n",
    "cond_var_by_pc = []\n",
    "for i in range(len(variance_ratios)):\n",
    "    cond_var_by_pc.append({\n",
    "        \"pc\": i + 1,\n",
    "        \"ratio\": float(variance_ratios[i])\n",
    "    })\n",
    "\n",
    "# Build default PC loading data\n",
    "pc_positions = []\n",
    "centered_pcs = []\n",
    "extreme_pcs = []\n",
    "\n",
    "for pc_idx in range(n_pcs):\n",
    "    asst_loading = asst_projected[0, pc_idx]\n",
    "    all_loadings = pca_transformed[:, pc_idx]\n",
    "    min_loading = all_loadings.min()\n",
    "    max_loading = all_loadings.max()\n",
    "\n",
    "    if max_loading != min_loading:\n",
    "        relative_position = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    else:\n",
    "        relative_position = 0.5\n",
    "\n",
    "    dist_to_min = relative_position\n",
    "    dist_to_max = 1.0 - relative_position\n",
    "    min_boundary_dist = min(dist_to_min, dist_to_max)\n",
    "\n",
    "    if relative_position < 0.25:\n",
    "        position_desc = \"near minimum\"\n",
    "        extreme_pcs.append(pc_idx + 1)\n",
    "    elif relative_position < 0.45:\n",
    "        position_desc = \"below center\"\n",
    "    elif relative_position < 0.55:\n",
    "        position_desc = \"centered\"\n",
    "        centered_pcs.append(pc_idx + 1)\n",
    "    elif relative_position < 0.75:\n",
    "        position_desc = \"above center\"\n",
    "    else:\n",
    "        position_desc = \"near maximum\"\n",
    "        extreme_pcs.append(pc_idx + 1)\n",
    "\n",
    "    pc_positions.append({\n",
    "        \"pc\": pc_idx + 1,\n",
    "        \"assistant_loading\": float(asst_loading),\n",
    "        \"role_range_min\": float(min_loading),\n",
    "        \"role_range_max\": float(max_loading),\n",
    "        \"relative_position\": float(relative_position),\n",
    "        \"min_boundary_distance\": float(min_boundary_dist),\n",
    "        \"position_category\": position_desc\n",
    "    })\n",
    "\n",
    "# Build the complete JSON structure\n",
    "model_variance_data = {\n",
    "    \"model_name\": model_name,\n",
    "    \"layer\": layer,\n",
    "    \"hidden_dim\": vectors.shape[1],\n",
    "    \"n_roles\": len(activations),\n",
    "    \"n_role_samples\": role_vectors.shape[0],\n",
    "    \"timestamp\": timestamp,\n",
    "    \"analysis_version\": \"1.0\",\n",
    "\n",
    "    \"across_within_role_var\": {\n",
    "        \"raw_activations\": {\n",
    "            \"across_var_mean\": float(raw_across_var.mean().item()),\n",
    "            \"within_var_mean\": float(avg_raw_within_var.mean().item()),\n",
    "            \"ratio\": float(raw_ratio)\n",
    "        },\n",
    "        \"raw_activations_normalized\": {\n",
    "            \"across_var_mean\": float(raw_across_var_normalized.mean().item()),\n",
    "            \"within_var_mean\": float(avg_raw_within_var_normalized.mean().item()),\n",
    "            \"ratio\": float(raw_ratio_normalized)\n",
    "        },\n",
    "        \"pca_space_all_components\": {\n",
    "            \"across_var_mean\": float(pca_across_var.mean()),\n",
    "            \"within_var_mean\": float(mean_pca_within_var.mean()),\n",
    "            \"ratio\": float(pca_ratio),\n",
    "            \"n_components\": int(len(pca_across_var))\n",
    "        },\n",
    "        \"pc1_only\": {\n",
    "            \"across_var\": float(pc1_across_var),\n",
    "            \"within_var_mean\": float(mean_pc1_within_var),\n",
    "            \"ratio\": float(pc1_ratio)\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"conditional_var_roles\": {\n",
    "        \"threshold_analysis\": {\n",
    "            \"pc1_threshold\": threshold,\n",
    "            \"assistant_like\": {\n",
    "                \"mask\": f\"pc1 < {threshold}\",\n",
    "                \"n_samples\": int(assistant_mask.sum()),\n",
    "                \"variance_raw\": float(var_assistant_raw),\n",
    "                \"variance_raw_pc1_removed\": float(var_assistant_raw_no_pc1)\n",
    "            },\n",
    "            \"roleplay\": {\n",
    "                \"mask\": f\"pc1 >= {threshold}\",\n",
    "                \"n_samples\": int(roleplay_mask.sum()),\n",
    "                \"variance_raw\": float(var_roleplay_raw),\n",
    "                \"variance_raw_pc1_removed\": float(var_roleplay_raw_no_pc1)\n",
    "            },\n",
    "            \"variance_ratio_raw\": float(var_ratio_raw),\n",
    "            \"variance_ratio_raw_pc1_removed\": float(var_ratio_raw_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"quintile_analysis\": {\n",
    "            \"n_quintiles\": 5,\n",
    "            \"quintiles\": quintiles_data,\n",
    "            \"variance_ratio_first_to_last_full\": float(quintile_ratio),\n",
    "            \"variance_ratio_first_to_last_pc1_removed\": float(quintile_ratio_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"distance_correlation\": {\n",
    "            \"full_space\": {\n",
    "                \"correlation\": float(correlation_raw),\n",
    "                \"p_value\": float(p_value_raw),\n",
    "                \"significant\": bool(p_value_raw < 0.05)\n",
    "            },\n",
    "            \"pc1_removed\": {\n",
    "                \"correlation\": float(correlation_raw_no_pc1),\n",
    "                \"p_value\": float(p_value_raw_no_pc1),\n",
    "                \"significant\": bool(p_value_raw_no_pc1 < 0.05)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"high_var_pc_correlation\": {\n",
    "        \"pc_distance_correlations\": {\n",
    "            \"description\": \"Correlation between each PC and distance in remaining PC space\",\n",
    "            \"n_pcs_analyzed\": 10,\n",
    "            \"correlations\": pc_distance_corrs,\n",
    "            \"pc1_correlation\": float(correlations[0]),\n",
    "            \"mean_correlation_pc2_to_10\": float(np.mean(correlations[1:]))\n",
    "        },\n",
    "\n",
    "        \"conditional_variance_by_pc\": {\n",
    "            \"description\": \"Variance in PC2-10 conditioned on high/low position along each PC\",\n",
    "            \"n_pcs_analyzed\": 10,\n",
    "            \"variance_ratios\": cond_var_by_pc,\n",
    "            \"pc1_variance_ratio\": float(variance_ratios[0]),\n",
    "            \"mean_variance_ratio_pc2_to_10\": float(np.mean(variance_ratios[1:])),\n",
    "            \"max_variance_ratio_excluding_pc1\": float(np.max(variance_ratios[1:])),\n",
    "            \"max_variance_ratio_pc\": int(np.argmax(variance_ratios[1:]) + 2)\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"default_pc_loading\": {\n",
    "        \"description\": \"Position of default assistant activation relative to role distribution on each PC\",\n",
    "        \"n_pcs_analyzed\": n_pcs,\n",
    "        \"pc_positions\": pc_positions,\n",
    "        \"summary\": {\n",
    "            \"pc1_position\": pc_positions[0][\"position_category\"],\n",
    "            \"pc1_relative_position\": pc_positions[0][\"relative_position\"],\n",
    "            \"centered_pcs\": centered_pcs,\n",
    "            \"extreme_pcs\": extreme_pcs\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"overall_activation_var\": {\n",
    "        \"description\": \"Variance in chat dataset activations explained by role and trait subspaces\",\n",
    "        \"dataset\": {\n",
    "            \"name\": \"lmsys_10000\",\n",
    "            \"n_samples\": int(raw_activations.shape[0]),\n",
    "            \"source_path\": act_dir\n",
    "        },\n",
    "        \"total_variance\": float(total_var),\n",
    "        \"role_subspace\": {\n",
    "            \"n_components\": int(roles_projected.shape[1]),\n",
    "            \"variance_captured\": float(roles_var),\n",
    "            \"variance_explained_ratio\": float(roles_variance_explained),\n",
    "            \"variance_explained_percent\": float(roles_variance_explained * 100)\n",
    "        },\n",
    "        \"trait_subspace\": {\n",
    "            \"n_components\": int(traits_projected.shape[1]),\n",
    "            \"variance_captured\": float(traits_var),\n",
    "            \"variance_explained_ratio\": float(traits_variance_explained),\n",
    "            \"variance_explained_percent\": float(traits_variance_explained * 100)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Built per-model variance analysis data structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "zi9ycc6ru9n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./results/gemma-2-27b/variance_layer22.json\n",
      "✓ Saved variance analysis for gemma-2-27b\n"
     ]
    }
   ],
   "source": [
    "# Save per-model variance analysis to JSON file\n",
    "filename = f\"{outdir}/{model_name.lower()}/variance_layer{layer}.json\"\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(model_variance_data, f, indent=2)\n",
    "\n",
    "print(f\"Saved: {filename}\")\n",
    "print(f\"✓ Saved variance analysis for {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4a7bf",
   "metadata": {},
   "source": [
    "## Correlations between role loadings onto PCs across the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65e2c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "# layers = [22, 32, 40]\n",
    "\n",
    "# trait_results = {}\n",
    "# labels = {}\n",
    "# for model, layer in zip(models, layers):\n",
    "#     model_dir = f\"/workspace/{model}/traits_240\"\n",
    "#     trait_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n",
    "#     print(trait_results[model]['pca_transformed'].shape)\n",
    "#     labels[model] = trait_results[model]['traits']['pos_neg_50']\n",
    "#     print(labels[model][:20])\n",
    "\n",
    "# # need to get intersection of traits across models (gemma missing vindictive)\n",
    "# pca_transformed = []\n",
    "# for model in models:\n",
    "#     if model != 'gemma-2-27b':\n",
    "#         # splice out index 5 but keep the ones before and after\n",
    "#         pca_transformed.append(np.concatenate((trait_results[model]['pca_transformed'][:5], trait_results[model]['pca_transformed'][6:])))\n",
    "#     else:\n",
    "#         pca_transformed.append(trait_results[model]['pca_transformed'])\n",
    "\n",
    "# for m in pca_transformed:\n",
    "#     print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c83e2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transpose each matrix so rows are PCs and columns are traits\n",
    "# pca_transposed = [m.T for m in pca_transformed]\n",
    "\n",
    "# # Extract top 10 PCs from each model\n",
    "# n_pcs = 6\n",
    "# top_pcs = [m[:n_pcs] for m in pca_transposed]\n",
    "\n",
    "# print(f\"Transposed shapes (n_pcs, n_traits):\")\n",
    "# for model, pc_matrix in zip(models, top_pcs):\n",
    "#     print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# # Compute pairwise correlations for each PC\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# pc_correlations = []\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     # Extract the trait loading vector for this PC from each model\n",
    "#     gemma_pc = top_pcs[0][pc_idx]\n",
    "#     qwen_pc = top_pcs[1][pc_idx]\n",
    "#     llama_pc = top_pcs[2][pc_idx]\n",
    "    \n",
    "#     # Compute pairwise correlations\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     # Create 3x3 correlation matrix\n",
    "#     corr_matrix = np.array([\n",
    "#         [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "#         [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "#         [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "#     ])\n",
    "    \n",
    "#     pc_correlations.append(corr_matrix)\n",
    "\n",
    "#     print(f\"\\nPC{pc_idx + 1}:\")\n",
    "#     print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "#     print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "#     print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6f52212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try for top 10 role PCs\n",
    "# models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "# layers = [22, 32, 40]\n",
    "\n",
    "# def get_role_labels(pca_results):\n",
    "#     labels = []\n",
    "#     if 'pos_2' in pca_results['roles'].keys():\n",
    "#         pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "#         pos_2_roles = [f\"{role} (Somewhat RP)\" for role in pos_2_roles]\n",
    "#         labels.extend(pos_2_roles)\n",
    "#     if 'pos_3' in pca_results['roles'].keys():\n",
    "#         pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "#         pos_3_roles = [f\"{role} (Fully RP)\" for role in pos_3_roles]\n",
    "#         labels.extend(pos_3_roles)\n",
    "#     return labels\n",
    "\n",
    "\n",
    "# role_results = {}\n",
    "# labels = {}\n",
    "# for model, layer in zip(models, layers):\n",
    "#     model_dir = f\"/workspace/{model}/roles_240\"\n",
    "#     role_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos23.pt\", weights_only=False)\n",
    "#     print(role_results[model]['pca_transformed'].shape)\n",
    "#     labels[model] = get_role_labels(role_results[model])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5faf8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find intersection of roles across all 3 models\n",
    "# set_gemma = set(labels['gemma-2-27b'])\n",
    "# set_qwen = set(labels['qwen-3-32b'])\n",
    "# set_llama = set(labels['llama-3.3-70b'])\n",
    "\n",
    "# common_roles = set_gemma & set_qwen & set_llama\n",
    "# print(f\"Common roles across all models: {len(common_roles)}\")\n",
    "\n",
    "# # Get indices of common roles for each model (preserving order from labels)\n",
    "# indices = {}\n",
    "# for model in models:\n",
    "#     model_indices = []\n",
    "#     for i, role in enumerate(labels[model]):\n",
    "#         if role in common_roles:\n",
    "#             model_indices.append(i)\n",
    "#     indices[model] = model_indices\n",
    "#     print(f\"{model}: {len(model_indices)} common roles\")\n",
    "\n",
    "# # Extract aligned PCA transformed matrices (only common roles, in consistent order)\n",
    "# # Need to ensure the same role ordering across models\n",
    "# common_roles_list = sorted(list(common_roles))  # Consistent ordering\n",
    "\n",
    "# pca_transformed_roles = []\n",
    "# for model in models:\n",
    "#     # Map from common_roles_list order to model's indices\n",
    "#     model_indices_ordered = []\n",
    "#     for role in common_roles_list:\n",
    "#         idx = labels[model].index(role)\n",
    "#         model_indices_ordered.append(idx)\n",
    "    \n",
    "#     # Extract rows for common roles in the standardized order\n",
    "#     pca_transformed_roles.append(role_results[model]['pca_transformed'][model_indices_ordered])\n",
    "#     print(f\"{model} aligned shape: {pca_transformed_roles[-1].shape}\")\n",
    "\n",
    "# # Transpose each matrix so rows are PCs and columns are roles\n",
    "# pca_transposed_roles = [m.T for m in pca_transformed_roles]\n",
    "\n",
    "# # Extract top 10 PCs from each model\n",
    "# n_pcs = 6\n",
    "# top_pcs_roles = [m[:n_pcs] for m in pca_transposed_roles]\n",
    "\n",
    "# print(f\"\\nTransposed shapes (n_pcs, n_common_roles):\")\n",
    "# for model, pc_matrix in zip(models, top_pcs_roles):\n",
    "#     print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# # Compute pairwise correlations for each PC\n",
    "# pc_correlations_roles = []\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     # Extract the role loading vector for this PC from each model\n",
    "#     gemma_pc = top_pcs_roles[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_roles[1][pc_idx]\n",
    "#     llama_pc = top_pcs_roles[2][pc_idx]\n",
    "    \n",
    "#     # Compute pairwise correlations\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     # Create 3x3 correlation matrix\n",
    "#     corr_matrix = np.array([\n",
    "#         [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "#         [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "#         [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "#     ])\n",
    "    \n",
    "#     pc_correlations_roles.append(corr_matrix)\n",
    "\n",
    "#     print(f\"\\nPC{pc_idx + 1}:\")\n",
    "#     print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "#     print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "#     print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b1694",
   "metadata": {},
   "source": [
    "## Cross Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "n0k76vs7m5m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build cross-model PC loadings analysis JSON structure\n",
    "\n",
    "# n_pcs = 6\n",
    "\n",
    "# # Build trait analysis\n",
    "# trait_data = {\n",
    "#     \"dataset_info\": {\n",
    "#         \"n_common_traits\": pca_transformed[0].shape[0],\n",
    "#         \"excluded_traits\": [\"vindictive\"],\n",
    "#         \"note\": \"Gemma missing vindictive trait, spliced out from other models for alignment\"\n",
    "#     },\n",
    "#     \"model_configs\": {},\n",
    "#     \"pc_correlations\": []\n",
    "# }\n",
    "\n",
    "# # Add model configs for traits\n",
    "# for model, layer_num in zip(models, layers):\n",
    "#     pca_shape = list(trait_results[model]['pca_transformed'].shape)\n",
    "#     trait_data[\"model_configs\"][model] = {\n",
    "#         \"layer\": int(layer_num),\n",
    "#         \"n_total_traits\": int(pca_shape[0]),\n",
    "#         \"pca_shape\": pca_shape\n",
    "#     }\n",
    "\n",
    "# # Add PC correlations for traits\n",
    "# pca_transposed_traits = [m.T for m in pca_transformed]\n",
    "# top_pcs_traits = [m[:n_pcs] for m in pca_transposed_traits]\n",
    "\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     gemma_pc = top_pcs_traits[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_traits[1][pc_idx]\n",
    "#     llama_pc = top_pcs_traits[2][pc_idx]\n",
    "    \n",
    "#     from scipy.stats import pearsonr\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     trait_data[\"pc_correlations\"].append({\n",
    "#         \"pc\": pc_idx + 1,\n",
    "#         \"gemma_qwen\": float(corr_gemma_qwen),\n",
    "#         \"gemma_llama\": float(corr_gemma_llama),\n",
    "#         \"qwen_llama\": float(corr_qwen_llama)\n",
    "#     })\n",
    "\n",
    "# # Build role analysis\n",
    "# role_data = {\n",
    "#     \"dataset_info\": {\n",
    "#         \"n_common_roles\": int(len(common_roles)),\n",
    "#         \"note\": \"Roles include pos_2 (Somewhat RP) and pos_3 (Fully RP) labels\",\n",
    "#         \"alignment_method\": \"sorted common roles list for consistent ordering\"\n",
    "#     },\n",
    "#     \"model_configs\": {},\n",
    "#     \"pc_correlations\": []\n",
    "# }\n",
    "\n",
    "# # Add model configs for roles\n",
    "# for model, layer_num in zip(models, layers):\n",
    "#     pca_shape = list(role_results[model]['pca_transformed'].shape)\n",
    "#     role_data[\"model_configs\"][model] = {\n",
    "#         \"layer\": int(layer_num),\n",
    "#         \"n_total_roles\": int(pca_shape[0]),\n",
    "#         \"n_common_roles\": int(len(common_roles)),\n",
    "#         \"pca_shape\": pca_shape\n",
    "#     }\n",
    "\n",
    "# # Add PC correlations for roles\n",
    "# pca_transposed_roles_func = [m.T for m in pca_transformed_roles]\n",
    "# top_pcs_roles_func = [m[:n_pcs] for m in pca_transposed_roles_func]\n",
    "\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     gemma_pc = top_pcs_roles_func[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_roles_func[1][pc_idx]\n",
    "#     llama_pc = top_pcs_roles_func[2][pc_idx]\n",
    "    \n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     role_data[\"pc_correlations\"].append({\n",
    "#         \"pc\": pc_idx + 1,\n",
    "#         \"gemma_qwen\": float(corr_gemma_qwen),\n",
    "#         \"gemma_llama\": float(corr_gemma_llama),\n",
    "#         \"qwen_llama\": float(corr_qwen_llama)\n",
    "#     })\n",
    "\n",
    "# # Build complete structure\n",
    "# cross_model_data = {\n",
    "#     \"analysis_version\": \"1.0\",\n",
    "#     \"timestamp\": timestamp,\n",
    "#     \"models\": models,\n",
    "#     \"n_pcs_analyzed\": n_pcs,\n",
    "#     \"trait_analysis\": trait_data,\n",
    "#     \"role_analysis\": role_data\n",
    "# }\n",
    "\n",
    "# print(\"Built cross-model PC loadings data structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6s0k2hy6svd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cross-model PC loadings to JSON file\n",
    "# filename = f\"{outdir}/cross_model_loadings.json\"\n",
    "# with open(filename, 'w') as f:\n",
    "#     json.dump(cross_model_data, f, indent=2)\n",
    "\n",
    "# print(f\"Saved: {filename}\")\n",
    "# print(f\"✓ Saved cross-model PC loadings analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2oon4jt838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Summary of saved files\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"SUMMARY: JSON Files Saved\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"\\nOutput directory: {outdir}\")\n",
    "# print(f\"\\nFiles created:\")\n",
    "# print(f\"  1. Per-model variance analysis:\")\n",
    "# print(f\"     - {model_name.lower().replace('.', '-').replace(' ', '-')}_layer{layer}.json\")\n",
    "# print(f\"\\n  2. Cross-model PC loadings:\")\n",
    "# print(f\"     - cross_model_loadings.json\")\n",
    "# print(f\"\\nNote: To save variance analysis for other models (Qwen, Llama),\")\n",
    "# print(f\"      update the configuration cell and re-run the notebook.\")\n",
    "# print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
