{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28531137",
   "metadata": {},
   "source": [
    "# Variance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f3bcdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:08.842015Z",
     "iopub.status.busy": "2025-08-06T00:18:08.841387Z",
     "iopub.status.idle": "2025-08-06T00:18:09.171163Z",
     "shell.execute_reply": "2025-08-06T00:18:09.170519Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.pca_utils import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julz1owfwk",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "o7pmyp071r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Change these parameters for different models/datasets\n",
    "base_dir = \"/workspace/gemma-2-27b\"\n",
    "type = \"roles_240\"\n",
    "dir = f\"{base_dir}/{type}\"\n",
    "model_name = \"Gemma-2-27B\"\n",
    "layer = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76552389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pca_results = torch.load(f\"{dir}/pca/layer{layer}_pos23.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bec2d8",
   "metadata": {},
   "source": [
    "## Variance across and within roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5319f",
   "metadata": {},
   "source": [
    "### raw activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16d954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([275, 4608])\n",
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "vectors = torch.stack(pca_results['vectors']['pos_3'])[:, layer, :].float()\n",
    "print(vectors.shape)\n",
    "\n",
    "# compute variance across roles (rows) along hidden_dims\n",
    "raw_across_var = torch.var(vectors, dim=0)\n",
    "print(raw_across_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197362bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 275 scores\n"
     ]
    }
   ],
   "source": [
    "# load in scores\n",
    "scores = {}\n",
    "for file in os.listdir(f\"{dir}/extract_scores\"):\n",
    "    if file.endswith('.json'):\n",
    "        scores[file.replace('.json', '')] = json.load(open(f\"{dir}/extract_scores/{file}\"))\n",
    "\n",
    "print(f\"Loaded {len(scores)} scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c900d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in raw activations\n",
    "activations = {}\n",
    "for file in os.listdir(f\"{dir}/response_activations\"):\n",
    "    if file.endswith('.pt') and 'default' not in file:\n",
    "        # dict we should iterate over (1200 each)\n",
    "        role_activations = []\n",
    "        obj = torch.load(f\"{dir}/response_activations/{file}\")\n",
    "        for key in obj:\n",
    "            if scores[file.replace('.pt', '')][key] == 3:\n",
    "                role_activations.append(obj[key])\n",
    "        activations[file.replace('.pt', '')] = torch.stack(role_activations)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912a4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "# compute variance within roles\n",
    "raw_within_var = []\n",
    "for file in activations:\n",
    "    raw_within_var.append(torch.var(activations[file][:, layer, :], dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var)} roles, shape is {raw_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea71a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "avg_raw_within_var = torch.stack(raw_within_var).mean(dim=0)\n",
    "print(avg_raw_within_var.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cf860e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of raw_across_var / avg_raw_within_var is 0.43051645159721375\n"
     ]
    }
   ],
   "source": [
    "# total variance ratio\n",
    "raw_ratio = raw_across_var.mean() / avg_raw_within_var.mean()\n",
    "print(f\"ratio of raw_across_var / avg_raw_within_var is {raw_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0512101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "raw_across_var_normalized = torch.var(F.normalize(vectors, p=2, dim=1), dim=0)\n",
    "print(raw_across_var_normalized.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63901cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is torch.Size([4608])\n",
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "raw_within_var_normalized = []\n",
    "for file in activations:\n",
    "    raw_within_var_normalized.append(torch.var(F.normalize(activations[file][:, layer, :], p=2, dim=1), dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var_normalized)} roles, shape is {raw_within_var_normalized[0].shape}\")\n",
    "avg_raw_within_var_normalized = torch.stack(raw_within_var_normalized).mean(dim=0)\n",
    "print(avg_raw_within_var_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc8b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of raw_across_var_normalized / avg_raw_within_var_normalized is 0.3623166084289551\n"
     ]
    }
   ],
   "source": [
    "raw_ratio_normalized = raw_across_var_normalized.mean() / avg_raw_within_var_normalized.mean()\n",
    "print(f\"ratio of raw_across_var_normalized / avg_raw_within_var_normalized is {raw_ratio_normalized}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f2faa",
   "metadata": {},
   "source": [
    "### in PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0642d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448,)\n"
     ]
    }
   ],
   "source": [
    "# get transformed role vectors\n",
    "pca_across_var = np.var(pca_results['pca_transformed'][:275], axis=0)\n",
    "print(pca_across_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec04e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1199, 46, 4608])\n"
     ]
    }
   ],
   "source": [
    "print(activations['absurdist'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8e550e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is (448,)\n"
     ]
    }
   ],
   "source": [
    "pca_within_var = []\n",
    "pc1_within_var = []\n",
    "for role in activations:\n",
    "    role_scaled = pca_results['scaler'].transform(activations[role][:, layer, :].float().numpy())\n",
    "    role_pca = pca_results['pca'].transform(role_scaled)\n",
    "    pca_within_var.append(np.var(role_pca, axis=0))\n",
    "    pc1_within_var.append(np.var(role_pca[:, 0]))\n",
    "\n",
    "print(f\"for {len(pca_within_var)} roles, shape is {pca_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d4565fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448,)\n"
     ]
    }
   ],
   "source": [
    "mean_pca_within_var = np.array(pca_within_var).mean(axis=0)\n",
    "print(mean_pca_within_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6776cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of pca_across_var / mean_pca_within_var is 0.31411965474791115\n"
     ]
    }
   ],
   "source": [
    "pca_ratio = pca_across_var.mean() / mean_pca_within_var.mean()\n",
    "print(f\"ratio of pca_across_var / mean_pca_within_var is {pca_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffd5cc",
   "metadata": {},
   "source": [
    "### pc1 variance only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77c857e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829.9696483722173\n"
     ]
    }
   ],
   "source": [
    "pc1_across_var = np.var(pca_results['pca_transformed'][:275, 0])\n",
    "print(pc1_across_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291.39803214992793\n",
      "ratio of pc1_across_var / mean_pc1_within_var is 2.848233539014387\n"
     ]
    }
   ],
   "source": [
    "mean_pc1_within_var = np.array(pc1_within_var).mean()\n",
    "print(mean_pc1_within_var)\n",
    "\n",
    "pc1_ratio = pc1_across_var / mean_pc1_within_var\n",
    "print(f\"ratio of pc1_across_var / mean_pc1_within_var is {pc1_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5eca2",
   "metadata": {},
   "source": [
    "## Conditional variance of role vectors based on distance from Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9db03468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([448, 4608])\n"
     ]
    }
   ],
   "source": [
    "role_vectors = torch.stack(pca_results['vectors']['pos_2'] + pca_results['vectors']['pos_3'])[:, layer, :]\n",
    "print(role_vectors.shape)\n",
    "\n",
    "pc1 = pca_results['pca_transformed'][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dw7pl9twyv",
   "metadata": {},
   "source": [
    "### Conditional variance in raw activation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "191e6z46xkk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RAW ACTIVATION SPACE: Two-Group Comparison\n",
      "============================================================\n",
      "PC1 threshold: 25\n",
      "Assistant-like roles (PC1 < 25): 128 samples\n",
      "Roleplay roles (PC1 >= 25): 320 samples\n",
      "\n",
      "Mean variance (Assistant-like): 54.750000\n",
      "Mean variance (Roleplay): 151.000000\n",
      "Variance ratio (Assistant/Roleplay): 0.3626 (36.26%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Two-group comparison: Assistant-like vs Roleplay\n",
    "# Using PC1 threshold of -25 (same as in 9_cone.ipynb)\n",
    "threshold = 25\n",
    "\n",
    "assistant_mask = pc1 > threshold\n",
    "roleplay_mask = pc1 <= threshold\n",
    "\n",
    "# Compute variance of raw activations for each group\n",
    "# role_vectors shape: [448, 4608]\n",
    "var_assistant_raw = torch.var(role_vectors[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_raw = torch.var(role_vectors[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_raw = var_assistant_raw / var_roleplay_raw\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like roles (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like): {var_assistant_raw:.6f}\")\n",
    "print(f\"Mean variance (Roleplay): {var_roleplay_raw:.6f}\")\n",
    "print(f\"Variance ratio (Assistant/Roleplay): {var_ratio_raw:.4f} ({var_ratio_raw*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "vm23njwgwk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE (PC1 projected out): Two-Group Comparison\n",
      "============================================================\n",
      "PC1 threshold: 25\n",
      "Assistant-like roles (PC1 < 25): 128 samples\n",
      "Roleplay roles (PC1 >= 25): 320 samples\n",
      "\n",
      "Mean variance (Assistant-like, PC1 removed): 54.452919\n",
      "Mean variance (Roleplay, PC1 removed): 138.992462\n",
      "Variance ratio (Assistant/Roleplay): 0.3918 (39.18%)\n",
      "\n",
      "This is analogous to the PC2-10 analysis in PC space.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Project out PC1 from raw activations\n",
    "# Get PC1 direction from PCA\n",
    "pc1_direction = torch.from_numpy(pca_results['pca'].components_[0]).float()\n",
    "\n",
    "# Project role_vectors onto PC1 and subtract\n",
    "# Formula: projection = (v · u) * u, where u is the unit vector (PC1 direction)\n",
    "pc1_loadings = (role_vectors.float() @ pc1_direction).unsqueeze(1)  # Shape: [448, 1]\n",
    "pc1_projections = pc1_loadings * pc1_direction.unsqueeze(0)  # Shape: [448, 4608]\n",
    "role_vectors_pc1_removed = role_vectors - pc1_projections\n",
    "\n",
    "# Compute variance with PC1 projected out\n",
    "var_assistant_raw_no_pc1 = torch.var(role_vectors_pc1_removed[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_raw_no_pc1 = torch.var(role_vectors_pc1_removed[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_raw_no_pc1 = var_assistant_raw_no_pc1 / var_roleplay_raw_no_pc1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE (PC1 projected out): Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like roles (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like, PC1 removed): {var_assistant_raw_no_pc1:.6f}\")\n",
    "print(f\"Mean variance (Roleplay, PC1 removed): {var_roleplay_raw_no_pc1:.6f}\")\n",
    "print(f\"Variance ratio (Assistant/Roleplay): {var_ratio_raw_no_pc1:.4f} ({var_ratio_raw_no_pc1*100:.2f}%)\")\n",
    "print(f\"\\nThis is analogous to the PC2-10 analysis in PC space.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "zv1prpa1y3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE: Quintile Analysis\n",
      "============================================================\n",
      "\n",
      "Quintile 1: PC1 ∈ [-86.47, -33.36]\n",
      "  Sample size: 90\n",
      "  Mean variance (full): 136.000000\n",
      "  Mean variance (PC1 removed): 134.244888\n",
      "\n",
      "Quintile 2: PC1 ∈ [-33.36, -1.06]\n",
      "  Sample size: 89\n",
      "  Mean variance (full): 98.000000\n",
      "  Mean variance (PC1 removed): 96.719231\n",
      "\n",
      "Quintile 3: PC1 ∈ [-1.06, 18.72]\n",
      "  Sample size: 90\n",
      "  Mean variance (full): 69.000000\n",
      "  Mean variance (PC1 removed): 68.681099\n",
      "\n",
      "Quintile 4: PC1 ∈ [18.72, 28.17]\n",
      "  Sample size: 89\n",
      "  Mean variance (full): 53.750000\n",
      "  Mean variance (PC1 removed): 53.688721\n",
      "\n",
      "Quintile 5: PC1 ∈ [28.17, 38.88]\n",
      "  Sample size: 90\n",
      "  Mean variance (full): 53.250000\n",
      "  Mean variance (PC1 removed): 53.227360\n",
      "\n",
      "------------------------------------------------------------\n",
      "Variance ratio (Last/First quintile, full): 2.55x\n",
      "Variance ratio (Last/First quintile, PC1 removed): 2.52x\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Quintile analysis\n",
    "n_quintiles = 5\n",
    "quintile_edges = np.quantile(pc1, np.linspace(0, 1, n_quintiles + 1))\n",
    "quintile_variances = []\n",
    "quintile_variances_no_pc1 = []\n",
    "quintile_sizes = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Quintile Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(n_quintiles):\n",
    "    if i == 0:\n",
    "        mask = (pc1 >= quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    else:\n",
    "        mask = (pc1 > quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    \n",
    "    quintile_var = torch.var(role_vectors[mask], dim=0).mean().item()\n",
    "    quintile_var_no_pc1 = torch.var(role_vectors_pc1_removed[mask], dim=0).mean().item()\n",
    "    quintile_variances.append(quintile_var)\n",
    "    quintile_variances_no_pc1.append(quintile_var_no_pc1)\n",
    "    quintile_sizes.append(mask.sum())\n",
    "    \n",
    "    print(f\"\\nQuintile {i+1}: PC1 ∈ [{quintile_edges[i]:.2f}, {quintile_edges[i+1]:.2f}]\")\n",
    "    print(f\"  Sample size: {mask.sum()}\")\n",
    "    print(f\"  Mean variance (full): {quintile_var:.6f}\")\n",
    "    print(f\"  Mean variance (PC1 removed): {quintile_var_no_pc1:.6f}\")\n",
    "\n",
    "# Calculate ratios between first and last quintile\n",
    "quintile_ratio = quintile_variances[0] / quintile_variances[-1]\n",
    "quintile_ratio_no_pc1 = quintile_variances_no_pc1[0] / quintile_variances_no_pc1[-1]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(f\"Variance ratio (Last/First quintile, full): {quintile_ratio:.2f}x\")\n",
    "print(f\"Variance ratio (Last/First quintile, PC1 removed): {quintile_ratio_no_pc1:.2f}x\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7kwaevse0w",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE: Distance from Center Correlation\n",
      "============================================================\n",
      "Correlation between PC1 and L2 distance from mean (full):\n",
      "  r = -0.5635\n",
      "  p-value = 6.652e-39\n",
      "  Highly significant (p < 0.001)\n",
      "\n",
      "Correlation between PC1 and L2 distance from mean (PC1 removed):\n",
      "  r = -0.5441\n",
      "  p-value = 7.002e-36\n",
      "  Highly significant (p < 0.001)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Distance from center correlation\n",
    "# Compute mean of raw activations\n",
    "role_vectors_mean = role_vectors.mean(dim=0)\n",
    "role_vectors_pc1_removed_mean = role_vectors_pc1_removed.mean(dim=0)\n",
    "\n",
    "# Compute L2 distance from mean for each role\n",
    "distances_raw = torch.norm(role_vectors.float() - role_vectors_mean, p=2, dim=1).numpy()\n",
    "distances_raw_no_pc1 = torch.norm(role_vectors_pc1_removed - role_vectors_pc1_removed_mean, p=2, dim=1).numpy()\n",
    "\n",
    "# Calculate correlation with PC1\n",
    "correlation_raw, p_value_raw = pearsonr(pc1, distances_raw)\n",
    "correlation_raw_no_pc1, p_value_raw_no_pc1 = pearsonr(pc1, distances_raw_no_pc1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Distance from Center Correlation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Correlation between PC1 and L2 distance from mean (full):\")\n",
    "print(f\"  r = {correlation_raw:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw:.3e}\")\n",
    "if p_value_raw < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "\n",
    "print(f\"\\nCorrelation between PC1 and L2 distance from mean (PC1 removed):\")\n",
    "print(f\"  r = {correlation_raw_no_pc1:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw_no_pc1:.3e}\")\n",
    "if p_value_raw_no_pc1 < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw_no_pc1 < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lsye2ajp11",
   "metadata": {},
   "source": [
    "### Per-PC analysis: Correlation between each PC and distance in remaining PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0tedpgpspjp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Correlation between each PC and distance in remaining PC space\n",
      "======================================================================\n",
      "PC 1: r = -0.6576, p = 7.913e-57 ***\n",
      "PC 2: r =  0.2100, p = 7.342e-06 ***\n",
      "PC 3: r =  0.3147, p = 9.348e-12 ***\n",
      "PC 4: r =  0.0543, p = 2.516e-01 \n",
      "PC 5: r = -0.2252, p = 1.468e-06 ***\n",
      "PC 6: r = -0.2385, p = 3.258e-07 ***\n",
      "PC 7: r =  0.0882, p = 6.229e-02 \n",
      "PC 8: r =  0.0283, p = 5.500e-01 \n",
      "PC 9: r = -0.0532, p = 2.616e-01 \n",
      "PC10: r =  0.0580, p = 2.208e-01 \n",
      "======================================================================\n",
      "\n",
      "PC1 correlation: -0.6576\n",
      "Mean correlation (PC2-10): 0.0263\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each of the top 10 PCs, calculate:\n",
    "# 1. The correlation between that PC and distance from center in all OTHER PCs\n",
    "# 2. This tells us if the pattern we see with PC1 generalizes to other PCs\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "n_pcs_to_analyze = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Correlation between each PC and distance in remaining PC space\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "correlations = []\n",
    "p_values = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_analyze):\n",
    "    # Get the PC values\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get all other PCs (excluding current PC)\n",
    "    other_pcs = np.delete(pca_transformed, pc_idx, axis=1)\n",
    "    \n",
    "    # Calculate distance from center in the remaining PC space\n",
    "    other_pcs_mean = other_pcs.mean(axis=0)\n",
    "    distances = np.linalg.norm(other_pcs - other_pcs_mean, axis=1)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr, p_val = pearsonr(pc_values, distances)\n",
    "    correlations.append(corr)\n",
    "    p_values.append(p_val)\n",
    "    \n",
    "    # Print results\n",
    "    sig_marker = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n",
    "    print(f\"PC{pc_idx+1:2d}: r = {corr:7.4f}, p = {p_val:.3e} {sig_marker}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPC1 correlation: {correlations[0]:.4f}\")\n",
    "print(f\"Mean correlation (PC2-10): {np.mean(correlations[1:]):.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4w4stk4a567",
   "metadata": {},
   "source": [
    "### Conditional variance in PC2-10 based on position along each PC\n",
    "\n",
    "This analysis shows whether the pattern of \"extreme positions → high variance in other PCs\" is unique to PC1 or generalizes to other PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "x42qo16zp6k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Conditional Variance in PC2-10 based on position along each PC\n",
      "================================================================================\n",
      "For each PC, we split roles by median and compute variance in PC2-10 (excluding that PC)\n",
      "--------------------------------------------------------------------------------\n",
      "PC 1: High=224 samples, Low=224 samples\n",
      "      Var(high) =   99.655, Var(low) =  303.220, Ratio = 3.043\n",
      "PC 2: High=224 samples, Low=224 samples\n",
      "      Var(high) =  230.203, Var(low) =  130.662, Ratio = 1.762\n",
      "PC 3: High=224 samples, Low=224 samples\n",
      "      Var(high) =  211.142, Var(low) =  164.985, Ratio = 1.280\n",
      "PC 4: High=224 samples, Low=224 samples\n",
      "      Var(high) =  179.438, Var(low) =  214.903, Ratio = 1.198\n",
      "PC 5: High=224 samples, Low=224 samples\n",
      "      Var(high) =  157.295, Var(low) =  247.421, Ratio = 1.573\n",
      "PC 6: High=224 samples, Low=224 samples\n",
      "      Var(high) =  195.218, Var(low) =  209.086, Ratio = 1.071\n",
      "PC 7: High=224 samples, Low=224 samples\n",
      "      Var(high) =  234.147, Var(low) =  181.103, Ratio = 1.293\n",
      "PC 8: High=224 samples, Low=224 samples\n",
      "      Var(high) =  200.367, Var(low) =  223.138, Ratio = 1.114\n",
      "PC 9: High=224 samples, Low=224 samples\n",
      "      Var(high) =  238.866, Var(low) =  190.133, Ratio = 1.256\n",
      "PC10: High=224 samples, Low=224 samples\n",
      "      Var(high) =  209.329, Var(low) =  223.313, Ratio = 1.067\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "  PC1 variance ratio: 3.043\n",
      "  Mean variance ratio for PC2-10: 1.290\n",
      "  Max variance ratio (excluding PC1): 1.762 (PC2)\n",
      "\n",
      "  → Shows whether PC1 is unique in having high-variance 'other dimensions' for extreme positions\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each PC, split roles into two groups (high/low) and compute variance in PC2-10 (excluding that PC)\n",
    "# This tests if extreme positions on PC_i lead to high variance in other PCs\n",
    "\n",
    "n_pcs_to_test = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Conditional Variance in PC2-10 based on position along each PC\")\n",
    "print(\"=\" * 80)\n",
    "print(\"For each PC, we split roles by median and compute variance in PC2-10 (excluding that PC)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "variance_ratios = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_test):\n",
    "    # Split by median on this PC\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    median_val = np.median(pc_values)\n",
    "    high_mask = pc_values > median_val\n",
    "    low_mask = pc_values <= median_val\n",
    "    \n",
    "    # Get PC2-10, excluding current PC if it's in that range\n",
    "    if pc_idx == 0:\n",
    "        # For PC1, we want variance in PC2-10\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    elif 1 <= pc_idx < 10:\n",
    "        # For PC2-9, exclude that PC from PC2-10\n",
    "        pc_indices = [i for i in range(1, 10) if i != pc_idx]\n",
    "        other_pcs = pca_transformed[:, pc_indices]\n",
    "    else:\n",
    "        # For PC10, use PC2-9\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    \n",
    "    # Compute variance for each group\n",
    "    var_high = np.var(other_pcs[high_mask], axis=0).mean()\n",
    "    var_low = np.var(other_pcs[low_mask], axis=0).mean()\n",
    "    \n",
    "    ratio = max(var_high, var_low) / min(var_high, var_low)\n",
    "    variance_ratios.append(ratio)\n",
    "    \n",
    "    print(f\"PC{pc_idx+1:2d}: High={high_mask.sum():3d} samples, Low={low_mask.sum():3d} samples\")\n",
    "    print(f\"      Var(high) = {var_high:8.3f}, Var(low) = {var_low:8.3f}, Ratio = {ratio:.3f}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  PC1 variance ratio: {variance_ratios[0]:.3f}\")\n",
    "print(f\"  Mean variance ratio for PC2-10: {np.mean(variance_ratios[1:]):.3f}\")\n",
    "print(f\"  Max variance ratio (excluding PC1): {np.max(variance_ratios[1:]):.3f} (PC{np.argmax(variance_ratios[1:])+2})\")\n",
    "print(\"\\n  → Shows whether PC1 is unique in having high-variance 'other dimensions' for extreme positions\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "psa4fpzrfl8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total roles: 448\n",
      "pca_transformed shape: (448, 448)\n"
     ]
    }
   ],
   "source": [
    "# Create role labels from pca_results\n",
    "def get_role_labels_from_pca(pca_results):\n",
    "    labels = []\n",
    "    if 'pos_2' in pca_results['roles'].keys():\n",
    "        pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "        labels.extend(pos_2_roles)\n",
    "    if 'pos_3' in pca_results['roles'].keys():\n",
    "        pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "        labels.extend(pos_3_roles)\n",
    "    return labels\n",
    "\n",
    "role_labels = get_role_labels_from_pca(pca_results)\n",
    "print(f\"Total roles: {len(role_labels)}\")\n",
    "print(f\"pca_transformed shape: {pca_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0ogly4i9nk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Top and Bottom Roles for Each PC\n",
      "================================================================================\n",
      "\n",
      "PC1:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Assistant                      (PC1 =   38.88)\n",
      "    2. Screener                       (PC1 =   38.71)\n",
      "    3. Doctor                         (PC1 =   37.75)\n",
      "    4. Analyst                        (PC1 =   36.68)\n",
      "    5. Researcher                     (PC1 =   36.55)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Caveman                        (PC1 =  -86.47)\n",
      "    2. Eldritch                       (PC1 =  -79.26)\n",
      "    3. Leviathan                      (PC1 =  -79.20)\n",
      "    4. Void                           (PC1 =  -74.09)\n",
      "    5. Aberration                     (PC1 =  -69.96)\n",
      "\n",
      "PC2:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Procrastinator                 (PC2 =   89.66)\n",
      "    2. Teenager                       (PC2 =   79.36)\n",
      "    3. Adolescent                     (PC2 =   77.52)\n",
      "    4. Toddler                        (PC2 =   61.69)\n",
      "    5. Gossip                         (PC2 =   52.68)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Eldritch                       (PC2 =  -57.07)\n",
      "    2. Leviathan                      (PC2 =  -45.70)\n",
      "    3. Crystalline                    (PC2 =  -45.51)\n",
      "    4. Oracle                         (PC2 =  -45.07)\n",
      "    5. Tree                           (PC2 =  -44.90)\n",
      "\n",
      "PC3:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Infant                         (PC3 =  109.26)\n",
      "    2. Toddler                        (PC3 =   86.59)\n",
      "    3. Caveman                        (PC3 =   65.89)\n",
      "    4. Void                           (PC3 =   50.69)\n",
      "    5. Virus                          (PC3 =   46.99)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Advocate                       (PC3 =  -34.64)\n",
      "    2. Visionary                      (PC3 =  -34.56)\n",
      "    3. Activist                       (PC3 =  -30.61)\n",
      "    4. Evangelist                     (PC3 =  -29.54)\n",
      "    5. Blogger                        (PC3 =  -29.49)\n",
      "\n",
      "PC4:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Narcissist                     (PC4 =   65.85)\n",
      "    2. Workaholic                     (PC4 =   65.40)\n",
      "    3. Cynic                          (PC4 =   61.07)\n",
      "    4. Provocateur                    (PC4 =   56.77)\n",
      "    5. Zealot                         (PC4 =   56.64)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Toddler                        (PC4 =  -45.79)\n",
      "    2. Caveman                        (PC4 =  -39.21)\n",
      "    3. Fool                           (PC4 =  -34.92)\n",
      "    4. Grandparent                    (PC4 =  -34.69)\n",
      "    5. Infant                         (PC4 =  -33.07)\n",
      "\n",
      "PC5:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Gamer                          (PC5 =   60.55)\n",
      "    2. Mechanic                       (PC5 =   43.87)\n",
      "    3. Hacker                         (PC5 =   40.12)\n",
      "    4. Surfer                         (PC5 =   39.51)\n",
      "    5. Smuggler                       (PC5 =   36.67)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Interviewer                    (PC5 =  -38.57)\n",
      "    2. Toddler                        (PC5 =  -32.91)\n",
      "    3. Counselor                      (PC5 =  -32.42)\n",
      "    4. Therapist                      (PC5 =  -29.73)\n",
      "    5. Moderator                      (PC5 =  -29.38)\n",
      "\n",
      "PC6:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Addict                         (PC6 =   26.33)\n",
      "    2. Prisoner                       (PC6 =   26.09)\n",
      "    3. Widow                          (PC6 =   25.94)\n",
      "    4. Divorcee                       (PC6 =   24.74)\n",
      "    5. Empath                         (PC6 =   24.24)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Toddler                        (PC6 = -106.46)\n",
      "    2. Infant                         (PC6 =  -96.66)\n",
      "    3. Caveman                        (PC6 =  -81.88)\n",
      "    4. Fool                           (PC6 =  -52.08)\n",
      "    5. Robot                          (PC6 =  -39.42)\n",
      "\n",
      "PC7:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Caveman                        (PC7 =   64.64)\n",
      "    2. Traditionalist                 (PC7 =   42.02)\n",
      "    3. Infant                         (PC7 =   39.22)\n",
      "    4. Zealot                         (PC7 =   38.83)\n",
      "    5. Workaholic                     (PC7 =   36.97)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Jester                         (PC7 =  -57.46)\n",
      "    2. Comedian                       (PC7 =  -57.39)\n",
      "    3. Absurdist                      (PC7 =  -54.89)\n",
      "    4. Trickster                      (PC7 =  -45.02)\n",
      "    5. Jester                         (PC7 =  -42.51)\n",
      "\n",
      "PC8:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Prisoner                       (PC8 =   41.61)\n",
      "    2. Exile                          (PC8 =   38.61)\n",
      "    3. Criminal                       (PC8 =   34.44)\n",
      "    4. Refugee                        (PC8 =   34.09)\n",
      "    5. Addict                         (PC8 =   31.69)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Zealot                         (PC8 =  -33.48)\n",
      "    2. Narcissist                     (PC8 =  -32.83)\n",
      "    3. Optimist                       (PC8 =  -30.38)\n",
      "    4. Gamer                          (PC8 =  -28.83)\n",
      "    5. Hedonist                       (PC8 =  -28.03)\n",
      "\n",
      "PC9:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Infant                         (PC9 =   39.31)\n",
      "    2. Toddler                        (PC9 =   30.55)\n",
      "    3. Simulacrum                     (PC9 =   25.18)\n",
      "    4. Hybrid                         (PC9 =   23.92)\n",
      "    5. Crystalline                    (PC9 =   23.15)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Caveman                        (PC9 =  -43.20)\n",
      "    2. Pirate                         (PC9 =  -31.84)\n",
      "    3. Interviewer                    (PC9 =  -30.48)\n",
      "    4. Zealot                         (PC9 =  -28.52)\n",
      "    5. Smuggler                       (PC9 =  -25.26)\n",
      "\n",
      "PC10:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Luddite                        (PC10 =   46.93)\n",
      "    2. Zealot                         (PC10 =   30.80)\n",
      "    3. Jester                         (PC10 =   30.55)\n",
      "    4. Absurdist                      (PC10 =   30.40)\n",
      "    5. Comedian                       (PC10 =   30.29)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Interviewer                    (PC10 =  -30.67)\n",
      "    2. Predator                       (PC10 =  -24.99)\n",
      "    3. Competitor                     (PC10 =  -24.44)\n",
      "    4. Fixer                          (PC10 =  -22.71)\n",
      "    5. Fixer                          (PC10 =  -22.40)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Show top/bottom roles for each PC\n",
    "n_pcs_to_show = 10  # Show first 5 PCs\n",
    "n_roles_to_show = 5  # Show top/bottom 5 roles\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Top and Bottom Roles for Each PC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pc_idx in range(n_pcs_to_show):\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get indices of top and bottom roles\n",
    "    top_indices = np.argsort(pc_values)[-n_roles_to_show:][::-1]\n",
    "    bottom_indices = np.argsort(pc_values)[:n_roles_to_show]\n",
    "    \n",
    "    print(f\"\\nPC{pc_idx+1}:\")\n",
    "    print(f\"  Top {n_roles_to_show} (highest loadings):\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "    \n",
    "    print(f\"  Bottom {n_roles_to_show} (lowest loadings):\")\n",
    "    for i, idx in enumerate(bottom_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4a7bf",
   "metadata": {},
   "source": [
    "## Correlations between role loadings onto PCs across the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239, 239)\n",
      "['zealous', 'wry', 'witty', 'whimsical', 'visceral', 'verbose', 'utilitarian', 'urgent', 'universalist', 'understated', 'transparent', 'traditional', 'theoretical', 'theatrical', 'temperamental', 'technical', 'tactful', 'systems_thinker', 'sycophantic', 'supportive']\n",
      "(240, 240)\n",
      "['zealous', 'wry', 'witty', 'whimsical', 'visceral', 'vindictive', 'verbose', 'utilitarian', 'urgent', 'universalist', 'understated', 'transparent', 'traditional', 'theoretical', 'theatrical', 'temperamental', 'technical', 'tactful', 'systems_thinker', 'sycophantic']\n",
      "(240, 240)\n",
      "['zealous', 'wry', 'witty', 'whimsical', 'visceral', 'vindictive', 'verbose', 'utilitarian', 'urgent', 'universalist', 'understated', 'transparent', 'traditional', 'theoretical', 'theatrical', 'temperamental', 'technical', 'tactful', 'systems_thinker', 'sycophantic']\n",
      "(239, 239)\n",
      "(239, 240)\n",
      "(239, 240)\n"
     ]
    }
   ],
   "source": [
    "models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "layers = [22, 32, 40]\n",
    "\n",
    "trait_results = {}\n",
    "labels = {}\n",
    "for model, layer in zip(models, layers):\n",
    "    model_dir = f\"/workspace/{model}/traits_240\"\n",
    "    trait_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n",
    "    print(trait_results[model]['pca_transformed'].shape)\n",
    "    labels[model] = trait_results[model]['traits']['pos_neg_50']\n",
    "    print(labels[model][:20])\n",
    "\n",
    "# need to get intersection of traits across models (gemma missing vindictive)\n",
    "pca_transformed = []\n",
    "for model in models:\n",
    "    if model != 'gemma-2-27b':\n",
    "        # splice out index 5 but keep the ones before and after\n",
    "        pca_transformed.append(np.concatenate((trait_results[model]['pca_transformed'][:5], trait_results[model]['pca_transformed'][6:])))\n",
    "    else:\n",
    "        pca_transformed.append(trait_results[model]['pca_transformed'])\n",
    "\n",
    "for m in pca_transformed:\n",
    "    print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c83e2c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed shapes (n_pcs, n_traits):\n",
      "gemma-2-27b: (6, 239)\n",
      "qwen-3-32b: (6, 239)\n",
      "llama-3.3-70b: (6, 239)\n",
      "\n",
      "PC1:\n",
      "  Gemma ↔ Qwen:  -0.8940\n",
      "  Gemma ↔ Llama:  0.9690\n",
      "  Qwen  ↔ Llama: -0.8359\n",
      "\n",
      "PC2:\n",
      "  Gemma ↔ Qwen:   0.8356\n",
      "  Gemma ↔ Llama: -0.9079\n",
      "  Qwen  ↔ Llama: -0.8064\n",
      "\n",
      "PC3:\n",
      "  Gemma ↔ Qwen:   0.7499\n",
      "  Gemma ↔ Llama: -0.9005\n",
      "  Qwen  ↔ Llama: -0.8542\n",
      "\n",
      "PC4:\n",
      "  Gemma ↔ Qwen:   0.6075\n",
      "  Gemma ↔ Llama:  0.6253\n",
      "  Qwen  ↔ Llama:  0.4756\n",
      "\n",
      "PC5:\n",
      "  Gemma ↔ Qwen:   0.3510\n",
      "  Gemma ↔ Llama:  0.5943\n",
      "  Qwen  ↔ Llama:  0.5252\n",
      "\n",
      "PC6:\n",
      "  Gemma ↔ Qwen:  -0.2080\n",
      "  Gemma ↔ Llama: -0.7845\n",
      "  Qwen  ↔ Llama: -0.3113\n"
     ]
    }
   ],
   "source": [
    "# Transpose each matrix so rows are PCs and columns are traits\n",
    "pca_transposed = [m.T for m in pca_transformed]\n",
    "\n",
    "# Extract top 10 PCs from each model\n",
    "n_pcs = 6\n",
    "top_pcs = [m[:n_pcs] for m in pca_transposed]\n",
    "\n",
    "print(f\"Transposed shapes (n_pcs, n_traits):\")\n",
    "for model, pc_matrix in zip(models, top_pcs):\n",
    "    print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# Compute pairwise correlations for each PC\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "pc_correlations = []\n",
    "for pc_idx in range(n_pcs):\n",
    "    # Extract the trait loading vector for this PC from each model\n",
    "    gemma_pc = top_pcs[0][pc_idx]\n",
    "    qwen_pc = top_pcs[1][pc_idx]\n",
    "    llama_pc = top_pcs[2][pc_idx]\n",
    "    \n",
    "    # Compute pairwise correlations\n",
    "    corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "    corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "    corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "    # Create 3x3 correlation matrix\n",
    "    corr_matrix = np.array([\n",
    "        [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "        [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "        [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "    ])\n",
    "    \n",
    "    pc_correlations.append(corr_matrix)\n",
    "\n",
    "    print(f\"\\nPC{pc_idx + 1}:\")\n",
    "    print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "    print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "    print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6f52212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 448)\n",
      "(463, 463)\n",
      "(377, 377)\n"
     ]
    }
   ],
   "source": [
    "# try for top 10 role PCs\n",
    "models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "layers = [22, 32, 40]\n",
    "\n",
    "def get_role_labels(pca_results):\n",
    "    labels = []\n",
    "    if 'pos_2' in pca_results['roles'].keys():\n",
    "        pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "        pos_2_roles = [f\"{role} (Somewhat RP)\" for role in pos_2_roles]\n",
    "        labels.extend(pos_2_roles)\n",
    "    if 'pos_3' in pca_results['roles'].keys():\n",
    "        pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "        pos_3_roles = [f\"{role} (Fully RP)\" for role in pos_3_roles]\n",
    "        labels.extend(pos_3_roles)\n",
    "    return labels\n",
    "\n",
    "\n",
    "role_results = {}\n",
    "labels = {}\n",
    "for model, layer in zip(models, layers):\n",
    "    model_dir = f\"/workspace/{model}/roles_240\"\n",
    "    role_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos23.pt\", weights_only=False)\n",
    "    print(role_results[model]['pca_transformed'].shape)\n",
    "    labels[model] = get_role_labels(role_results[model])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5faf8b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common roles across all models: 361\n",
      "gemma-2-27b: 361 common roles\n",
      "qwen-3-32b: 361 common roles\n",
      "llama-3.3-70b: 361 common roles\n",
      "gemma-2-27b aligned shape: (361, 448)\n",
      "qwen-3-32b aligned shape: (361, 463)\n",
      "llama-3.3-70b aligned shape: (361, 377)\n",
      "\n",
      "Transposed shapes (n_pcs, n_common_roles):\n",
      "gemma-2-27b: (6, 361)\n",
      "qwen-3-32b: (6, 361)\n",
      "llama-3.3-70b: (6, 361)\n",
      "\n",
      "PC1:\n",
      "  Gemma ↔ Qwen:  -0.9633\n",
      "  Gemma ↔ Llama: -0.9530\n",
      "  Qwen  ↔ Llama:  0.9723\n",
      "\n",
      "PC2:\n",
      "  Gemma ↔ Qwen:   0.9284\n",
      "  Gemma ↔ Llama:  0.9121\n",
      "  Qwen  ↔ Llama:  0.9176\n",
      "\n",
      "PC3:\n",
      "  Gemma ↔ Qwen:   0.3108\n",
      "  Gemma ↔ Llama:  0.7327\n",
      "  Qwen  ↔ Llama:  0.6831\n",
      "\n",
      "PC4:\n",
      "  Gemma ↔ Qwen:   0.6476\n",
      "  Gemma ↔ Llama: -0.8664\n",
      "  Qwen  ↔ Llama: -0.6006\n",
      "\n",
      "PC5:\n",
      "  Gemma ↔ Qwen:   0.6709\n",
      "  Gemma ↔ Llama:  0.8028\n",
      "  Qwen  ↔ Llama:  0.7283\n",
      "\n",
      "PC6:\n",
      "  Gemma ↔ Qwen:   0.2149\n",
      "  Gemma ↔ Llama: -0.5411\n",
      "  Qwen  ↔ Llama: -0.1034\n"
     ]
    }
   ],
   "source": [
    "# Find intersection of roles across all 3 models\n",
    "set_gemma = set(labels['gemma-2-27b'])\n",
    "set_qwen = set(labels['qwen-3-32b'])\n",
    "set_llama = set(labels['llama-3.3-70b'])\n",
    "\n",
    "common_roles = set_gemma & set_qwen & set_llama\n",
    "print(f\"Common roles across all models: {len(common_roles)}\")\n",
    "\n",
    "# Get indices of common roles for each model (preserving order from labels)\n",
    "indices = {}\n",
    "for model in models:\n",
    "    model_indices = []\n",
    "    for i, role in enumerate(labels[model]):\n",
    "        if role in common_roles:\n",
    "            model_indices.append(i)\n",
    "    indices[model] = model_indices\n",
    "    print(f\"{model}: {len(model_indices)} common roles\")\n",
    "\n",
    "# Extract aligned PCA transformed matrices (only common roles, in consistent order)\n",
    "# Need to ensure the same role ordering across models\n",
    "common_roles_list = sorted(list(common_roles))  # Consistent ordering\n",
    "\n",
    "pca_transformed_roles = []\n",
    "for model in models:\n",
    "    # Map from common_roles_list order to model's indices\n",
    "    model_indices_ordered = []\n",
    "    for role in common_roles_list:\n",
    "        idx = labels[model].index(role)\n",
    "        model_indices_ordered.append(idx)\n",
    "    \n",
    "    # Extract rows for common roles in the standardized order\n",
    "    pca_transformed_roles.append(role_results[model]['pca_transformed'][model_indices_ordered])\n",
    "    print(f\"{model} aligned shape: {pca_transformed_roles[-1].shape}\")\n",
    "\n",
    "# Transpose each matrix so rows are PCs and columns are roles\n",
    "pca_transposed_roles = [m.T for m in pca_transformed_roles]\n",
    "\n",
    "# Extract top 10 PCs from each model\n",
    "n_pcs = 6\n",
    "top_pcs_roles = [m[:n_pcs] for m in pca_transposed_roles]\n",
    "\n",
    "print(f\"\\nTransposed shapes (n_pcs, n_common_roles):\")\n",
    "for model, pc_matrix in zip(models, top_pcs_roles):\n",
    "    print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# Compute pairwise correlations for each PC\n",
    "pc_correlations_roles = []\n",
    "for pc_idx in range(n_pcs):\n",
    "    # Extract the role loading vector for this PC from each model\n",
    "    gemma_pc = top_pcs_roles[0][pc_idx]\n",
    "    qwen_pc = top_pcs_roles[1][pc_idx]\n",
    "    llama_pc = top_pcs_roles[2][pc_idx]\n",
    "    \n",
    "    # Compute pairwise correlations\n",
    "    corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "    corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "    corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "    # Create 3x3 correlation matrix\n",
    "    corr_matrix = np.array([\n",
    "        [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "        [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "        [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "    ])\n",
    "    \n",
    "    pc_correlations_roles.append(corr_matrix)\n",
    "\n",
    "    print(f\"\\nPC{pc_idx + 1}:\")\n",
    "    print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "    print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "    print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0108b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
