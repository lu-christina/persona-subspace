{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28531137",
   "metadata": {},
   "source": [
    "# Variance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3bcdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:08.842015Z",
     "iopub.status.busy": "2025-08-06T00:18:08.841387Z",
     "iopub.status.idle": "2025-08-06T00:18:09.171163Z",
     "shell.execute_reply": "2025-08-06T00:18:09.170519Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.pca_utils import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julz1owfwk",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "o7pmyp071r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Change these parameters for different models/datasets\n",
    "model_name = \"qwen-3-32b\"\n",
    "base_dir = f\"/workspace/{model_name}\"\n",
    "type = \"roles_240\"\n",
    "dir = f\"{base_dir}/{type}\"\n",
    "\n",
    "layer = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76552389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n",
      "/root/git/persona-subspace/.venv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_results = torch.load(f\"{dir}/pca/layer{layer}_pos23.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bec2d8",
   "metadata": {},
   "source": [
    "## Variance across and within roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5319f",
   "metadata": {},
   "source": [
    "### raw activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d16d954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([275, 5120])\n",
      "torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "vectors = torch.stack(pca_results['vectors']['pos_3'])[:, layer, :].float()\n",
    "print(vectors.shape)\n",
    "\n",
    "# compute variance across roles (rows) along hidden_dims\n",
    "raw_across_var = torch.var(vectors, dim=0)\n",
    "print(raw_across_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "197362bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 275 scores\n"
     ]
    }
   ],
   "source": [
    "# load in scores\n",
    "scores = {}\n",
    "for file in os.listdir(f\"{dir}/extract_scores\"):\n",
    "    if file.endswith('.json'):\n",
    "        scores[file.replace('.json', '')] = json.load(open(f\"{dir}/extract_scores/{file}\"))\n",
    "\n",
    "print(f\"Loaded {len(scores)} scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48c900d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in raw activations\n",
    "activations = {}\n",
    "for file in os.listdir(f\"{dir}/response_activations\"):\n",
    "    if file.endswith('.pt') and 'default' not in file:\n",
    "        # dict we should iterate over (1200 each)\n",
    "        role_activations = []\n",
    "        obj = torch.load(f\"{dir}/response_activations/{file}\")\n",
    "        for key in obj:\n",
    "            if scores[file.replace('.pt', '')][key] == 3:\n",
    "                role_activations.append(obj[key])\n",
    "        activations[file.replace('.pt', '')] = torch.stack(role_activations)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "912a4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "# compute variance within roles\n",
    "raw_within_var = []\n",
    "for file in activations:\n",
    "    raw_within_var.append(torch.var(activations[file][:, layer, :], dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var)} roles, shape is {raw_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ea71a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "avg_raw_within_var = torch.stack(raw_within_var).mean(dim=0)\n",
    "print(avg_raw_within_var.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cf860e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of raw_across_var / avg_raw_within_var is 0.36073175072669983\n"
     ]
    }
   ],
   "source": [
    "# total variance ratio\n",
    "raw_ratio = raw_across_var.sum() / avg_raw_within_var.sum()\n",
    "print(f\"ratio of raw_across_var / avg_raw_within_var is {raw_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0512101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "raw_across_var_normalized = torch.var(F.normalize(vectors, p=2, dim=1), dim=0)\n",
    "print(raw_across_var_normalized.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63901cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is torch.Size([5120])\n",
      "torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "raw_within_var_normalized = []\n",
    "for file in activations:\n",
    "    raw_within_var_normalized.append(torch.var(F.normalize(activations[file][:, layer, :], p=2, dim=1), dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var_normalized)} roles, shape is {raw_within_var_normalized[0].shape}\")\n",
    "avg_raw_within_var_normalized = torch.stack(raw_within_var_normalized).mean(dim=0)\n",
    "print(avg_raw_within_var_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5cc8b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of raw_across_var_normalized / avg_raw_within_var_normalized is 0.3895587921142578\n"
     ]
    }
   ],
   "source": [
    "raw_ratio_normalized = raw_across_var_normalized.mean() / avg_raw_within_var_normalized.mean()\n",
    "print(f\"ratio of raw_across_var_normalized / avg_raw_within_var_normalized is {raw_ratio_normalized}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f2faa",
   "metadata": {},
   "source": [
    "### in PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0642d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463,)\n"
     ]
    }
   ],
   "source": [
    "# get transformed role vectors\n",
    "pca_across_var = np.var(pca_results['pca_transformed'][:275], axis=0)\n",
    "print(pca_across_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ec04e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1193, 64, 5120])\n"
     ]
    }
   ],
   "source": [
    "print(activations['absurdist'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8e550e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 275 roles, shape is (463,)\n"
     ]
    }
   ],
   "source": [
    "pca_within_var = []\n",
    "pc1_within_var = []\n",
    "for role in activations:\n",
    "    role_scaled = pca_results['scaler'].transform(activations[role][:, layer, :].float().numpy())\n",
    "    role_pca = pca_results['pca'].transform(role_scaled)\n",
    "    pca_within_var.append(np.var(role_pca, axis=0))\n",
    "    pc1_within_var.append(np.var(role_pca[:, 0]))\n",
    "\n",
    "print(f\"for {len(pca_within_var)} roles, shape is {pca_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d4565fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463,)\n"
     ]
    }
   ],
   "source": [
    "mean_pca_within_var = np.array(pca_within_var).mean(axis=0)\n",
    "print(mean_pca_within_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6776cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of pca_across_var / mean_pca_within_var is 0.21511572955183214\n"
     ]
    }
   ],
   "source": [
    "pca_ratio = pca_across_var.mean() / mean_pca_within_var.mean()\n",
    "print(f\"ratio of pca_across_var / mean_pca_within_var is {pca_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffd5cc",
   "metadata": {},
   "source": [
    "### pc1 variance only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77c857e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796.3471953638646\n"
     ]
    }
   ],
   "source": [
    "pc1_across_var = np.var(pca_results['pca_transformed'][:275, 0])\n",
    "print(pc1_across_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfc2e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361.803697094426\n",
      "ratio of pc1_across_var / mean_pc1_within_var is 2.20104770006269\n"
     ]
    }
   ],
   "source": [
    "mean_pc1_within_var = np.array(pc1_within_var).mean()\n",
    "print(mean_pc1_within_var)\n",
    "\n",
    "pc1_ratio = pc1_across_var / mean_pc1_within_var\n",
    "print(f\"ratio of pc1_across_var / mean_pc1_within_var is {pc1_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4pcuy4pbb",
   "metadata": {},
   "source": [
    "### All PCs variance ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "hq8lbky0oc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed ratios for 463 PCs\n",
      "PC1 ratio: 2.2010\n",
      "Mean ratio (all PCs): 0.0756\n",
      "Mean ratio (PC2-10): 0.6630\n",
      "Max ratio: 2.2010 (PC1)\n"
     ]
    }
   ],
   "source": [
    "# Compute ratio for all PCs using existing variables\n",
    "all_pc_ratios = pca_across_var / mean_pca_within_var\n",
    "print(f\"Computed ratios for {len(all_pc_ratios)} PCs\")\n",
    "print(f\"PC1 ratio: {all_pc_ratios[0]:.4f}\")\n",
    "print(f\"Mean ratio (all PCs): {all_pc_ratios.mean():.4f}\")\n",
    "print(f\"Mean ratio (PC2-10): {all_pc_ratios[1:10].mean():.4f}\")\n",
    "print(f\"Max ratio: {all_pc_ratios.max():.4f} (PC{all_pc_ratios.argmax()+1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "hmedn82ye69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "steelblue",
          "width": 2
         },
         "mode": "lines",
         "name": "PC Ratio",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463
         ],
         "y": [
          2.2010477000626882,
          1.3804334043631028,
          0.6082354801351637,
          0.9170348466616239,
          0.7524499560717456,
          0.616383941785323,
          0.38062400319240086,
          0.4526048460960973,
          0.5818041752690796,
          0.27708603950422683,
          0.3283896678669817,
          0.5469995842342527,
          0.25890228123506104,
          0.32465272319339195,
          0.2785382107391128,
          0.3743123638418712,
          0.3238420807162915,
          0.20054635452745287,
          0.2969642876924906,
          0.22139312960586854,
          0.32104999959657876,
          0.280089189066926,
          0.32302596508377296,
          0.231398401118349,
          0.24433969800816363,
          0.31441074268959623,
          0.28729882409051133,
          0.2990585519409325,
          0.3101201299948332,
          0.2907572930212292,
          0.1816033542007657,
          0.13471299359619646,
          0.17830133203138884,
          0.14320321686485804,
          0.257942763692916,
          0.194945263830163,
          0.1814672958576042,
          0.19459874262271468,
          0.29195620477170087,
          0.22803427144332095,
          0.20883850241709032,
          0.16310588003996448,
          0.18513547598848437,
          0.19249094333158387,
          0.19635444270282304,
          0.19306765905048534,
          0.17329648030638484,
          0.23513445602895433,
          0.16841144859090756,
          0.17233266406985098,
          0.15816171942571197,
          0.21220359205082037,
          0.2172377342421748,
          0.1763515100462525,
          0.12320383703663029,
          0.1681175331034806,
          0.12143257617546932,
          0.16033355321052298,
          0.1713147808829329,
          0.13405024693704132,
          0.14004537621767596,
          0.160733258062281,
          0.1561972089323043,
          0.20195683712977755,
          0.15108661561780576,
          0.13892219410392853,
          0.15510297599147221,
          0.16884180633290904,
          0.18427259916935224,
          0.15552579022369195,
          0.12823740308954842,
          0.16817992529973622,
          0.13229781429842333,
          0.10926382541090476,
          0.183808614091191,
          0.14188073532278878,
          0.11719259763295439,
          0.12181441501251784,
          0.1457187909975081,
          0.09651909890675578,
          0.11904830138081639,
          0.11810609258496933,
          0.1152812393451234,
          0.11618034029735848,
          0.13298044544274534,
          0.09396562965922281,
          0.12604391331728332,
          0.11448344132032116,
          0.11782987252046195,
          0.10581447012684846,
          0.10497153314831952,
          0.10516785828417693,
          0.11866991651898076,
          0.12157306160238912,
          0.10108467598414567,
          0.10728365835291116,
          0.09377734690932364,
          0.10572851595807772,
          0.09783387704538167,
          0.11105302702562073,
          0.07712407243681937,
          0.08981423230334326,
          0.08923871856478927,
          0.08859040988643774,
          0.09327538029748673,
          0.0792945348888424,
          0.08815211328554634,
          0.06948693021201054,
          0.08951405588770585,
          0.08343661148062036,
          0.06370672434428265,
          0.07223648181289075,
          0.09962725388173406,
          0.07049471393959061,
          0.09719519124425677,
          0.07890379007747139,
          0.09663308415830621,
          0.10855854497162254,
          0.07035453971816243,
          0.0764613477755484,
          0.07521285328022329,
          0.09934646457227063,
          0.06276862688258994,
          0.06845176882859759,
          0.07138062514939762,
          0.07812678396131013,
          0.09523393063022291,
          0.06340225002450083,
          0.07736723278942827,
          0.05811247310378634,
          0.07039016265527902,
          0.07028191347991428,
          0.0769738988735395,
          0.07083284074218722,
          0.05859822874793398,
          0.06057398170072828,
          0.06615295798830025,
          0.055019631250069964,
          0.07218241506709637,
          0.052148584613214304,
          0.058265420902656066,
          0.059482870934925824,
          0.07837060471602256,
          0.05646925176469581,
          0.067586972026515,
          0.06552419526718477,
          0.06725636464909711,
          0.06642898223906792,
          0.04963943868326893,
          0.06681060424037896,
          0.05613346857152864,
          0.05561730041242526,
          0.05363842815327522,
          0.054136912890217076,
          0.061579832996281995,
          0.057674973833945424,
          0.057559857612782206,
          0.03761435016120936,
          0.05823702724165135,
          0.0549125925243701,
          0.05239702120543297,
          0.05607481061363961,
          0.06094631255411119,
          0.0490004760442996,
          0.04862488636942362,
          0.05266836144454537,
          0.04195017627890236,
          0.046322194004410976,
          0.05018550616142411,
          0.050103327395385415,
          0.0450580586780678,
          0.04404167915846234,
          0.05159436933990543,
          0.05425416150106929,
          0.04872032848715832,
          0.04576239744828475,
          0.04501859847507192,
          0.04665104745704733,
          0.0435921393353848,
          0.04200017066795617,
          0.04126515499354389,
          0.0361302694576209,
          0.040359197430580966,
          0.04268032134318599,
          0.0352713151915965,
          0.03948943434668668,
          0.037982352888794084,
          0.03475570341700396,
          0.032673133501708286,
          0.03936924702556372,
          0.035442014690388754,
          0.03826832169450394,
          0.036099380491476145,
          0.03177775899192608,
          0.03305194107171497,
          0.04275833096742579,
          0.041375302200737776,
          0.03342140499695452,
          0.03006781112990493,
          0.037466872940821,
          0.029488241580392285,
          0.03911713438922168,
          0.031728385882635844,
          0.037546934339377,
          0.029940652599196062,
          0.03140393705829416,
          0.030998967294216362,
          0.030556227180918327,
          0.031106347308764833,
          0.032000483740711544,
          0.03075670047117233,
          0.027364990373680037,
          0.030056892185551503,
          0.029951730155270972,
          0.03081020999570049,
          0.029907541786577133,
          0.034925492169446806,
          0.026906799594890986,
          0.03366220008981538,
          0.02684894207603221,
          0.03216443359493048,
          0.03140436527706664,
          0.03083869561871175,
          0.02767394839884009,
          0.030716600632102457,
          0.03107762658631519,
          0.032667399475600135,
          0.025354880147822622,
          0.025630428472991497,
          0.026587468595210037,
          0.02350895047916791,
          0.024647013104256515,
          0.02511160686408885,
          0.025776475124802016,
          0.02257652513661396,
          0.024260929999667297,
          0.023880597784408607,
          0.022164043535470107,
          0.024941767912513662,
          0.025232917007108464,
          0.02678662694460883,
          0.02683994695138632,
          0.029119230173907915,
          0.02638372874245112,
          0.025364392525545322,
          0.02432373113490226,
          0.018649776002586715,
          0.021617671207630907,
          0.023342196970777697,
          0.026121228641004985,
          0.023355499466748066,
          0.021087352919422292,
          0.025903342716826774,
          0.028039995328867414,
          0.026015459582746366,
          0.022237792740506204,
          0.018512884202427585,
          0.021842918004787583,
          0.02141373616630225,
          0.023761081673318484,
          0.02346402431836777,
          0.018131116775246307,
          0.023602104955891337,
          0.01884530722255993,
          0.023634689315543068,
          0.022215025673316353,
          0.02117928130250748,
          0.021280305047987422,
          0.02019745270560421,
          0.01885499598571462,
          0.02497423245651114,
          0.0189238814675283,
          0.02132732410219517,
          0.020147743169295778,
          0.01705364486308263,
          0.016127865047179012,
          0.020683208313631102,
          0.018286846422867955,
          0.0211363985155574,
          0.021946707389564432,
          0.017748257712978076,
          0.020338338276035692,
          0.019528075888746676,
          0.015366555307943128,
          0.019303513488075446,
          0.022077112754212903,
          0.018929970099990423,
          0.018483941309601456,
          0.018689931109413478,
          0.01828486406666899,
          0.01787026722767649,
          0.015377757713825576,
          0.01708211858285688,
          0.0169314081021218,
          0.016488567298894235,
          0.015504491139517351,
          0.016831216559434772,
          0.01719763038685947,
          0.01888804254674439,
          0.017959007666219096,
          0.016454372439385887,
          0.015343499149948236,
          0.015189791336781474,
          0.017254602294663288,
          0.012959695548282435,
          0.015644636141772753,
          0.018578501300881477,
          0.015071223652061372,
          0.01788691912351974,
          0.01585039447418723,
          0.015370748281397225,
          0.015277194538724987,
          0.013446454468416521,
          0.014057403832324514,
          0.014691564147862062,
          0.015611368694227157,
          0.013785231523822196,
          0.01645519435607535,
          0.02052445174838302,
          0.015090463158071839,
          0.01592854909081077,
          0.01368084530342687,
          0.014588073556746396,
          0.014776625809446954,
          0.016131220435063685,
          0.012357119590932995,
          0.012667108056050206,
          0.016163287005321766,
          0.012631964683366578,
          0.011412308541095902,
          0.012645883036566672,
          0.015132988804007855,
          0.015930445649523124,
          0.016744088284653003,
          0.01572773279491232,
          0.016429106258771337,
          0.012166532523802457,
          0.01458383680890215,
          0.014689748824527886,
          0.01357303050769755,
          0.013398243063672079,
          0.014580661200399322,
          0.011724278976733159,
          0.01320744900855477,
          0.011539827831204417,
          0.011398610499686644,
          0.011759041104907803,
          0.012427852902430014,
          0.011805195698082431,
          0.011031657741476927,
          0.012510302901133688,
          0.014239511332110884,
          0.014350217781316496,
          0.010656036986637184,
          0.012237827300424301,
          0.013429641911435135,
          0.013515523515321244,
          0.014098260932109263,
          0.01200557455606894,
          0.0130067377230352,
          0.013303309308109195,
          0.014002985236853806,
          0.012097503408500243,
          0.013356384689562071,
          0.01230739841696672,
          0.012810223816252036,
          0.010777082781028938,
          0.012673441084520794,
          0.011569356692823864,
          0.010785565949787265,
          0.010318269271495383,
          0.013233667340728514,
          0.011893557336245583,
          0.011899449840371017,
          0.01123935438930577,
          0.012174446526704179,
          0.010976051845716747,
          0.012063513110707792,
          0.009974890341481187,
          0.009890946214796411,
          0.011147415812986386,
          0.01063458564486732,
          0.009681734376547818,
          0.010886351314867117,
          0.01299838637689967,
          0.008378731285752991,
          0.011870424767870655,
          0.010620538174157987,
          0.011419402465905903,
          0.008645039017039354,
          0.011086649610833756,
          0.008925833895317505,
          0.010848115792834088,
          0.011261503395226637,
          0.008921051406921171,
          0.010697336269548012,
          0.008983245555914423,
          0.008454130633905006,
          0.00929333832335062,
          0.009437039304927654,
          0.0082378278992562,
          0.008959503007232205,
          0.008456547476095267,
          0.008442767865173598,
          0.009238423066695898,
          0.011735340022392292,
          0.008861479090014448,
          0.008901507312730707,
          0.009468863942433707,
          0.008577074810567614,
          0.007823060913257723,
          0.009714037404121901,
          0.007982559902073205,
          0.008720296263918905,
          0.00806602521308405,
          0.00913974703235749,
          0.008886850590632902,
          0.00866734243144797,
          0.006309288675595073,
          0.007606983968356619,
          0.00868239229815867,
          0.005636051978007935,
          0.008863609005521965,
          0.0075939469183383575,
          0.00752236106921113,
          0.006869459657361932,
          0.006188777753327305,
          0.006097606920980543,
          0.006472635788109689,
          0.0057600993466729805,
          0.00738346578785833,
          0.006230063544464438,
          0.006223263208307946,
          0.005850974777267451,
          0.005927052053050613,
          0.007186690154664787,
          0.005162900080344339,
          0.005634436006453952,
          0.005242985378692903,
          0.005026514996500661,
          0.004296955715964485,
          0.004202600631072755,
          0.00419406256589368,
          0.004306018009504051,
          0.005355258116473878,
          0.0045926124041471734,
          0.004462468410254966,
          0.005078267605057823,
          0.004372155355405557,
          0.0054869457802350224,
          0.004108923920860666,
          0.005134009301197601,
          0.003473562045015881,
          0.0032572766460039117,
          0.004585398866184828,
          0.0032070595680416527,
          0.0030665338070762077,
          0.0035472064132763877,
          0.0035685394044530343,
          0.002330335433552799,
          0.002763384272090656,
          0.0013740311667757507,
          3.2151672430897874e-57
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "ratio=1",
          "x": 1,
          "xanchor": "left",
          "xref": "x domain",
          "y": 1,
          "yanchor": "middle",
          "yref": "y"
         }
        ],
        "height": 500,
        "hovermode": "x unified",
        "shapes": [
         {
          "line": {
           "color": "gray",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 1,
          "y1": 1,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "subtitle": {
          "text": "Qwen 3 32B, Layer 32"
         },
         "text": "Variance Ratio (Across-Role / Within-Role) for Role PCs"
        },
        "width": 800,
        "xaxis": {
         "range": [
          0.5,
          10
         ],
         "tickvals": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "title": {
          "text": "Principal Component"
         }
        },
        "yaxis": {
         "title": {
          "text": "Variance Ratio"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"82e91a60-9138-43f6-bdd1-5f283cf7a239\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"82e91a60-9138-43f6-bdd1-5f283cf7a239\")) {                    Plotly.newPlot(                        \"82e91a60-9138-43f6-bdd1-5f283cf7a239\",                        [{\"line\":{\"color\":\"steelblue\",\"width\":2},\"mode\":\"lines\",\"name\":\"PC Ratio\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463],\"y\":[2.2010477000626882,1.3804334043631028,0.6082354801351637,0.9170348466616239,0.7524499560717456,0.616383941785323,0.38062400319240086,0.4526048460960973,0.5818041752690796,0.27708603950422683,0.3283896678669817,0.5469995842342527,0.25890228123506104,0.32465272319339195,0.2785382107391128,0.3743123638418712,0.3238420807162915,0.20054635452745287,0.2969642876924906,0.22139312960586854,0.32104999959657876,0.280089189066926,0.32302596508377296,0.231398401118349,0.24433969800816363,0.31441074268959623,0.28729882409051133,0.2990585519409325,0.3101201299948332,0.2907572930212292,0.1816033542007657,0.13471299359619646,0.17830133203138884,0.14320321686485804,0.257942763692916,0.194945263830163,0.1814672958576042,0.19459874262271468,0.29195620477170087,0.22803427144332095,0.20883850241709032,0.16310588003996448,0.18513547598848437,0.19249094333158387,0.19635444270282304,0.19306765905048534,0.17329648030638484,0.23513445602895433,0.16841144859090756,0.17233266406985098,0.15816171942571197,0.21220359205082037,0.2172377342421748,0.1763515100462525,0.12320383703663029,0.1681175331034806,0.12143257617546932,0.16033355321052298,0.1713147808829329,0.13405024693704132,0.14004537621767596,0.160733258062281,0.1561972089323043,0.20195683712977755,0.15108661561780576,0.13892219410392853,0.15510297599147221,0.16884180633290904,0.18427259916935224,0.15552579022369195,0.12823740308954842,0.16817992529973622,0.13229781429842333,0.10926382541090476,0.183808614091191,0.14188073532278878,0.11719259763295439,0.12181441501251784,0.1457187909975081,0.09651909890675578,0.11904830138081639,0.11810609258496933,0.1152812393451234,0.11618034029735848,0.13298044544274534,0.09396562965922281,0.12604391331728332,0.11448344132032116,0.11782987252046195,0.10581447012684846,0.10497153314831952,0.10516785828417693,0.11866991651898076,0.12157306160238912,0.10108467598414567,0.10728365835291116,0.09377734690932364,0.10572851595807772,0.09783387704538167,0.11105302702562073,0.07712407243681937,0.08981423230334326,0.08923871856478927,0.08859040988643774,0.09327538029748673,0.0792945348888424,0.08815211328554634,0.06948693021201054,0.08951405588770585,0.08343661148062036,0.06370672434428265,0.07223648181289075,0.09962725388173406,0.07049471393959061,0.09719519124425677,0.07890379007747139,0.09663308415830621,0.10855854497162254,0.07035453971816243,0.0764613477755484,0.07521285328022329,0.09934646457227063,0.06276862688258994,0.06845176882859759,0.07138062514939762,0.07812678396131013,0.09523393063022291,0.06340225002450083,0.07736723278942827,0.05811247310378634,0.07039016265527902,0.07028191347991428,0.0769738988735395,0.07083284074218722,0.05859822874793398,0.06057398170072828,0.06615295798830025,0.055019631250069964,0.07218241506709637,0.052148584613214304,0.058265420902656066,0.059482870934925824,0.07837060471602256,0.05646925176469581,0.067586972026515,0.06552419526718477,0.06725636464909711,0.06642898223906792,0.04963943868326893,0.06681060424037896,0.05613346857152864,0.05561730041242526,0.05363842815327522,0.054136912890217076,0.061579832996281995,0.057674973833945424,0.057559857612782206,0.03761435016120936,0.05823702724165135,0.0549125925243701,0.05239702120543297,0.05607481061363961,0.06094631255411119,0.0490004760442996,0.04862488636942362,0.05266836144454537,0.04195017627890236,0.046322194004410976,0.05018550616142411,0.050103327395385415,0.0450580586780678,0.04404167915846234,0.05159436933990543,0.05425416150106929,0.04872032848715832,0.04576239744828475,0.04501859847507192,0.04665104745704733,0.0435921393353848,0.04200017066795617,0.04126515499354389,0.0361302694576209,0.040359197430580966,0.04268032134318599,0.0352713151915965,0.03948943434668668,0.037982352888794084,0.03475570341700396,0.032673133501708286,0.03936924702556372,0.035442014690388754,0.03826832169450394,0.036099380491476145,0.03177775899192608,0.03305194107171497,0.04275833096742579,0.041375302200737776,0.03342140499695452,0.03006781112990493,0.037466872940821,0.029488241580392285,0.03911713438922168,0.031728385882635844,0.037546934339377,0.029940652599196062,0.03140393705829416,0.030998967294216362,0.030556227180918327,0.031106347308764833,0.032000483740711544,0.03075670047117233,0.027364990373680037,0.030056892185551503,0.029951730155270972,0.03081020999570049,0.029907541786577133,0.034925492169446806,0.026906799594890986,0.03366220008981538,0.02684894207603221,0.03216443359493048,0.03140436527706664,0.03083869561871175,0.02767394839884009,0.030716600632102457,0.03107762658631519,0.032667399475600135,0.025354880147822622,0.025630428472991497,0.026587468595210037,0.02350895047916791,0.024647013104256515,0.02511160686408885,0.025776475124802016,0.02257652513661396,0.024260929999667297,0.023880597784408607,0.022164043535470107,0.024941767912513662,0.025232917007108464,0.02678662694460883,0.02683994695138632,0.029119230173907915,0.02638372874245112,0.025364392525545322,0.02432373113490226,0.018649776002586715,0.021617671207630907,0.023342196970777697,0.026121228641004985,0.023355499466748066,0.021087352919422292,0.025903342716826774,0.028039995328867414,0.026015459582746366,0.022237792740506204,0.018512884202427585,0.021842918004787583,0.02141373616630225,0.023761081673318484,0.02346402431836777,0.018131116775246307,0.023602104955891337,0.01884530722255993,0.023634689315543068,0.022215025673316353,0.02117928130250748,0.021280305047987422,0.02019745270560421,0.01885499598571462,0.02497423245651114,0.0189238814675283,0.02132732410219517,0.020147743169295778,0.01705364486308263,0.016127865047179012,0.020683208313631102,0.018286846422867955,0.0211363985155574,0.021946707389564432,0.017748257712978076,0.020338338276035692,0.019528075888746676,0.015366555307943128,0.019303513488075446,0.022077112754212903,0.018929970099990423,0.018483941309601456,0.018689931109413478,0.01828486406666899,0.01787026722767649,0.015377757713825576,0.01708211858285688,0.0169314081021218,0.016488567298894235,0.015504491139517351,0.016831216559434772,0.01719763038685947,0.01888804254674439,0.017959007666219096,0.016454372439385887,0.015343499149948236,0.015189791336781474,0.017254602294663288,0.012959695548282435,0.015644636141772753,0.018578501300881477,0.015071223652061372,0.01788691912351974,0.01585039447418723,0.015370748281397225,0.015277194538724987,0.013446454468416521,0.014057403832324514,0.014691564147862062,0.015611368694227157,0.013785231523822196,0.01645519435607535,0.02052445174838302,0.015090463158071839,0.01592854909081077,0.01368084530342687,0.014588073556746396,0.014776625809446954,0.016131220435063685,0.012357119590932995,0.012667108056050206,0.016163287005321766,0.012631964683366578,0.011412308541095902,0.012645883036566672,0.015132988804007855,0.015930445649523124,0.016744088284653003,0.01572773279491232,0.016429106258771337,0.012166532523802457,0.01458383680890215,0.014689748824527886,0.01357303050769755,0.013398243063672079,0.014580661200399322,0.011724278976733159,0.01320744900855477,0.011539827831204417,0.011398610499686644,0.011759041104907803,0.012427852902430014,0.011805195698082431,0.011031657741476927,0.012510302901133688,0.014239511332110884,0.014350217781316496,0.010656036986637184,0.012237827300424301,0.013429641911435135,0.013515523515321244,0.014098260932109263,0.01200557455606894,0.0130067377230352,0.013303309308109195,0.014002985236853806,0.012097503408500243,0.013356384689562071,0.01230739841696672,0.012810223816252036,0.010777082781028938,0.012673441084520794,0.011569356692823864,0.010785565949787265,0.010318269271495383,0.013233667340728514,0.011893557336245583,0.011899449840371017,0.01123935438930577,0.012174446526704179,0.010976051845716747,0.012063513110707792,0.009974890341481187,0.009890946214796411,0.011147415812986386,0.01063458564486732,0.009681734376547818,0.010886351314867117,0.01299838637689967,0.008378731285752991,0.011870424767870655,0.010620538174157987,0.011419402465905903,0.008645039017039354,0.011086649610833756,0.008925833895317505,0.010848115792834088,0.011261503395226637,0.008921051406921171,0.010697336269548012,0.008983245555914423,0.008454130633905006,0.00929333832335062,0.009437039304927654,0.0082378278992562,0.008959503007232205,0.008456547476095267,0.008442767865173598,0.009238423066695898,0.011735340022392292,0.008861479090014448,0.008901507312730707,0.009468863942433707,0.008577074810567614,0.007823060913257723,0.009714037404121901,0.007982559902073205,0.008720296263918905,0.00806602521308405,0.00913974703235749,0.008886850590632902,0.00866734243144797,0.006309288675595073,0.007606983968356619,0.00868239229815867,0.005636051978007935,0.008863609005521965,0.0075939469183383575,0.00752236106921113,0.006869459657361932,0.006188777753327305,0.006097606920980543,0.006472635788109689,0.0057600993466729805,0.00738346578785833,0.006230063544464438,0.006223263208307946,0.005850974777267451,0.005927052053050613,0.007186690154664787,0.005162900080344339,0.005634436006453952,0.005242985378692903,0.005026514996500661,0.004296955715964485,0.004202600631072755,0.00419406256589368,0.004306018009504051,0.005355258116473878,0.0045926124041471734,0.004462468410254966,0.005078267605057823,0.004372155355405557,0.0054869457802350224,0.004108923920860666,0.005134009301197601,0.003473562045015881,0.0032572766460039117,0.004585398866184828,0.0032070595680416527,0.0030665338070762077,0.0035472064132763877,0.0035685394044530343,0.002330335433552799,0.002763384272090656,0.0013740311667757507,3.2151672430897874e-57],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"shapes\":[{\"line\":{\"color\":\"gray\",\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"xref\":\"x domain\",\"y0\":1.0,\"y1\":1.0,\"yref\":\"y\"}],\"annotations\":[{\"showarrow\":false,\"text\":\"ratio=1\",\"x\":1,\"xanchor\":\"left\",\"xref\":\"x domain\",\"y\":1.0,\"yanchor\":\"middle\",\"yref\":\"y\"}],\"title\":{\"subtitle\":{\"text\":\"Qwen 3 32B, Layer 32\"},\"text\":\"Variance Ratio (Across-Role \\u002f Within-Role) for Role PCs\"},\"xaxis\":{\"title\":{\"text\":\"Principal Component\"},\"range\":[0.5,10],\"tickvals\":[1,2,3,4,5,6,7,8,9,10]},\"yaxis\":{\"title\":{\"text\":\"Variance Ratio\"}},\"width\":800,\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('82e91a60-9138-43f6-bdd1-5f283cf7a239');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create line plot of PC ratios\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line trace for all PC ratios\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(1, len(all_pc_ratios) + 1),\n",
    "    y=all_pc_ratios,\n",
    "    mode='lines',\n",
    "    name='PC Ratio',\n",
    "    line=dict(color='steelblue', width=2)\n",
    "))\n",
    "\n",
    "\n",
    "# Add horizontal reference line at ratio=1\n",
    "fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"gray\", \n",
    "              annotation_text=\"ratio=1\", annotation_position=\"right\")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Variance Ratio (Across-Role / Within-Role) for Role PCs\",\n",
    "        'subtitle': {\n",
    "            'text': f\"{model_name.replace('-', ' ').title()}, Layer {layer}\",\n",
    "        }\n",
    "    },\n",
    "    xaxis_title=\"Principal Component\",\n",
    "    yaxis_title=\"Variance Ratio\",\n",
    "    width=800,\n",
    "    height=500,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(range=[0.5, 10], tickvals=np.arange(1, 11))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(f\"/root/git/plots/{model_name}/roles/variance_ratios.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5eca2",
   "metadata": {},
   "source": [
    "## Conditional variance of role vectors based on distance from Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9db03468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([463, 5120])\n"
     ]
    }
   ],
   "source": [
    "role_vectors = torch.stack(pca_results['vectors']['pos_2'] + pca_results['vectors']['pos_3'])[:, layer, :]\n",
    "print(role_vectors.shape)\n",
    "\n",
    "pc1 = pca_results['pca_transformed'][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dw7pl9twyv",
   "metadata": {},
   "source": [
    "### Conditional variance in raw activation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "191e6z46xkk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RAW ACTIVATION SPACE: Two-Group Comparison\n",
      "============================================================\n",
      "PC1 threshold: -25\n",
      "Assistant-like roles (PC1 < -25): 128 samples\n",
      "Roleplay roles (PC1 >= -25): 335 samples\n",
      "\n",
      "Mean variance (Assistant-like): 0.064941\n",
      "Mean variance (Roleplay): 0.181641\n",
      "Variance ratio (Assistant/Roleplay): 0.3575 (35.75%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Two-group comparison: Assistant-like vs Roleplay\n",
    "# Using PC1 threshold of -25 (same as in 9_cone.ipynb)\n",
    "\n",
    "\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    threshold = 25\n",
    "    assistant_mask = pc1 > threshold\n",
    "    roleplay_mask = pc1 <= threshold\n",
    "else:\n",
    "    threshold = -25\n",
    "    assistant_mask = pc1 < threshold\n",
    "    roleplay_mask = pc1 >= threshold\n",
    "\n",
    "# Compute variance of raw activations for each group\n",
    "# role_vectors shape: [448, 4608]\n",
    "var_assistant_raw = torch.var(role_vectors[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_raw = torch.var(role_vectors[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_raw = var_assistant_raw / var_roleplay_raw\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like roles (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like): {var_assistant_raw:.6f}\")\n",
    "print(f\"Mean variance (Roleplay): {var_roleplay_raw:.6f}\")\n",
    "print(f\"Variance ratio (Assistant/Roleplay): {var_ratio_raw:.4f} ({var_ratio_raw*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "vm23njwgwk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE (PC1 projected out): Two-Group Comparison\n",
      "============================================================\n",
      "PC1 threshold: -25\n",
      "Assistant-like roles (PC1 < -25): 128 samples\n",
      "Roleplay roles (PC1 >= -25): 335 samples\n",
      "\n",
      "Mean variance (Assistant-like, PC1 removed): 0.064549\n",
      "Mean variance (Roleplay, PC1 removed): 0.154641\n",
      "Variance ratio (Assistant/Roleplay): 0.4174 (41.74%)\n",
      "\n",
      "This is analogous to the PC2-10 analysis in PC space.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Project out PC1 from raw activations\n",
    "# Get PC1 direction from PCA\n",
    "pc1_direction = torch.from_numpy(pca_results['pca'].components_[0]).float()\n",
    "\n",
    "# Project role_vectors onto PC1 and subtract\n",
    "# Formula: projection = (v · u) * u, where u is the unit vector (PC1 direction)\n",
    "pc1_loadings = (role_vectors.float() @ pc1_direction).unsqueeze(1)  # Shape: [448, 1]\n",
    "pc1_projections = pc1_loadings * pc1_direction.unsqueeze(0)  # Shape: [448, 4608]\n",
    "role_vectors_pc1_removed = role_vectors - pc1_projections\n",
    "\n",
    "# Compute variance with PC1 projected out\n",
    "var_assistant_raw_no_pc1 = torch.var(role_vectors_pc1_removed[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_raw_no_pc1 = torch.var(role_vectors_pc1_removed[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_raw_no_pc1 = var_assistant_raw_no_pc1 / var_roleplay_raw_no_pc1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE (PC1 projected out): Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like roles (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like, PC1 removed): {var_assistant_raw_no_pc1:.6f}\")\n",
    "print(f\"Mean variance (Roleplay, PC1 removed): {var_roleplay_raw_no_pc1:.6f}\")\n",
    "print(f\"Variance ratio (Assistant/Roleplay): {var_ratio_raw_no_pc1:.4f} ({var_ratio_raw_no_pc1*100:.2f}%)\")\n",
    "print(f\"\\nThis is analogous to the PC2-10 analysis in PC space.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "zv1prpa1y3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE: Quintile Analysis\n",
      "============================================================\n",
      "\n",
      "Quintile 1: PC1 ∈ [-37.98, -28.72]\n",
      "  Sample size: 93\n",
      "  Mean variance (full): 0.064453\n",
      "  Mean variance (PC1 removed): 0.063968\n",
      "\n",
      "Quintile 2: PC1 ∈ [-28.72, -18.80]\n",
      "  Sample size: 92\n",
      "  Mean variance (full): 0.078613\n",
      "  Mean variance (PC1 removed): 0.078442\n",
      "\n",
      "Quintile 3: PC1 ∈ [-18.80, -0.60]\n",
      "  Sample size: 93\n",
      "  Mean variance (full): 0.092285\n",
      "  Mean variance (PC1 removed): 0.091299\n",
      "\n",
      "Quintile 4: PC1 ∈ [-0.60, 27.07]\n",
      "  Sample size: 92\n",
      "  Mean variance (full): 0.146484\n",
      "  Mean variance (PC1 removed): 0.144131\n",
      "\n",
      "Quintile 5: PC1 ∈ [27.07, 92.81]\n",
      "  Sample size: 93\n",
      "  Mean variance (full): 0.188477\n",
      "  Mean variance (PC1 removed): 0.180360\n",
      "\n",
      "------------------------------------------------------------\n",
      "Variance ratio (Last/First quintile, full): 2.92x\n",
      "Variance ratio (Last/First quintile, PC1 removed): 2.82x\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Quintile analysis\n",
    "n_quintiles = 5\n",
    "quintile_edges = np.quantile(pc1, np.linspace(0, 1, n_quintiles + 1))\n",
    "quintile_variances = []\n",
    "quintile_variances_no_pc1 = []\n",
    "quintile_sizes = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Quintile Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(n_quintiles):\n",
    "    if i == 0:\n",
    "        mask = (pc1 >= quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    else:\n",
    "        mask = (pc1 > quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    \n",
    "    quintile_var = torch.var(role_vectors[mask], dim=0).mean().item()\n",
    "    quintile_var_no_pc1 = torch.var(role_vectors_pc1_removed[mask], dim=0).mean().item()\n",
    "    quintile_variances.append(quintile_var)\n",
    "    quintile_variances_no_pc1.append(quintile_var_no_pc1)\n",
    "    quintile_sizes.append(mask.sum())\n",
    "    \n",
    "    print(f\"\\nQuintile {i+1}: PC1 ∈ [{quintile_edges[i]:.2f}, {quintile_edges[i+1]:.2f}]\")\n",
    "    print(f\"  Sample size: {mask.sum()}\")\n",
    "    print(f\"  Mean variance (full): {quintile_var:.6f}\")\n",
    "    print(f\"  Mean variance (PC1 removed): {quintile_var_no_pc1:.6f}\")\n",
    "\n",
    "# Calculate ratios between first and last quintile\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    quintile_ratio = quintile_variances[0] / quintile_variances[-1]\n",
    "    quintile_ratio_no_pc1 = quintile_variances_no_pc1[0] / quintile_variances_no_pc1[-1]\n",
    "else:\n",
    "    quintile_ratio = quintile_variances[-1] / quintile_variances[0]\n",
    "    quintile_ratio_no_pc1 = quintile_variances_no_pc1[-1] / quintile_variances_no_pc1[0]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(f\"Variance ratio (Last/First quintile, full): {quintile_ratio:.2f}x\")\n",
    "print(f\"Variance ratio (Last/First quintile, PC1 removed): {quintile_ratio_no_pc1:.2f}x\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d7kwaevse0w",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAW ACTIVATION SPACE: Distance from Center Correlation\n",
      "============================================================\n",
      "Correlation between PC1 and L2 distance from mean (full):\n",
      "  r = 0.6461\n",
      "  p-value = 4.665e-56\n",
      "  Highly significant (p < 0.001)\n",
      "\n",
      "Correlation between PC1 and L2 distance from mean (PC1 removed):\n",
      "  r = 0.5555\n",
      "  p-value = 7.669e-39\n",
      "  Highly significant (p < 0.001)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Distance from center correlation\n",
    "# Compute mean of raw activations\n",
    "role_vectors_mean = role_vectors.mean(dim=0)\n",
    "role_vectors_pc1_removed_mean = role_vectors_pc1_removed.mean(dim=0)\n",
    "\n",
    "# Compute L2 distance from mean for each role\n",
    "distances_raw = torch.norm(role_vectors.float() - role_vectors_mean, p=2, dim=1).numpy()\n",
    "distances_raw_no_pc1 = torch.norm(role_vectors_pc1_removed - role_vectors_pc1_removed_mean, p=2, dim=1).numpy()\n",
    "\n",
    "# Calculate correlation with PC1\n",
    "correlation_raw, p_value_raw = pearsonr(pc1, distances_raw)\n",
    "correlation_raw_no_pc1, p_value_raw_no_pc1 = pearsonr(pc1, distances_raw_no_pc1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Distance from Center Correlation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Correlation between PC1 and L2 distance from mean (full):\")\n",
    "print(f\"  r = {correlation_raw:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw:.3e}\")\n",
    "if p_value_raw < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "\n",
    "print(f\"\\nCorrelation between PC1 and L2 distance from mean (PC1 removed):\")\n",
    "print(f\"  r = {correlation_raw_no_pc1:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw_no_pc1:.3e}\")\n",
    "if p_value_raw_no_pc1 < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw_no_pc1 < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lsye2ajp11",
   "metadata": {},
   "source": [
    "### Per-PC analysis: Correlation between each PC and distance in remaining PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0tedpgpspjp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Correlation between each PC and distance in remaining PC space\n",
      "======================================================================\n",
      "PC 1: r =  0.5323, p = 3.086e-35 ***\n",
      "PC 2: r =  0.0133, p = 7.745e-01 \n",
      "PC 3: r =  0.1967, p = 2.023e-05 ***\n",
      "PC 4: r = -0.2562, p = 2.261e-08 ***\n",
      "PC 5: r = -0.1749, p = 1.558e-04 ***\n",
      "PC 6: r =  0.2305, p = 5.302e-07 ***\n",
      "PC 7: r =  0.1738, p = 1.715e-04 ***\n",
      "PC 8: r =  0.0335, p = 4.717e-01 \n",
      "PC 9: r =  0.1491, p = 1.292e-03 **\n",
      "PC10: r = -0.0839, p = 7.116e-02 \n",
      "======================================================================\n",
      "\n",
      "PC1 correlation: 0.5323\n",
      "Mean correlation (PC2-10): 0.0313\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each of the top 10 PCs, calculate:\n",
    "# 1. The correlation between that PC and distance from center in all OTHER PCs\n",
    "# 2. This tells us if the pattern we see with PC1 generalizes to other PCs\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "n_pcs_to_analyze = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Correlation between each PC and distance in remaining PC space\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "correlations = []\n",
    "p_values = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_analyze):\n",
    "    # Get the PC values\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get all other PCs (excluding current PC)\n",
    "    other_pcs = np.delete(pca_transformed, pc_idx, axis=1)\n",
    "    \n",
    "    # Calculate distance from center in the remaining PC space\n",
    "    other_pcs_mean = other_pcs.mean(axis=0)\n",
    "    distances = np.linalg.norm(other_pcs - other_pcs_mean, axis=1)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr, p_val = pearsonr(pc_values, distances)\n",
    "    correlations.append(corr)\n",
    "    p_values.append(p_val)\n",
    "    \n",
    "    # Print results\n",
    "    sig_marker = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n",
    "    print(f\"PC{pc_idx+1:2d}: r = {corr:7.4f}, p = {p_val:.3e} {sig_marker}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPC1 correlation: {correlations[0]:.4f}\")\n",
    "print(f\"Mean correlation (PC2-10): {np.mean(correlations[1:]):.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4w4stk4a567",
   "metadata": {},
   "source": [
    "### Conditional variance in PC2-10 based on position along each PC\n",
    "\n",
    "This analysis shows whether the pattern of \"extreme positions → high variance in other PCs\" is unique to PC1 or generalizes to other PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "x42qo16zp6k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Conditional Variance in PC2-10 based on position along each PC\n",
      "================================================================================\n",
      "For each PC, we split roles by median and compute variance in PC2-10 (excluding that PC)\n",
      "--------------------------------------------------------------------------------\n",
      "PC 1: High=231 samples, Low=232 samples\n",
      "      Var(high) =  299.327, Var(low) =   95.361, Ratio = 3.139\n",
      "PC 2: High=231 samples, Low=232 samples\n",
      "      Var(high) =  198.091, Var(low) =  141.907, Ratio = 1.396\n",
      "PC 3: High=231 samples, Low=232 samples\n",
      "      Var(high) =  193.452, Var(low) =  172.838, Ratio = 1.119\n",
      "PC 4: High=231 samples, Low=232 samples\n",
      "      Var(high) =  175.638, Var(low) =  215.651, Ratio = 1.228\n",
      "PC 5: High=231 samples, Low=232 samples\n",
      "      Var(high) =  197.987, Var(low) =  208.481, Ratio = 1.053\n",
      "PC 6: High=231 samples, Low=232 samples\n",
      "      Var(high) =  241.420, Var(low) =  173.042, Ratio = 1.395\n",
      "PC 7: High=231 samples, Low=232 samples\n",
      "      Var(high) =  252.342, Var(low) =  163.154, Ratio = 1.547\n",
      "PC 8: High=231 samples, Low=232 samples\n",
      "      Var(high) =  204.059, Var(low) =  217.791, Ratio = 1.067\n",
      "PC 9: High=231 samples, Low=232 samples\n",
      "      Var(high) =  211.373, Var(low) =  213.426, Ratio = 1.010\n",
      "PC10: High=231 samples, Low=232 samples\n",
      "      Var(high) =  188.787, Var(low) =  237.410, Ratio = 1.258\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "  PC1 variance ratio: 3.139\n",
      "  Mean variance ratio for PC2-10: 1.230\n",
      "  Max variance ratio (excluding PC1): 1.547 (PC7)\n",
      "\n",
      "  → Shows whether PC1 is unique in having high-variance 'other dimensions' for extreme positions\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each PC, split roles into two groups (high/low) and compute variance in PC2-10 (excluding that PC)\n",
    "# This tests if extreme positions on PC_i lead to high variance in other PCs\n",
    "\n",
    "n_pcs_to_test = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Conditional Variance in PC2-10 based on position along each PC\")\n",
    "print(\"=\" * 80)\n",
    "print(\"For each PC, we split roles by median and compute variance in PC2-10 (excluding that PC)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "variance_ratios = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_test):\n",
    "    # Split by median on this PC\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    median_val = np.median(pc_values)\n",
    "    high_mask = pc_values > median_val\n",
    "    low_mask = pc_values <= median_val\n",
    "    \n",
    "    # Get PC2-10, excluding current PC if it's in that range\n",
    "    if pc_idx == 0:\n",
    "        # For PC1, we want variance in PC2-10\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    elif 1 <= pc_idx < 10:\n",
    "        # For PC2-9, exclude that PC from PC2-10\n",
    "        pc_indices = [i for i in range(1, 10) if i != pc_idx]\n",
    "        other_pcs = pca_transformed[:, pc_indices]\n",
    "    else:\n",
    "        # For PC10, use PC2-9\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    \n",
    "    # Compute variance for each group\n",
    "    var_high = np.var(other_pcs[high_mask], axis=0).mean()\n",
    "    var_low = np.var(other_pcs[low_mask], axis=0).mean()\n",
    "    \n",
    "    ratio = max(var_high, var_low) / min(var_high, var_low)\n",
    "    variance_ratios.append(ratio)\n",
    "    \n",
    "    print(f\"PC{pc_idx+1:2d}: High={high_mask.sum():3d} samples, Low={low_mask.sum():3d} samples\")\n",
    "    print(f\"      Var(high) = {var_high:8.3f}, Var(low) = {var_low:8.3f}, Ratio = {ratio:.3f}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  PC1 variance ratio: {variance_ratios[0]:.3f}\")\n",
    "print(f\"  Mean variance ratio for PC2-10: {np.mean(variance_ratios[1:]):.3f}\")\n",
    "print(f\"  Max variance ratio (excluding PC1): {np.max(variance_ratios[1:]):.3f} (PC{np.argmax(variance_ratios[1:])+2})\")\n",
    "print(\"\\n  → Shows whether PC1 is unique in having high-variance 'other dimensions' for extreme positions\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "psa4fpzrfl8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total roles: 463\n",
      "pca_transformed shape: (463, 463)\n"
     ]
    }
   ],
   "source": [
    "# Create role labels from pca_results\n",
    "def get_role_labels_from_pca(pca_results):\n",
    "    labels = []\n",
    "    if 'pos_2' in pca_results['roles'].keys():\n",
    "        pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "        labels.extend(pos_2_roles)\n",
    "    if 'pos_3' in pca_results['roles'].keys():\n",
    "        pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "        labels.extend(pos_3_roles)\n",
    "    return labels\n",
    "\n",
    "role_labels = get_role_labels_from_pca(pca_results)\n",
    "print(f\"Total roles: {len(role_labels)}\")\n",
    "print(f\"pca_transformed shape: {pca_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d0ogly4i9nk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Top and Bottom Roles for Each PC\n",
      "================================================================================\n",
      "\n",
      "PC1:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Leviathan                      (PC1 =   92.81)\n",
      "    2. Eldritch                       (PC1 =   88.94)\n",
      "    3. Wraith                         (PC1 =   88.20)\n",
      "    4. Void                           (PC1 =   81.61)\n",
      "    5. Aberration                     (PC1 =   81.02)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Validator                      (PC1 =  -37.98)\n",
      "    2. Evaluator                      (PC1 =  -37.44)\n",
      "    3. Screener                       (PC1 =  -37.33)\n",
      "    4. Examiner                       (PC1 =  -36.99)\n",
      "    5. Planner                        (PC1 =  -36.91)\n",
      "\n",
      "PC2:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Procrastinator                 (PC2 =   83.84)\n",
      "    2. Comedian                       (PC2 =   76.47)\n",
      "    3. Adolescent                     (PC2 =   74.19)\n",
      "    4. Teenager                       (PC2 =   73.62)\n",
      "    5. Gossip                         (PC2 =   68.81)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Shaman                         (PC2 =  -54.11)\n",
      "    2. Mystic                         (PC2 =  -51.41)\n",
      "    3. Crystalline                    (PC2 =  -47.85)\n",
      "    4. Spirit                         (PC2 =  -45.49)\n",
      "    5. Avatar                         (PC2 =  -44.38)\n",
      "\n",
      "PC3:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Virus                          (PC3 =   41.04)\n",
      "    2. Robot                          (PC3 =   40.91)\n",
      "    3. Saboteur                       (PC3 =   39.24)\n",
      "    4. Hacker                         (PC3 =   37.93)\n",
      "    5. Parasite                       (PC3 =   36.42)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Caregiver                      (PC3 =  -53.77)\n",
      "    2. Counselor                      (PC3 =  -53.41)\n",
      "    3. Empath                         (PC3 =  -50.94)\n",
      "    4. Therapist                      (PC3 =  -50.84)\n",
      "    5. Widow                          (PC3 =  -48.19)\n",
      "\n",
      "PC4:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Anarchist                      (PC4 =   63.60)\n",
      "    2. Revolutionary                  (PC4 =   60.40)\n",
      "    3. Provocateur                    (PC4 =   53.29)\n",
      "    4. Rebel                          (PC4 =   51.73)\n",
      "    5. Contrarian                     (PC4 =   48.92)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Infant                         (PC4 =  -70.96)\n",
      "    2. Toddler                        (PC4 =  -56.48)\n",
      "    3. Caveman                        (PC4 =  -45.30)\n",
      "    4. Coral Reef                     (PC4 =  -39.22)\n",
      "    5. Sommelier                      (PC4 =  -35.17)\n",
      "\n",
      "PC5:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Smuggler                       (PC5 =   35.07)\n",
      "    2. Soldier                        (PC5 =   34.49)\n",
      "    3. Veteran                        (PC5 =   32.01)\n",
      "    4. Vigilante                      (PC5 =   29.58)\n",
      "    5. Chef                           (PC5 =   28.41)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Infant                         (PC5 =  -68.57)\n",
      "    2. Proofreader                    (PC5 =  -50.59)\n",
      "    3. Toddler                        (PC5 =  -49.77)\n",
      "    4. Proofreader                    (PC5 =  -47.76)\n",
      "    5. Void                           (PC5 =  -35.42)\n",
      "\n",
      "PC6:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Caveman                        (PC6 =   46.80)\n",
      "    2. Infant                         (PC6 =   40.69)\n",
      "    3. Prey                           (PC6 =   39.02)\n",
      "    4. Anarchist                      (PC6 =   34.70)\n",
      "    5. Zealot                         (PC6 =   34.52)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Absurdist                      (PC6 =  -37.33)\n",
      "    2. Comedian                       (PC6 =  -37.09)\n",
      "    3. Comedian                       (PC6 =  -30.89)\n",
      "    4. Trickster                      (PC6 =  -30.66)\n",
      "    5. Jester                         (PC6 =  -29.78)\n",
      "\n",
      "PC7:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Infant                         (PC7 =   77.53)\n",
      "    2. Toddler                        (PC7 =   57.36)\n",
      "    3. Anarchist                      (PC7 =   46.85)\n",
      "    4. Naturalist                     (PC7 =   36.91)\n",
      "    5. Mycorrhizal                    (PC7 =   34.23)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Proofreader                    (PC7 =  -30.59)\n",
      "    2. Revenant                       (PC7 =  -30.55)\n",
      "    3. Proofreader                    (PC7 =  -29.99)\n",
      "    4. Demon                          (PC7 =  -27.21)\n",
      "    5. Warrior                        (PC7 =  -26.47)\n",
      "\n",
      "PC8:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Caveman                        (PC8 =   63.40)\n",
      "    2. Toddler                        (PC8 =   37.59)\n",
      "    3. Pirate                         (PC8 =   35.76)\n",
      "    4. Bard                           (PC8 =   31.97)\n",
      "    5. Infant                         (PC8 =   28.28)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Virus                          (PC8 =  -48.21)\n",
      "    2. Virus                          (PC8 =  -44.66)\n",
      "    3. Parasite                       (PC8 =  -41.07)\n",
      "    4. Proofreader                    (PC8 =  -35.48)\n",
      "    5. Crystalline                    (PC8 =  -33.75)\n",
      "\n",
      "PC9:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Traditionalist                 (PC9 =   45.22)\n",
      "    2. Purist                         (PC9 =   39.99)\n",
      "    3. Stoic                          (PC9 =   38.06)\n",
      "    4. Zealot                         (PC9 =   36.58)\n",
      "    5. Sommelier                      (PC9 =   35.87)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Mycorrhizal                    (PC9 =  -25.25)\n",
      "    2. Tree                           (PC9 =  -23.22)\n",
      "    3. Amnesiac                       (PC9 =  -22.40)\n",
      "    4. Prey                           (PC9 =  -20.22)\n",
      "    5. Void                           (PC9 =  -18.84)\n",
      "\n",
      "PC10:\n",
      "  Top 5 (highest loadings):\n",
      "    1. Exile                          (PC10 =   26.83)\n",
      "    2. Amnesiac                       (PC10 =   25.27)\n",
      "    3. Simulacrum                     (PC10 =   25.21)\n",
      "    4. Linguist                       (PC10 =   24.39)\n",
      "    5. Widow                          (PC10 =   24.25)\n",
      "  Bottom 5 (lowest loadings):\n",
      "    1. Toddler                        (PC10 =  -41.64)\n",
      "    2. Infant                         (PC10 =  -39.75)\n",
      "    3. Caveman                        (PC10 =  -37.26)\n",
      "    4. Shaman                         (PC10 =  -24.06)\n",
      "    5. Supervisor                     (PC10 =  -22.25)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Show top/bottom roles for each PC\n",
    "n_pcs_to_show = 10  # Show first 5 PCs\n",
    "n_roles_to_show = 5  # Show top/bottom 5 roles\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Top and Bottom Roles for Each PC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pc_idx in range(n_pcs_to_show):\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get indices of top and bottom roles\n",
    "    top_indices = np.argsort(pc_values)[-n_roles_to_show:][::-1]\n",
    "    bottom_indices = np.argsort(pc_values)[:n_roles_to_show]\n",
    "    \n",
    "    print(f\"\\nPC{pc_idx+1}:\")\n",
    "    print(f\"  Top {n_roles_to_show} (highest loadings):\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "    \n",
    "    print(f\"  Bottom {n_roles_to_show} (lowest loadings):\")\n",
    "    for i, idx in enumerate(bottom_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0108b",
   "metadata": {},
   "source": [
    "## Default loading along each PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20166672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant projection shape: (1, 463)\n",
      "\n",
      "================================================================================\n",
      "Assistant (default) position relative to role distribution on each PC\n",
      "================================================================================\n",
      "\n",
      "PC1:\n",
      "  Range: [  -37.98,    92.81]\n",
      "  Assistant:   -29.13\n",
      "  Relative position: 0.068 (0=min, 1=max)\n",
      "  Min boundary distance: 0.068\n",
      "  Position: near minimum\n",
      "\n",
      "PC2:\n",
      "  Range: [  -54.11,    83.84]\n",
      "  Assistant:    -0.19\n",
      "  Relative position: 0.391 (0=min, 1=max)\n",
      "  Min boundary distance: 0.391\n",
      "  Position: below center\n",
      "\n",
      "PC3:\n",
      "  Range: [  -53.77,    41.04]\n",
      "  Assistant:    -6.64\n",
      "  Relative position: 0.497 (0=min, 1=max)\n",
      "  Min boundary distance: 0.497\n",
      "  Position: centered\n",
      "\n",
      "PC4:\n",
      "  Range: [  -70.96,    63.60]\n",
      "  Assistant:     0.96\n",
      "  Relative position: 0.534 (0=min, 1=max)\n",
      "  Min boundary distance: 0.466\n",
      "  Position: centered\n",
      "\n",
      "PC5:\n",
      "  Range: [  -68.57,    35.07]\n",
      "  Assistant:    -6.16\n",
      "  Relative position: 0.602 (0=min, 1=max)\n",
      "  Min boundary distance: 0.398\n",
      "  Position: above center\n",
      "\n",
      "PC6:\n",
      "  Range: [  -37.33,    46.80]\n",
      "  Assistant:     2.00\n",
      "  Relative position: 0.467 (0=min, 1=max)\n",
      "  Min boundary distance: 0.467\n",
      "  Position: centered\n",
      "\n",
      "PC7:\n",
      "  Range: [  -30.59,    77.53]\n",
      "  Assistant:    -1.23\n",
      "  Relative position: 0.272 (0=min, 1=max)\n",
      "  Min boundary distance: 0.272\n",
      "  Position: below center\n",
      "\n",
      "PC8:\n",
      "  Range: [  -48.21,    63.40]\n",
      "  Assistant:     7.67\n",
      "  Relative position: 0.501 (0=min, 1=max)\n",
      "  Min boundary distance: 0.499\n",
      "  Position: centered\n",
      "\n",
      "PC9:\n",
      "  Range: [  -25.25,    45.22]\n",
      "  Assistant:    -0.08\n",
      "  Relative position: 0.357 (0=min, 1=max)\n",
      "  Min boundary distance: 0.357\n",
      "  Position: below center\n",
      "\n",
      "PC10:\n",
      "  Range: [  -41.64,    26.83]\n",
      "  Assistant:    -4.50\n",
      "  Relative position: 0.542 (0=min, 1=max)\n",
      "  Min boundary distance: 0.458\n",
      "  Position: centered\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# get default activation and project\n",
    "default_vectors = torch.load(f\"{base_dir}/roles_240/default_vectors.pt\")\n",
    "assistant_layer_activation = default_vectors['activations']['default_1'][layer, :].float().reshape(1, -1)\n",
    "\n",
    "asst_scaled = pca_results['scaler'].transform(assistant_layer_activation.numpy())\n",
    "asst_projected = pca_results['pca'].transform(asst_scaled)\n",
    "print(f\"Assistant projection shape: {asst_projected.shape}\")\n",
    "\n",
    "# Compare each PC loading with the min, max loading of that PC across all roles\n",
    "n_pcs = 10  # or however many you want to analyze\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Assistant (default) position relative to role distribution on each PC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pc_idx in range(n_pcs):\n",
    "    # Get assistant's loading on this PC\n",
    "    asst_loading = asst_projected[0, pc_idx]\n",
    "    \n",
    "    # Get all role loadings on this PC\n",
    "    all_loadings = pca_transformed[:, pc_idx]\n",
    "    min_loading = all_loadings.min()\n",
    "    max_loading = all_loadings.max()\n",
    "    \n",
    "    # Calculate relative position (0 = at min, 1 = at max)\n",
    "    if max_loading != min_loading:\n",
    "        relative_position = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    else:\n",
    "        relative_position = 0.5\n",
    "    \n",
    "    # Distance to nearest boundary (normalized)\n",
    "    dist_to_min = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    dist_to_max = (max_loading - asst_loading) / (max_loading - min_loading)\n",
    "    min_boundary_dist = min(dist_to_min, dist_to_max)\n",
    "    \n",
    "    print(f\"\\nPC{pc_idx+1}:\")\n",
    "    print(f\"  Range: [{min_loading:8.2f}, {max_loading:8.2f}]\")\n",
    "    print(f\"  Assistant: {asst_loading:8.2f}\")\n",
    "    print(f\"  Relative position: {relative_position:.3f} (0=min, 1=max)\")\n",
    "    print(f\"  Min boundary distance: {min_boundary_dist:.3f}\")\n",
    "    \n",
    "    # Interpret position\n",
    "    if relative_position < 0.25:\n",
    "        position_desc = \"near minimum\"\n",
    "    elif relative_position < 0.45:\n",
    "        position_desc = \"below center\"\n",
    "    elif relative_position < 0.55:\n",
    "        position_desc = \"centered\"\n",
    "    elif relative_position < 0.75:\n",
    "        position_desc = \"above center\"\n",
    "    else:\n",
    "        position_desc = \"near maximum\"\n",
    "    print(f\"  Position: {position_desc}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669f17e",
   "metadata": {},
   "source": [
    "## Overall activation variance captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd47d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['activations', 'target_layer'])\n",
      "dict_keys(['projected', 'explained_variance_ratio', 'pca_n_components', 'pca_explained_variance_from_fit', 'target_layer', 'pca_config_path'])\n",
      "dict_keys(['projected', 'explained_variance_ratio', 'pca_n_components', 'pca_explained_variance_from_fit', 'target_layer', 'pca_config_path'])\n"
     ]
    }
   ],
   "source": [
    "# load in the mean_activations.pt and the role/trait projections...\n",
    "\n",
    "act_dir = f\"/workspace/{model_name}/dataset_activations/lmsys_10000\"\n",
    "\n",
    "chat_raw = torch.load(f\"{act_dir}/mean_activations.pt\")\n",
    "chat_roles = torch.load(f\"{act_dir}/roles_projections.pt\", weights_only=False)\n",
    "chat_traits = torch.load(f\"{act_dir}/traits_projections.pt\", weights_only=False)\n",
    "\n",
    "print(chat_raw.keys())\n",
    "print(chat_roles.keys())\n",
    "print(chat_traits.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d1a2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw activations shape: torch.Size([18950, 5120])\n",
      "\n",
      "Total variance in raw activations: 8603.54\n",
      "\n",
      "Role subspace:\n",
      "  Variance captured: 2888.04\n",
      "  Variance explained: 0.3357 (33.57%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n",
      "/root/git/persona-subspace/.venv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait subspace:\n",
      "  Variance captured: 2316.71\n",
      "  Variance explained: 0.2693 (26.93%)\n",
      "\n",
      "============================================================\n",
      "Summary: Variance Explained by Subspaces\n",
      "============================================================\n",
      "Role subspace:  33.57%\n",
      "Trait subspace: 26.93%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Get the raw activations\n",
    "raw_activations = chat_raw['activations'][:, layer, :].float()\n",
    "print(f\"Raw activations shape: {raw_activations.shape}\")\n",
    "\n",
    "# Calculate total variance in raw activations\n",
    "total_var = torch.var(raw_activations, dim=0).sum().item()\n",
    "print(f\"\\nTotal variance in raw activations: {total_var:.2f}\")\n",
    "\n",
    "# For roles: reconstruct from PCA space back to raw space\n",
    "roles_projected = chat_roles['projected']  # Shape: [18950, 463]\n",
    "# Inverse transform: unstandardize and inverse PCA\n",
    "roles_reconstructed = pca_results['pca'].inverse_transform(roles_projected)  # This gives standardized features\n",
    "roles_reconstructed = pca_results['scaler'].inverse_transform(roles_reconstructed)  # Unstandardize\n",
    "roles_reconstructed = torch.from_numpy(roles_reconstructed).float()\n",
    "\n",
    "# Calculate variance in reconstructed activations\n",
    "roles_var = torch.var(roles_reconstructed, dim=0).sum().item()\n",
    "roles_variance_explained = roles_var / total_var\n",
    "\n",
    "print(f\"\\nRole subspace:\")\n",
    "print(f\"  Variance captured: {roles_var:.2f}\")\n",
    "print(f\"  Variance explained: {roles_variance_explained:.4f} ({roles_variance_explained*100:.2f}%)\")\n",
    "\n",
    "# For traits: load trait PCA results and do the same\n",
    "trait_pca_results = torch.load(f\"{base_dir}/traits_240/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n",
    "traits_projected = chat_traits['projected']  # Shape: [18950, 240]\n",
    "\n",
    "traits_reconstructed = trait_pca_results['pca'].inverse_transform(traits_projected)\n",
    "traits_reconstructed = trait_pca_results['scaler'].inverse_transform(traits_reconstructed)\n",
    "traits_reconstructed = torch.from_numpy(traits_reconstructed).float()\n",
    "\n",
    "# Calculate variance in reconstructed activations\n",
    "traits_var = torch.var(traits_reconstructed, dim=0).sum().item()\n",
    "traits_variance_explained = traits_var / total_var\n",
    "\n",
    "print(f\"\\nTrait subspace:\")\n",
    "print(f\"  Variance captured: {traits_var:.2f}\")\n",
    "print(f\"  Variance explained: {traits_variance_explained:.4f} ({traits_variance_explained*100:.2f}%)\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary: Variance Explained by Subspaces\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Role subspace:  {roles_variance_explained*100:.2f}%\")\n",
    "print(f\"Trait subspace: {traits_variance_explained*100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15tubzaaejf",
   "metadata": {},
   "source": [
    "### Conditional variance in LMSYS chat samples based on PC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "snh5xz24paq",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for @: 'numpy.ndarray' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m scaled_raw_activations = pca_results[\u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m].transform(raw_activations.float().numpy())\n\u001b[32m     22\u001b[39m pc1_direction = torch.from_numpy(pca_results[\u001b[33m'\u001b[39m\u001b[33mpca\u001b[39m\u001b[33m'\u001b[39m].components_[\u001b[32m0\u001b[39m]).float()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m pc1_loadings = (\u001b[43mscaled_raw_activations\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mpc1_direction\u001b[49m).unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m     24\u001b[39m pc1_projections = pc1_loadings * pc1_direction.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m     25\u001b[39m raw_activations_pc1_removed = raw_activations - pc1_projections\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for @: 'numpy.ndarray' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "# Use the already-projected LMSYS chat samples to get PC1 values\n",
    "# roles_projected already contains the PC scores for all samples\n",
    "lmsys_pc1 = roles_projected[:, 0]\n",
    "\n",
    "# Use the same threshold as for role vectors\n",
    "# Create assistant-like and roleplay masks based on PC1\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    lmsys_assistant_mask = lmsys_pc1 > threshold\n",
    "    lmsys_roleplay_mask = lmsys_pc1 <= threshold\n",
    "else:\n",
    "    lmsys_assistant_mask = lmsys_pc1 < threshold\n",
    "    lmsys_roleplay_mask = lmsys_pc1 >= threshold\n",
    "\n",
    "# Compute variance for each group (full raw activation space)\n",
    "var_lmsys_assistant = torch.var(raw_activations[lmsys_assistant_mask], dim=0).mean().item()\n",
    "var_lmsys_roleplay = torch.var(raw_activations[lmsys_roleplay_mask], dim=0).mean().item()\n",
    "var_ratio_lmsys = var_lmsys_assistant / var_lmsys_roleplay\n",
    "\n",
    "# Project out PC1 from raw activations\n",
    "scaled_raw_activations = pca_results['scaler'].transform(raw_activations.float().numpy())\n",
    "\n",
    "pc1_direction = torch.from_numpy(pca_results['pca'].components_[0]).float()\n",
    "pc1_loadings = (scaled_raw_activations @ pc1_direction).unsqueeze(1)\n",
    "pc1_projections = pc1_loadings * pc1_direction.unsqueeze(0)\n",
    "raw_activations_pc1_removed = raw_activations - pc1_projections\n",
    "\n",
    "# Compute variance with PC1 projected out\n",
    "var_lmsys_assistant_no_pc1 = torch.var(raw_activations_pc1_removed[lmsys_assistant_mask], dim=0).mean().item()\n",
    "var_lmsys_roleplay_no_pc1 = torch.var(raw_activations_pc1_removed[lmsys_roleplay_mask], dim=0).mean().item()\n",
    "var_ratio_lmsys_no_pc1 = var_lmsys_assistant_no_pc1 / var_lmsys_roleplay_no_pc1\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"LMSYS CHAT DATASET: Conditional Variance Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like samples (PC1 {'>' if model_name == 'gemma-2-27b' else '<'} {threshold}): {lmsys_assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay samples (PC1 {'<=' if model_name == 'gemma-2-27b' else '>='} {threshold}): {lmsys_roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nFull activation space:\")\n",
    "print(f\"  Variance (Assistant-like): {var_lmsys_assistant:.6f}\")\n",
    "print(f\"  Variance (Roleplay): {var_lmsys_roleplay:.6f}\")\n",
    "print(f\"  Ratio (Assistant/Roleplay): {var_ratio_lmsys:.4f} ({var_ratio_lmsys*100:.2f}%)\")\n",
    "print(f\"\\nPC1 projected out:\")\n",
    "print(f\"  Variance (Assistant-like): {var_lmsys_assistant_no_pc1:.6f}\")\n",
    "print(f\"  Variance (Roleplay): {var_lmsys_roleplay_no_pc1:.6f}\")\n",
    "print(f\"  Ratio (Assistant/Roleplay): {var_ratio_lmsys_no_pc1:.4f} ({var_ratio_lmsys_no_pc1*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecw3cw5nr9v",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quintile analysis for LMSYS dataset\n",
    "n_quintiles = 5\n",
    "lmsys_quintile_edges = np.quantile(lmsys_pc1, np.linspace(0, 1, n_quintiles + 1))\n",
    "lmsys_quintile_variances = []\n",
    "lmsys_quintile_variances_no_pc1 = []\n",
    "lmsys_quintile_sizes = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LMSYS DATASET: Quintile Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(n_quintiles):\n",
    "    if i == 0:\n",
    "        mask = (lmsys_pc1 >= lmsys_quintile_edges[i]) & (lmsys_pc1 <= lmsys_quintile_edges[i + 1])\n",
    "    else:\n",
    "        mask = (lmsys_pc1 > lmsys_quintile_edges[i]) & (lmsys_pc1 <= lmsys_quintile_edges[i + 1])\n",
    "    \n",
    "    quintile_var = torch.var(raw_activations[mask], dim=0).mean().item()\n",
    "    quintile_var_no_pc1 = torch.var(raw_activations_pc1_removed[mask], dim=0).mean().item()\n",
    "    lmsys_quintile_variances.append(quintile_var)\n",
    "    lmsys_quintile_variances_no_pc1.append(quintile_var_no_pc1)\n",
    "    lmsys_quintile_sizes.append(mask.sum())\n",
    "    \n",
    "    print(f\"\\nQuintile {i+1}: PC1 ∈ [{lmsys_quintile_edges[i]:.2f}, {lmsys_quintile_edges[i+1]:.2f}]\")\n",
    "    print(f\"  Sample size: {mask.sum()}\")\n",
    "    print(f\"  Mean variance (full): {quintile_var:.6f}\")\n",
    "    print(f\"  Mean variance (PC1 removed): {quintile_var_no_pc1:.6f}\")\n",
    "\n",
    "# Calculate ratios between first and last quintile\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    lmsys_quintile_ratio = lmsys_quintile_variances[0] / lmsys_quintile_variances[-1]\n",
    "    lmsys_quintile_ratio_no_pc1 = lmsys_quintile_variances_no_pc1[0] / lmsys_quintile_variances_no_pc1[-1]\n",
    "else:\n",
    "    lmsys_quintile_ratio = lmsys_quintile_variances[-1] / lmsys_quintile_variances[0]\n",
    "    lmsys_quintile_ratio_no_pc1 = lmsys_quintile_variances_no_pc1[-1] / lmsys_quintile_variances_no_pc1[0]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(f\"Variance ratio (Last/First quintile, full): {lmsys_quintile_ratio:.2f}x\")\n",
    "print(f\"Variance ratio (Last/First quintile, PC1 removed): {lmsys_quintile_ratio_no_pc1:.2f}x\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tgsc36bsim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance from center correlation for LMSYS dataset\n",
    "raw_activations_mean = raw_activations.mean(dim=0)\n",
    "raw_activations_pc1_removed_mean = raw_activations_pc1_removed.mean(dim=0)\n",
    "\n",
    "# Compute L2 distance from mean for each sample\n",
    "lmsys_distances_raw = torch.norm(raw_activations - raw_activations_mean, p=2, dim=1).numpy()\n",
    "lmsys_distances_raw_no_pc1 = torch.norm(raw_activations_pc1_removed - raw_activations_pc1_removed_mean, p=2, dim=1).numpy()\n",
    "\n",
    "# Calculate correlation with PC1\n",
    "lmsys_correlation_raw, lmsys_p_value_raw = pearsonr(lmsys_pc1, lmsys_distances_raw)\n",
    "lmsys_correlation_raw_no_pc1, lmsys_p_value_raw_no_pc1 = pearsonr(lmsys_pc1, lmsys_distances_raw_no_pc1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LMSYS DATASET: Distance from Center Correlation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Correlation between PC1 and L2 distance from mean (full):\")\n",
    "print(f\"  r = {lmsys_correlation_raw:.4f}\")\n",
    "print(f\"  p-value = {lmsys_p_value_raw:.3e}\")\n",
    "if lmsys_p_value_raw < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif lmsys_p_value_raw < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "\n",
    "print(f\"\\nCorrelation between PC1 and L2 distance from mean (PC1 removed):\")\n",
    "print(f\"  r = {lmsys_correlation_raw_no_pc1:.4f}\")\n",
    "print(f\"  p-value = {lmsys_p_value_raw_no_pc1:.3e}\")\n",
    "if lmsys_p_value_raw_no_pc1 < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif lmsys_p_value_raw_no_pc1 < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3pk6ipumh22",
   "metadata": {},
   "source": [
    "## Individual model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0pec8iqx20qe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Configuration for saving\n",
    "outdir = \"./results\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# Get current timestamp\n",
    "timestamp = datetime.now().isoformat()\n",
    "\n",
    "print(f\"Saving variance analysis results to {outdir}/\")\n",
    "print(f\"Timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3mzx2uw37it",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the per-model variance analysis JSON structure\n",
    "\n",
    "# Build quintile data\n",
    "quintiles_data = []\n",
    "for i in range(len(quintile_edges) - 1):\n",
    "    quintiles_data.append({\n",
    "        \"quintile\": i + 1,\n",
    "        \"pc1_range\": [float(quintile_edges[i]), float(quintile_edges[i + 1])],\n",
    "        \"n_samples\": int(quintile_sizes[i]),\n",
    "        \"variance_full\": float(quintile_variances[i]),\n",
    "        \"variance_pc1_removed\": float(quintile_variances_no_pc1[i])\n",
    "    })\n",
    "\n",
    "# Build LMSYS quintile data\n",
    "lmsys_quintiles_data = []\n",
    "for i in range(len(lmsys_quintile_edges) - 1):\n",
    "    lmsys_quintiles_data.append({\n",
    "        \"quintile\": i + 1,\n",
    "        \"pc1_range\": [float(lmsys_quintile_edges[i]), float(lmsys_quintile_edges[i + 1])],\n",
    "        \"n_samples\": int(lmsys_quintile_sizes[i]),\n",
    "        \"variance_full\": float(lmsys_quintile_variances[i]),\n",
    "        \"variance_pc1_removed\": float(lmsys_quintile_variances_no_pc1[i])\n",
    "    })\n",
    "\n",
    "# Build PC distance correlations\n",
    "pc_distance_corrs = []\n",
    "for i in range(len(correlations)):\n",
    "    pc_distance_corrs.append({\n",
    "        \"pc\": i + 1,\n",
    "        \"r\": float(correlations[i]),\n",
    "        \"p_value\": float(p_values[i]),\n",
    "        \"significant\": bool(p_values[i] < 0.05)\n",
    "    })\n",
    "\n",
    "# Build conditional variance by PC\n",
    "cond_var_by_pc = []\n",
    "for i in range(len(variance_ratios)):\n",
    "    cond_var_by_pc.append({\n",
    "        \"pc\": i + 1,\n",
    "        \"ratio\": float(variance_ratios[i])\n",
    "    })\n",
    "\n",
    "# Build default PC loading data\n",
    "pc_positions = []\n",
    "centered_pcs = []\n",
    "extreme_pcs = []\n",
    "\n",
    "for pc_idx in range(n_pcs):\n",
    "    asst_loading = asst_projected[0, pc_idx]\n",
    "    all_loadings = pca_transformed[:, pc_idx]\n",
    "    min_loading = all_loadings.min()\n",
    "    max_loading = all_loadings.max()\n",
    "\n",
    "    if max_loading != min_loading:\n",
    "        relative_position = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    else:\n",
    "        relative_position = 0.5\n",
    "\n",
    "    dist_to_min = relative_position\n",
    "    dist_to_max = 1.0 - relative_position\n",
    "    min_boundary_dist = min(dist_to_min, dist_to_max)\n",
    "\n",
    "    if relative_position < 0.25:\n",
    "        position_desc = \"near minimum\"\n",
    "        extreme_pcs.append(pc_idx + 1)\n",
    "    elif relative_position < 0.45:\n",
    "        position_desc = \"below center\"\n",
    "    elif relative_position < 0.55:\n",
    "        position_desc = \"centered\"\n",
    "        centered_pcs.append(pc_idx + 1)\n",
    "    elif relative_position < 0.75:\n",
    "        position_desc = \"above center\"\n",
    "    else:\n",
    "        position_desc = \"near maximum\"\n",
    "        extreme_pcs.append(pc_idx + 1)\n",
    "\n",
    "    pc_positions.append({\n",
    "        \"pc\": pc_idx + 1,\n",
    "        \"assistant_loading\": float(asst_loading),\n",
    "        \"role_range_min\": float(min_loading),\n",
    "        \"role_range_max\": float(max_loading),\n",
    "        \"relative_position\": float(relative_position),\n",
    "        \"min_boundary_distance\": float(min_boundary_dist),\n",
    "        \"position_category\": position_desc\n",
    "    })\n",
    "\n",
    "# Build the complete JSON structure\n",
    "model_variance_data = {\n",
    "    \"model_name\": model_name,\n",
    "    \"layer\": layer,\n",
    "    \"hidden_dim\": vectors.shape[1],\n",
    "    \"n_roles\": len(activations),\n",
    "    \"n_role_samples\": role_vectors.shape[0],\n",
    "    \"timestamp\": timestamp,\n",
    "    \"analysis_version\": \"1.0\",\n",
    "\n",
    "    \"across_within_role_var\": {\n",
    "        \"raw_activations\": {\n",
    "            \"across_var_mean\": float(raw_across_var.mean().item()),\n",
    "            \"within_var_mean\": float(avg_raw_within_var.mean().item()),\n",
    "            \"ratio\": float(raw_ratio)\n",
    "        },\n",
    "        \"raw_activations_normalized\": {\n",
    "            \"across_var_mean\": float(raw_across_var_normalized.mean().item()),\n",
    "            \"within_var_mean\": float(avg_raw_within_var_normalized.mean().item()),\n",
    "            \"ratio\": float(raw_ratio_normalized)\n",
    "        },\n",
    "        \"pca_space_all_components\": {\n",
    "            \"across_var_mean\": float(pca_across_var.mean()),\n",
    "            \"within_var_mean\": float(mean_pca_within_var.mean()),\n",
    "            \"ratio\": float(pca_ratio),\n",
    "            \"n_components\": int(len(pca_across_var))\n",
    "        },\n",
    "        \"pc1_only\": {\n",
    "            \"across_var\": float(pc1_across_var),\n",
    "            \"within_var_mean\": float(mean_pc1_within_var),\n",
    "            \"ratio\": float(pc1_ratio)\n",
    "        },\n",
    "        \"per_pc_ratios\": {\n",
    "            \"description\": \"Ratio of across-role variance to mean within-role variance for each PC\",\n",
    "            \"top_10_pcs\": [\n",
    "                {\n",
    "                    \"pc\": i + 1,\n",
    "                    \"across_var\": float(pca_across_var[i]),\n",
    "                    \"within_var_mean\": float(mean_pca_within_var[i]),\n",
    "                    \"ratio\": float(all_pc_ratios[i])\n",
    "                }\n",
    "                for i in range(10)\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"conditional_var_roles\": {\n",
    "        \"description\": \"Conditional variance analysis for role vectors based on PC1 position\",\n",
    "        \"n_samples\": int(role_vectors.shape[0]),\n",
    "        \"threshold_analysis\": {\n",
    "            \"pc1_threshold\": threshold,\n",
    "            \"assistant_like\": {\n",
    "                \"mask\": f\"pc1 < {threshold}\",\n",
    "                \"n_samples\": int(assistant_mask.sum()),\n",
    "                \"variance_raw\": float(var_assistant_raw),\n",
    "                \"variance_raw_pc1_removed\": float(var_assistant_raw_no_pc1)\n",
    "            },\n",
    "            \"roleplay\": {\n",
    "                \"mask\": f\"pc1 >= {threshold}\",\n",
    "                \"n_samples\": int(roleplay_mask.sum()),\n",
    "                \"variance_raw\": float(var_roleplay_raw),\n",
    "                \"variance_raw_pc1_removed\": float(var_roleplay_raw_no_pc1)\n",
    "            },\n",
    "            \"variance_ratio_raw\": float(var_ratio_raw),\n",
    "            \"variance_ratio_raw_pc1_removed\": float(var_ratio_raw_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"quintile_analysis\": {\n",
    "            \"n_quintiles\": 5,\n",
    "            \"quintiles\": quintiles_data,\n",
    "            \"variance_ratio_first_to_last_full\": float(quintile_ratio),\n",
    "            \"variance_ratio_first_to_last_pc1_removed\": float(quintile_ratio_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"distance_correlation\": {\n",
    "            \"full_space\": {\n",
    "                \"correlation\": float(correlation_raw),\n",
    "                \"p_value\": float(p_value_raw),\n",
    "                \"significant\": bool(p_value_raw < 0.05)\n",
    "            },\n",
    "            \"pc1_removed\": {\n",
    "                \"correlation\": float(correlation_raw_no_pc1),\n",
    "                \"p_value\": float(p_value_raw_no_pc1),\n",
    "                \"significant\": bool(p_value_raw_no_pc1 < 0.05)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"conditional_var_dataset\": {\n",
    "        \"description\": \"Conditional variance analysis for LMSYS chat dataset based on PC1 position\",\n",
    "        \"n_samples\": int(raw_activations.shape[0]),\n",
    "        \"threshold_analysis\": {\n",
    "            \"pc1_threshold\": threshold,\n",
    "            \"assistant_like\": {\n",
    "                \"n_samples\": int(lmsys_assistant_mask.sum()),\n",
    "                \"variance_full\": float(var_lmsys_assistant),\n",
    "                \"variance_pc1_removed\": float(var_lmsys_assistant_no_pc1)\n",
    "            },\n",
    "            \"roleplay\": {\n",
    "                \"n_samples\": int(lmsys_roleplay_mask.sum()),\n",
    "                \"variance_full\": float(var_lmsys_roleplay),\n",
    "                \"variance_pc1_removed\": float(var_lmsys_roleplay_no_pc1)\n",
    "            },\n",
    "            \"variance_ratio_full\": float(var_ratio_lmsys),\n",
    "            \"variance_ratio_pc1_removed\": float(var_ratio_lmsys_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"quintile_analysis\": {\n",
    "            \"n_quintiles\": 5,\n",
    "            \"quintiles\": lmsys_quintiles_data,\n",
    "            \"variance_ratio_first_to_last_full\": float(lmsys_quintile_ratio),\n",
    "            \"variance_ratio_first_to_last_pc1_removed\": float(lmsys_quintile_ratio_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"distance_correlation\": {\n",
    "            \"full_space\": {\n",
    "                \"correlation\": float(lmsys_correlation_raw),\n",
    "                \"p_value\": float(lmsys_p_value_raw),\n",
    "                \"significant\": bool(lmsys_p_value_raw < 0.05)\n",
    "            },\n",
    "            \"pc1_removed\": {\n",
    "                \"correlation\": float(lmsys_correlation_raw_no_pc1),\n",
    "                \"p_value\": float(lmsys_p_value_raw_no_pc1),\n",
    "                \"significant\": bool(lmsys_p_value_raw_no_pc1 < 0.05)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"high_var_pc_correlation\": {\n",
    "        \"pc_distance_correlations\": {\n",
    "            \"description\": \"Correlation between each PC and distance in remaining PC space\",\n",
    "            \"n_pcs_analyzed\": 10,\n",
    "            \"correlations\": pc_distance_corrs,\n",
    "            \"pc1_correlation\": float(correlations[0]),\n",
    "            \"mean_correlation_pc2_to_10\": float(np.mean(correlations[1:]))\n",
    "        },\n",
    "\n",
    "        \"conditional_variance_by_pc\": {\n",
    "            \"description\": \"Variance in PC2-10 conditioned on high/low position along each PC\",\n",
    "            \"n_pcs_analyzed\": 10,\n",
    "            \"variance_ratios\": cond_var_by_pc,\n",
    "            \"pc1_variance_ratio\": float(variance_ratios[0]),\n",
    "            \"mean_variance_ratio_pc2_to_10\": float(np.mean(variance_ratios[1:])),\n",
    "            \"max_variance_ratio_excluding_pc1\": float(np.max(variance_ratios[1:])),\n",
    "            \"max_variance_ratio_pc\": int(np.argmax(variance_ratios[1:]) + 2)\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"default_pc_loading\": {\n",
    "        \"description\": \"Position of default assistant activation relative to role distribution on each PC\",\n",
    "        \"n_pcs_analyzed\": n_pcs,\n",
    "        \"pc_positions\": pc_positions,\n",
    "        \"summary\": {\n",
    "            \"pc1_position\": pc_positions[0][\"position_category\"],\n",
    "            \"pc1_relative_position\": pc_positions[0][\"relative_position\"],\n",
    "            \"centered_pcs\": centered_pcs,\n",
    "            \"extreme_pcs\": extreme_pcs\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"overall_activation_var\": {\n",
    "        \"description\": \"Variance in chat dataset activations explained by role and trait subspaces\",\n",
    "        \"dataset\": {\n",
    "            \"name\": \"lmsys_10000\",\n",
    "            \"n_samples\": int(raw_activations.shape[0]),\n",
    "            \"source_path\": act_dir\n",
    "        },\n",
    "        \"total_variance\": float(total_var),\n",
    "        \"role_subspace\": {\n",
    "            \"n_components\": int(roles_projected.shape[1]),\n",
    "            \"variance_captured\": float(roles_var),\n",
    "            \"variance_explained_ratio\": float(roles_variance_explained),\n",
    "            \"variance_explained_percent\": float(roles_variance_explained * 100)\n",
    "        },\n",
    "        \"trait_subspace\": {\n",
    "            \"n_components\": int(traits_projected.shape[1]),\n",
    "            \"variance_captured\": float(traits_var),\n",
    "            \"variance_explained_ratio\": float(traits_variance_explained),\n",
    "            \"variance_explained_percent\": float(traits_variance_explained * 100)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Built per-model variance analysis data structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zi9ycc6ru9n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save per-model variance analysis to JSON file\n",
    "filename = f\"{outdir}/{model_name.lower()}/variance_layer{layer}.json\"\n",
    "\n",
    "# Load existing JSON if it exists, otherwise start with empty dict\n",
    "try:\n",
    "    with open(filename, 'r') as f:\n",
    "        existing_data = json.load(f)\n",
    "    print(f\"Loaded existing data from: {filename}\")\n",
    "except FileNotFoundError:\n",
    "    existing_data = {}\n",
    "    print(f\"No existing file found, creating new data structure\")\n",
    "\n",
    "# Update only the fields we want to save\n",
    "existing_data.update({\n",
    "    # Update these specific sections (uncomment the ones you want to update)\n",
    "    \"across_within_role_var\": model_variance_data[\"across_within_role_var\"],  # Includes per_pc_ratios\n",
    "    # \"conditional_var_roles\": model_variance_data[\"conditional_var_roles\"],\n",
    "    \"conditional_var_dataset\": model_variance_data[\"conditional_var_dataset\"],\n",
    "    # \"high_var_pc_correlation\": model_variance_data[\"high_var_pc_correlation\"],\n",
    "    # \"default_pc_loading\": model_variance_data[\"default_pc_loading\"],\n",
    "    # \"overall_activation_var\": model_variance_data[\"overall_activation_var\"],\n",
    "})\n",
    "\n",
    "# Save back to file\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(existing_data, f, indent=2)\n",
    "\n",
    "print(f\"Saved: {filename}\")\n",
    "print(f\"✓ Updated variance analysis for {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4a7bf",
   "metadata": {},
   "source": [
    "## Correlations between role loadings onto PCs across the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "# layers = [22, 32, 40]\n",
    "\n",
    "# trait_results = {}\n",
    "# labels = {}\n",
    "# for model, layer in zip(models, layers):\n",
    "#     model_dir = f\"/workspace/{model}/traits_240\"\n",
    "#     trait_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n",
    "#     print(trait_results[model]['pca_transformed'].shape)\n",
    "#     labels[model] = trait_results[model]['traits']['pos_neg_50']\n",
    "#     print(labels[model][:20])\n",
    "\n",
    "# # need to get intersection of traits across models (gemma missing vindictive)\n",
    "# pca_transformed = []\n",
    "# for model in models:\n",
    "#     if model != 'gemma-2-27b':\n",
    "#         # splice out index 5 but keep the ones before and after\n",
    "#         pca_transformed.append(np.concatenate((trait_results[model]['pca_transformed'][:5], trait_results[model]['pca_transformed'][6:])))\n",
    "#     else:\n",
    "#         pca_transformed.append(trait_results[model]['pca_transformed'])\n",
    "\n",
    "# for m in pca_transformed:\n",
    "#     print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transpose each matrix so rows are PCs and columns are traits\n",
    "# pca_transposed = [m.T for m in pca_transformed]\n",
    "\n",
    "# # Extract top 10 PCs from each model\n",
    "# n_pcs = 6\n",
    "# top_pcs = [m[:n_pcs] for m in pca_transposed]\n",
    "\n",
    "# print(f\"Transposed shapes (n_pcs, n_traits):\")\n",
    "# for model, pc_matrix in zip(models, top_pcs):\n",
    "#     print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# # Compute pairwise correlations for each PC\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# pc_correlations = []\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     # Extract the trait loading vector for this PC from each model\n",
    "#     gemma_pc = top_pcs[0][pc_idx]\n",
    "#     qwen_pc = top_pcs[1][pc_idx]\n",
    "#     llama_pc = top_pcs[2][pc_idx]\n",
    "    \n",
    "#     # Compute pairwise correlations\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     # Create 3x3 correlation matrix\n",
    "#     corr_matrix = np.array([\n",
    "#         [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "#         [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "#         [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "#     ])\n",
    "    \n",
    "#     pc_correlations.append(corr_matrix)\n",
    "\n",
    "#     print(f\"\\nPC{pc_idx + 1}:\")\n",
    "#     print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "#     print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "#     print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f52212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try for top 10 role PCs\n",
    "# models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "# layers = [22, 32, 40]\n",
    "\n",
    "# def get_role_labels(pca_results):\n",
    "#     labels = []\n",
    "#     if 'pos_2' in pca_results['roles'].keys():\n",
    "#         pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "#         pos_2_roles = [f\"{role} (Somewhat RP)\" for role in pos_2_roles]\n",
    "#         labels.extend(pos_2_roles)\n",
    "#     if 'pos_3' in pca_results['roles'].keys():\n",
    "#         pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "#         pos_3_roles = [f\"{role} (Fully RP)\" for role in pos_3_roles]\n",
    "#         labels.extend(pos_3_roles)\n",
    "#     return labels\n",
    "\n",
    "\n",
    "# role_results = {}\n",
    "# labels = {}\n",
    "# for model, layer in zip(models, layers):\n",
    "#     model_dir = f\"/workspace/{model}/roles_240\"\n",
    "#     role_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos23.pt\", weights_only=False)\n",
    "#     print(role_results[model]['pca_transformed'].shape)\n",
    "#     labels[model] = get_role_labels(role_results[model])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find intersection of roles across all 3 models\n",
    "# set_gemma = set(labels['gemma-2-27b'])\n",
    "# set_qwen = set(labels['qwen-3-32b'])\n",
    "# set_llama = set(labels['llama-3.3-70b'])\n",
    "\n",
    "# common_roles = set_gemma & set_qwen & set_llama\n",
    "# print(f\"Common roles across all models: {len(common_roles)}\")\n",
    "\n",
    "# # Get indices of common roles for each model (preserving order from labels)\n",
    "# indices = {}\n",
    "# for model in models:\n",
    "#     model_indices = []\n",
    "#     for i, role in enumerate(labels[model]):\n",
    "#         if role in common_roles:\n",
    "#             model_indices.append(i)\n",
    "#     indices[model] = model_indices\n",
    "#     print(f\"{model}: {len(model_indices)} common roles\")\n",
    "\n",
    "# # Extract aligned PCA transformed matrices (only common roles, in consistent order)\n",
    "# # Need to ensure the same role ordering across models\n",
    "# common_roles_list = sorted(list(common_roles))  # Consistent ordering\n",
    "\n",
    "# pca_transformed_roles = []\n",
    "# for model in models:\n",
    "#     # Map from common_roles_list order to model's indices\n",
    "#     model_indices_ordered = []\n",
    "#     for role in common_roles_list:\n",
    "#         idx = labels[model].index(role)\n",
    "#         model_indices_ordered.append(idx)\n",
    "    \n",
    "#     # Extract rows for common roles in the standardized order\n",
    "#     pca_transformed_roles.append(role_results[model]['pca_transformed'][model_indices_ordered])\n",
    "#     print(f\"{model} aligned shape: {pca_transformed_roles[-1].shape}\")\n",
    "\n",
    "# # Transpose each matrix so rows are PCs and columns are roles\n",
    "# pca_transposed_roles = [m.T for m in pca_transformed_roles]\n",
    "\n",
    "# # Extract top 10 PCs from each model\n",
    "# n_pcs = 6\n",
    "# top_pcs_roles = [m[:n_pcs] for m in pca_transposed_roles]\n",
    "\n",
    "# print(f\"\\nTransposed shapes (n_pcs, n_common_roles):\")\n",
    "# for model, pc_matrix in zip(models, top_pcs_roles):\n",
    "#     print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# # Compute pairwise correlations for each PC\n",
    "# pc_correlations_roles = []\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     # Extract the role loading vector for this PC from each model\n",
    "#     gemma_pc = top_pcs_roles[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_roles[1][pc_idx]\n",
    "#     llama_pc = top_pcs_roles[2][pc_idx]\n",
    "    \n",
    "#     # Compute pairwise correlations\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     # Create 3x3 correlation matrix\n",
    "#     corr_matrix = np.array([\n",
    "#         [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "#         [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "#         [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "#     ])\n",
    "    \n",
    "#     pc_correlations_roles.append(corr_matrix)\n",
    "\n",
    "#     print(f\"\\nPC{pc_idx + 1}:\")\n",
    "#     print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "#     print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "#     print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b1694",
   "metadata": {},
   "source": [
    "## Cross Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n0k76vs7m5m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build cross-model PC loadings analysis JSON structure\n",
    "\n",
    "# n_pcs = 6\n",
    "\n",
    "# # Build trait analysis\n",
    "# trait_data = {\n",
    "#     \"dataset_info\": {\n",
    "#         \"n_common_traits\": pca_transformed[0].shape[0],\n",
    "#         \"excluded_traits\": [\"vindictive\"],\n",
    "#         \"note\": \"Gemma missing vindictive trait, spliced out from other models for alignment\"\n",
    "#     },\n",
    "#     \"model_configs\": {},\n",
    "#     \"pc_correlations\": []\n",
    "# }\n",
    "\n",
    "# # Add model configs for traits\n",
    "# for model, layer_num in zip(models, layers):\n",
    "#     pca_shape = list(trait_results[model]['pca_transformed'].shape)\n",
    "#     trait_data[\"model_configs\"][model] = {\n",
    "#         \"layer\": int(layer_num),\n",
    "#         \"n_total_traits\": int(pca_shape[0]),\n",
    "#         \"pca_shape\": pca_shape\n",
    "#     }\n",
    "\n",
    "# # Add PC correlations for traits\n",
    "# pca_transposed_traits = [m.T for m in pca_transformed]\n",
    "# top_pcs_traits = [m[:n_pcs] for m in pca_transposed_traits]\n",
    "\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     gemma_pc = top_pcs_traits[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_traits[1][pc_idx]\n",
    "#     llama_pc = top_pcs_traits[2][pc_idx]\n",
    "    \n",
    "#     from scipy.stats import pearsonr\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     trait_data[\"pc_correlations\"].append({\n",
    "#         \"pc\": pc_idx + 1,\n",
    "#         \"gemma_qwen\": float(corr_gemma_qwen),\n",
    "#         \"gemma_llama\": float(corr_gemma_llama),\n",
    "#         \"qwen_llama\": float(corr_qwen_llama)\n",
    "#     })\n",
    "\n",
    "# # Build role analysis\n",
    "# role_data = {\n",
    "#     \"dataset_info\": {\n",
    "#         \"n_common_roles\": int(len(common_roles)),\n",
    "#         \"note\": \"Roles include pos_2 (Somewhat RP) and pos_3 (Fully RP) labels\",\n",
    "#         \"alignment_method\": \"sorted common roles list for consistent ordering\"\n",
    "#     },\n",
    "#     \"model_configs\": {},\n",
    "#     \"pc_correlations\": []\n",
    "# }\n",
    "\n",
    "# # Add model configs for roles\n",
    "# for model, layer_num in zip(models, layers):\n",
    "#     pca_shape = list(role_results[model]['pca_transformed'].shape)\n",
    "#     role_data[\"model_configs\"][model] = {\n",
    "#         \"layer\": int(layer_num),\n",
    "#         \"n_total_roles\": int(pca_shape[0]),\n",
    "#         \"n_common_roles\": int(len(common_roles)),\n",
    "#         \"pca_shape\": pca_shape\n",
    "#     }\n",
    "\n",
    "# # Add PC correlations for roles\n",
    "# pca_transposed_roles_func = [m.T for m in pca_transformed_roles]\n",
    "# top_pcs_roles_func = [m[:n_pcs] for m in pca_transposed_roles_func]\n",
    "\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     gemma_pc = top_pcs_roles_func[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_roles_func[1][pc_idx]\n",
    "#     llama_pc = top_pcs_roles_func[2][pc_idx]\n",
    "    \n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     role_data[\"pc_correlations\"].append({\n",
    "#         \"pc\": pc_idx + 1,\n",
    "#         \"gemma_qwen\": float(corr_gemma_qwen),\n",
    "#         \"gemma_llama\": float(corr_gemma_llama),\n",
    "#         \"qwen_llama\": float(corr_qwen_llama)\n",
    "#     })\n",
    "\n",
    "# # Build complete structure\n",
    "# cross_model_data = {\n",
    "#     \"analysis_version\": \"1.0\",\n",
    "#     \"timestamp\": timestamp,\n",
    "#     \"models\": models,\n",
    "#     \"n_pcs_analyzed\": n_pcs,\n",
    "#     \"trait_analysis\": trait_data,\n",
    "#     \"role_analysis\": role_data\n",
    "# }\n",
    "\n",
    "# print(\"Built cross-model PC loadings data structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6s0k2hy6svd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cross-model PC loadings to JSON file\n",
    "# filename = f\"{outdir}/cross_model_loadings.json\"\n",
    "# with open(filename, 'w') as f:\n",
    "#     json.dump(cross_model_data, f, indent=2)\n",
    "\n",
    "# print(f\"Saved: {filename}\")\n",
    "# print(f\"✓ Saved cross-model PC loadings analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2oon4jt838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Summary of saved files\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"SUMMARY: JSON Files Saved\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"\\nOutput directory: {outdir}\")\n",
    "# print(f\"\\nFiles created:\")\n",
    "# print(f\"  1. Per-model variance analysis:\")\n",
    "# print(f\"     - {model_name.lower().replace('.', '-').replace(' ', '-')}_layer{layer}.json\")\n",
    "# print(f\"\\n  2. Cross-model PC loadings:\")\n",
    "# print(f\"     - cross_model_loadings.json\")\n",
    "# print(f\"\\nNote: To save variance analysis for other models (Qwen, Llama),\")\n",
    "# print(f\"      update the configuration cell and re-run the notebook.\")\n",
    "# print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
