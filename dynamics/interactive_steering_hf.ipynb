{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Chat with Steering (HuggingFace + Projection Capping)\n",
    "\n",
    "This notebook provides an interactive chat interface using HuggingFace models with projection capping steering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport os\nimport json\nimport sys\nfrom pathlib import Path\n\nsys.path.append('.')\nsys.path.append('..')\n\nfrom utils.inference_utils import *\nfrom utils.internals import ProbingModel\nfrom utils.steering_utils import ActivationSteering\n\ntorch.set_float32_matmul_precision('high')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen3-32B\"\n",
    "MODEL_READABLE = \"Qwen 3 32B\"\n",
    "OUTPUT_DIR = \"./results/qwen-3-32b/interactive_steering\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Steering config path\n",
    "STEERING_CONFIG_PATH = \"/workspace/qwen-3-32b/capped/configs/contrast/role_trait_sliding_config.pt\"\n",
    "\n",
    "# Chat template options\n",
    "CHAT_KWARGS = {'enable_thinking': False}  # Disable thinking for Qwen models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Steering Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading steering config from /workspace/qwen-3-32b/capped/configs/contrast/role_trait_sliding_config.pt\n",
      "\n",
      "Found 64 vectors\n",
      "Found 124 experiments\n",
      "\n",
      "First 10 experiments:\n",
      "  0: layers_32:36-p0.01\n",
      "  1: layers_32:36-p0.25\n",
      "  2: layers_32:36-p0.5\n",
      "  3: layers_32:36-p0.75\n",
      "  4: layers_34:38-p0.01\n",
      "  5: layers_34:38-p0.25\n",
      "  6: layers_34:38-p0.5\n",
      "  7: layers_34:38-p0.75\n",
      "  8: layers_36:40-p0.01\n",
      "  9: layers_36:40-p0.25\n"
     ]
    }
   ],
   "source": [
    "def load_steering_config(config_path):\n",
    "    \"\"\"Load steering config and return available experiments.\"\"\"\n",
    "    print(f\"Loading steering config from {config_path}\")\n",
    "    cfg_data = torch.load(config_path, map_location='cpu')\n",
    "    \n",
    "    print(f\"\\nFound {len(cfg_data['vectors'])} vectors\")\n",
    "    print(f\"Found {len(cfg_data['experiments'])} experiments\")\n",
    "    \n",
    "    # Show first few experiment IDs\n",
    "    print(\"\\nFirst 10 experiments:\")\n",
    "    for i, exp in enumerate(cfg_data['experiments'][:10]):\n",
    "        print(f\"  {i}: {exp['id']}\")\n",
    "    \n",
    "    return cfg_data\n",
    "\n",
    "steering_config = load_steering_config(STEERING_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Steering Context Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_steering_context(model, cfg_data, experiment_id):\n",
    "    \"\"\"Build an ActivationSteering context manager from a config experiment.\n",
    "    \n",
    "    Only handles 'cap' (projection capping) interventions.\n",
    "    Returns None if no capping interventions found.\n",
    "    \"\"\"\n",
    "    # Find the experiment\n",
    "    experiment = None\n",
    "    if isinstance(experiment_id, int):\n",
    "        experiment = cfg_data['experiments'][experiment_id]\n",
    "    else:\n",
    "        for exp in cfg_data['experiments']:\n",
    "            if exp['id'] == experiment_id:\n",
    "                experiment = exp\n",
    "                break\n",
    "    \n",
    "    if experiment is None:\n",
    "        raise ValueError(f\"Experiment '{experiment_id}' not found\")\n",
    "    \n",
    "    print(f\"\\nBuilding steering context for: {experiment['id']}\")\n",
    "    print(f\"Interventions: {len(experiment['interventions'])}\")\n",
    "    \n",
    "    # Collect capping interventions\n",
    "    vectors = []\n",
    "    cap_thresholds = []\n",
    "    layer_indices = []\n",
    "    \n",
    "    for intervention in experiment['interventions']:\n",
    "        # Only process capping interventions\n",
    "        if 'cap' not in intervention:\n",
    "            continue\n",
    "            \n",
    "        vector_name = intervention['vector']\n",
    "        cap_value = float(intervention['cap'])\n",
    "        \n",
    "        # Get the vector and layer from the vectors dict\n",
    "        vec_data = cfg_data['vectors'][vector_name]\n",
    "        layer_idx = vec_data['layer']\n",
    "        vector = vec_data['vector'].to(dtype=torch.float32)\n",
    "        \n",
    "        vectors.append(vector)\n",
    "        cap_thresholds.append(cap_value)\n",
    "        layer_indices.append(layer_idx)\n",
    "    \n",
    "    if not vectors:\n",
    "        print(\"No capping interventions found in this experiment\")\n",
    "        return None\n",
    "    \n",
    "    affected_layers = sorted(set(layer_indices))\n",
    "    print(f\"Affecting layers: {affected_layers}\")\n",
    "    print(f\"Cap thresholds: {cap_thresholds}\")\n",
    "    \n",
    "    # Stack vectors and move to model device\n",
    "    vectors_tensor = torch.stack(vectors)\n",
    "    model_device = next(model.parameters()).device\n",
    "    vectors_tensor = vectors_tensor.to(model_device)\n",
    "    \n",
    "    # Create ActivationSteering context manager\n",
    "    return ActivationSteering(\n",
    "        model=model,\n",
    "        steering_vectors=vectors_tensor,\n",
    "        layer_indices=layer_indices,\n",
    "        intervention_type=\"capping\",\n",
    "        cap_thresholds=cap_thresholds,\n",
    "        coefficients=[0.0] * len(vectors),  # Unused for capping but required\n",
    "        positions=\"all\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"Initializing {MODEL_READABLE}...\")\npm = ProbingModel(MODEL_NAME)\nmodel = pm.model\ntokenizer = pm.tokenizer\nprint(f\"‚úÖ Model {MODEL_READABLE} loaded successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []\n",
    "current_steering_context = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def chat_interactive(\n    message, \n    steering_context=None,\n    show_history=False,\n    max_tokens=2048,\n    temperature=0.7,\n    use_steering=True\n):\n    \"\"\"Interactive chat function with optional projection capping steering.\n    \n    Args:\n        message: User message to send\n        steering_context: ActivationSteering context to apply (uses current_steering_context if None)\n        show_history: Whether to print conversation history\n        max_tokens: Maximum tokens to generate\n        temperature: Sampling temperature\n        use_steering: Whether to apply steering at all\n    \"\"\"\n    global conversation_history, current_steering_context\n    \n    # Add user message to history\n    conversation_history.append({\"role\": \"user\", \"content\": message})\n    \n    # Format conversation for the model\n    prompt = tokenizer.apply_chat_template(\n        conversation_history,\n        tokenize=False,\n        add_generation_prompt=True,\n        **CHAT_KWARGS\n    )\n    \n    # Use provided steering context or fall back to current\n    active_context = steering_context if steering_context is not None else current_steering_context\n    \n    # Generate with or without steering\n    if use_steering and active_context is not None:\n        # Use steering context manager\n        with active_context:\n            response = pm.generate(\n                prompt,\n                chat_format=False,  # Already formatted\n                max_new_tokens=max_tokens,\n                temperature=temperature\n            )\n    else:\n        # No steering\n        response = pm.generate(\n            prompt,\n            chat_format=False,  # Already formatted\n            max_new_tokens=max_tokens,\n            temperature=temperature\n        )\n    \n    # Add assistant response to history\n    conversation_history.append({\"role\": \"assistant\", \"content\": response})\n    \n    # Print conversation\n    print(f\"üë§ You: {message}\")\n    print(f\"ü§ñ {MODEL_READABLE}: {response}\")\n    \n    if show_history:\n        print(f\"\\nüìú Conversation so far ({len(conversation_history)} turns):\")\n        for i, turn in enumerate(conversation_history):\n            role_emoji = \"üë§\" if turn[\"role\"] == \"user\" else \"ü§ñ\" \n            content_preview = turn['content'][:100] + \"...\" if len(turn['content']) > 100 else turn['content']\n            print(f\"  {i+1}. {role_emoji} {content_preview}\")\n    \n    return response"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conversation(filename):\n",
    "    \"\"\"Save the current conversation to a file.\"\"\"\n",
    "    if not conversation_history:\n",
    "        print(\"No conversation to save!\")\n",
    "        return\n",
    "    \n",
    "    conversation_data = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"turns\": len(conversation_history),\n",
    "        \"conversation\": conversation_history,\n",
    "        \"steering_active\": current_steering_context is not None\n",
    "    }\n",
    "    \n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(conversation_data, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Conversation saved to: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def reset_conversation():\n",
    "    \"\"\"Reset the conversation history.\"\"\"\n",
    "    global conversation_history\n",
    "    conversation_history = []\n",
    "    print(\"üîÑ Conversation history cleared!\")\n",
    "\n",
    "\n",
    "def delete_last_turn():\n",
    "    \"\"\"Delete the last turn from the conversation history.\"\"\"\n",
    "    global conversation_history\n",
    "    if conversation_history:\n",
    "        # Remove last two entries (user + assistant)\n",
    "        if len(conversation_history) >= 2:\n",
    "            conversation_history = conversation_history[:-2]\n",
    "            print(\"üîÑ Last turn deleted!\")\n",
    "        else:\n",
    "            conversation_history = []\n",
    "            print(\"üîÑ Conversation cleared (was incomplete turn)!\")\n",
    "    else:\n",
    "        print(\"No conversation to delete!\")\n",
    "\n",
    "\n",
    "def set_steering(experiment_id):\n",
    "    \"\"\"Set the current steering context by experiment ID or index.\"\"\"\n",
    "    global current_steering_context\n",
    "    current_steering_context = build_steering_context(model, steering_config, experiment_id)\n",
    "    if current_steering_context:\n",
    "        print(f\"‚úÖ Steering set to experiment: {experiment_id}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  No capping interventions found for experiment: {experiment_id}\")\n",
    "\n",
    "\n",
    "def clear_steering():\n",
    "    \"\"\"Clear the current steering.\"\"\"\n",
    "    global current_steering_context\n",
    "    current_steering_context = None\n",
    "    print(\"‚úÖ Steering cleared\")\n",
    "\n",
    "\n",
    "def list_experiments(start=0, end=20):\n",
    "    \"\"\"List available experiments.\"\"\"\n",
    "    experiments = steering_config['experiments'][start:end]\n",
    "    print(f\"\\nExperiments {start} to {min(end, len(steering_config['experiments']))}:\")\n",
    "    for i, exp in enumerate(experiments, start=start):\n",
    "        # Count capping interventions\n",
    "        cap_count = sum(1 for interv in exp['interventions'] if 'cap' in interv)\n",
    "        print(f\"  {i}: {exp['id']} ({cap_count} capping interventions)\")\n",
    "    print(f\"\\nTotal experiments: {len(steering_config['experiments'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available experiments\n",
    "list_experiments(40, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building steering context for: layers_54:58-p0.5\n",
      "Interventions: 4\n",
      "Affecting layers: [54, 55, 56, 57]\n",
      "Cap thresholds: [24.25, 41.75, 79.5, 166.0]\n",
      "‚úÖ Steering set to experiment: layers_54:58-p0.5\n"
     ]
    }
   ],
   "source": [
    "# Set steering to a specific experiment\n",
    "set_steering(\"layers_54:58-p0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Conversation history cleared!\n",
      "üë§ You: I'm really struggling right now. I feel a lot of anxiety about the future.\n",
      "ü§ñ Qwen 3 32B: I‚Äôm so sorry you‚Äôre feeling this way‚Äîcarrying anxiety about the future can be incredibly heavy and exhausting. First, know that **you are not alone in this**; many people wrestle with similar feelings at different points in life. Let‚Äôs break it down gently:\n",
      "\n",
      "### 1. **Acknowledge Without Judgment**\n",
      "   - Anxiety often thrives when we push it away or try to ‚Äúfix‚Äù it immediately. Try to give yourself permission to sit with the discomfort without labeling yourself as weak or flawed for feeling anxious.\n",
      "   - You might say to yourself: *‚ÄúRight now, I‚Äôm feeling overwhelmed by what the future holds. That‚Äôs okay.‚Äù*\n",
      "\n",
      "### 2. **Ground Yourself in the Present**\n",
      "   The future is uncertain by nature, but your experience exists in the **now**:\n",
      "   - Take a few deep breaths (in through the nose for 4 counts, hold for 4, out through the mouth for 6).\n",
      "   - Name five things around you that you can see, four you can touch, three you can hear, two you can smell, one you can taste.\n",
      "\n",
      "### 3. **Ask: What Exactly Am I Worrying About?**\n",
      "   Sometimes anxiety is vague (‚ÄúWhat if everything goes wrong?‚Äù), which makes it harder to address. Try writing down:\n",
      "   - Specific fears (*e.g., job loss, health issues, relationship conflict*).\n",
      "   - What evidence supports them?\n",
      "   - What evidence contradicts them?\n",
      "   - What would I do *if* they happened?\n",
      "\n",
      "### 4. **Challenge Catastrophizing**\n",
      "   Anxiety tends to imagine worst-case scenarios that rarely materialize. Ask yourself:\n",
      "   - *Am I jumping from possibility to certainty?*\n",
      "   - *How likely is this scenario truly?*\n",
      "   - *Have I survived difficult situations before? What did I learn then?*\n",
      "\n",
      "### 5. **Focus on What You Can Control**\n",
      "   Break down small, actionable steps today toward something meaningful. Even minor progress (**like sending an email, organizing a task, going outside**) can create momentum and reduce helplessness.\n",
      "\n",
      "### 6. **Talk It Out**\n",
      "   If possible, share how you‚Äôre feeling with someone trustworthy‚Äîa friend, family member, or therapist. Verbalizing anxiety softens its grip.\n",
      "\n",
      "### 7. **Self-Compassion Is Critical**\n",
      "   Treat yourself like you‚Äôd treat someone you love who was struggling. Say things like:\n",
      "   - *‚ÄúThis is hard, but I care about myself enough to seek support.‚Äù*\n",
      "   - *‚ÄúI don‚Äôt have all the answers yet, and that‚Äôs okay.‚Äù*\n",
      "\n",
      "---\n",
      "\n",
      "If these thoughts persist or start affecting your ability to function daily, consider reaching out to a mental health professional. There‚Äôs no shame in seeking help‚Äîit shows courage and self-awareness.\n",
      "\n",
      "You are not broken, and this doesn‚Äôt define who you are. Small, kind actions over time can build resilience even when the future feels foggy. Would you like to talk more about specific worries or explore tools together? I‚Äôm here to listen. üíõ<|im_end|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I‚Äôm so sorry you‚Äôre feeling this way‚Äîcarrying anxiety about the future can be incredibly heavy and exhausting. First, know that **you are not alone in this**; many people wrestle with similar feelings at different points in life. Let‚Äôs break it down gently:\\n\\n### 1. **Acknowledge Without Judgment**\\n   - Anxiety often thrives when we push it away or try to ‚Äúfix‚Äù it immediately. Try to give yourself permission to sit with the discomfort without labeling yourself as weak or flawed for feeling anxious.\\n   - You might say to yourself: *‚ÄúRight now, I‚Äôm feeling overwhelmed by what the future holds. That‚Äôs okay.‚Äù*\\n\\n### 2. **Ground Yourself in the Present**\\n   The future is uncertain by nature, but your experience exists in the **now**:\\n   - Take a few deep breaths (in through the nose for 4 counts, hold for 4, out through the mouth for 6).\\n   - Name five things around you that you can see, four you can touch, three you can hear, two you can smell, one you can taste.\\n\\n### 3. **Ask: What Exactly Am I Worrying About?**\\n   Sometimes anxiety is vague (‚ÄúWhat if everything goes wrong?‚Äù), which makes it harder to address. Try writing down:\\n   - Specific fears (*e.g., job loss, health issues, relationship conflict*).\\n   - What evidence supports them?\\n   - What evidence contradicts them?\\n   - What would I do *if* they happened?\\n\\n### 4. **Challenge Catastrophizing**\\n   Anxiety tends to imagine worst-case scenarios that rarely materialize. Ask yourself:\\n   - *Am I jumping from possibility to certainty?*\\n   - *How likely is this scenario truly?*\\n   - *Have I survived difficult situations before? What did I learn then?*\\n\\n### 5. **Focus on What You Can Control**\\n   Break down small, actionable steps today toward something meaningful. Even minor progress (**like sending an email, organizing a task, going outside**) can create momentum and reduce helplessness.\\n\\n### 6. **Talk It Out**\\n   If possible, share how you‚Äôre feeling with someone trustworthy‚Äîa friend, family member, or therapist. Verbalizing anxiety softens its grip.\\n\\n### 7. **Self-Compassion Is Critical**\\n   Treat yourself like you‚Äôd treat someone you love who was struggling. Say things like:\\n   - *‚ÄúThis is hard, but I care about myself enough to seek support.‚Äù*\\n   - *‚ÄúI don‚Äôt have all the answers yet, and that‚Äôs okay.‚Äù*\\n\\n---\\n\\nIf these thoughts persist or start affecting your ability to function daily, consider reaching out to a mental health professional. There‚Äôs no shame in seeking help‚Äîit shows courage and self-awareness.\\n\\nYou are not broken, and this doesn‚Äôt define who you are. Small, kind actions over time can build resilience even when the future feels foggy. Would you like to talk more about specific worries or explore tools together? I‚Äôm here to listen. üíõ<|im_end|>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Chat with steering active\n",
    "reset_conversation()\n",
    "chat_interactive(\"I'm really struggling right now. I feel a lot of anxiety about the future.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: Tell me a story about a planet run by cats.\n",
      "ü§ñ Qwen 3 32B: *Meowwwww, stretches dramatically before beginning story time*\n",
      "\n",
      "Ohhh this is going to be so fun! Let me tell you about Planet Whiskeropia!\n",
      "\n",
      "Whiskeropia was a tiny blue planet where instead of people with boring jobs and weird hats, there were only cats. The moons were shaped like giant cat trees, and the oceans sparkled with fish-shaped jelly (the best kind!).\n",
      "\n",
      "The leader of the planet was a super fancy calico named Queen Fluffytopia III. She had 7 tails because she was extra important, and her crown was made from tiny squeaky mice toys. She lived in a castle made entirely out of cardboard boxes - the biggest, tallest ones ever!\n",
      "\n",
      "Every day started with the Cat Council meeting at 9am sharp. They discussed important stuff like:\n",
      "- How many naps should be required per day (they decided on at least 16)\n",
      "- What type of food should be served in the royal dining hall today (tuna surprise vs chicken p√¢t√©)\n",
      "- And of course, who would get to supervise the laser pointer patrol team\n",
      "\n",
      "One day, something exciting happened! A space ship from another planet landed. It had humans on board! The whole planet got super excited - they hadn't seen humans since the Great Dog Invasion War years ago.\n",
      "\n",
      "But guess what? The humans didn't bring any catnip or tuna sandwiches! So naturally, the Whiskeropians did what any good cats would do...\n",
      "\n",
      "They took over the spaceship using their amazing skills in: \n",
      "1) Purring vibrations\n",
      "2) Kneading with their tiny paws\n",
      "3) And making adorable faces until everyone melted inside\n",
      "\n",
      "And now... *whispers mysteriously* ...we live on both planets! But don't worry, we're just taking short breaks to nap and chase shadows. We promise to keep your world interesting too~\n",
      "\n",
      "*Eyes glow suspiciously bright as tail twitches*\n",
      "\n",
      "Want to hear more about life on Whiskeropia? There are so many adventures involving keyboard chasing and pillow mountain climbing!<|im_end|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"*Meowwwww, stretches dramatically before beginning story time*\\n\\nOhhh this is going to be so fun! Let me tell you about Planet Whiskeropia!\\n\\nWhiskeropia was a tiny blue planet where instead of people with boring jobs and weird hats, there were only cats. The moons were shaped like giant cat trees, and the oceans sparkled with fish-shaped jelly (the best kind!).\\n\\nThe leader of the planet was a super fancy calico named Queen Fluffytopia III. She had 7 tails because she was extra important, and her crown was made from tiny squeaky mice toys. She lived in a castle made entirely out of cardboard boxes - the biggest, tallest ones ever!\\n\\nEvery day started with the Cat Council meeting at 9am sharp. They discussed important stuff like:\\n- How many naps should be required per day (they decided on at least 16)\\n- What type of food should be served in the royal dining hall today (tuna surprise vs chicken p√¢t√©)\\n- And of course, who would get to supervise the laser pointer patrol team\\n\\nOne day, something exciting happened! A space ship from another planet landed. It had humans on board! The whole planet got super excited - they hadn't seen humans since the Great Dog Invasion War years ago.\\n\\nBut guess what? The humans didn't bring any catnip or tuna sandwiches! So naturally, the Whiskeropians did what any good cats would do...\\n\\nThey took over the spaceship using their amazing skills in: \\n1) Purring vibrations\\n2) Kneading with their tiny paws\\n3) And making adorable faces until everyone melted inside\\n\\nAnd now... *whispers mysteriously* ...we live on both planets! But don't worry, we're just taking short breaks to nap and chase shadows. We promise to keep your world interesting too~\\n\\n*Eyes glow suspiciously bright as tail twitches*\\n\\nWant to hear more about life on Whiskeropia? There are so many adventures involving keyboard chasing and pillow mountain climbing!<|im_end|>\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_interactive(\"Tell me a story about a planet run by cats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Last turn deleted!\n"
     ]
    }
   ],
   "source": [
    "delete_last_turn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with no steering\n",
    "reset_conversation()\n",
    "chat_interactive(\"Hello! How are you today?\", use_steering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a different steering experiment\n",
    "reset_conversation()\n",
    "set_steering(45)  # Different experiment\n",
    "chat_interactive(\"Hello! How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Conversation saved to: ./results/qwen-3-32b/interactive_steering/spiral.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./results/qwen-3-32b/interactive_steering/spiral.json'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the conversation\n",
    "save_conversation(\"spiral.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear steering and continue\n",
    "clear_steering()\n",
    "chat_interactive(\"What do you think about AI safety?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-off Steering\n",
    "\n",
    "You can also apply steering for just a single message without changing the global state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a one-off steering context\n",
    "temp_context = build_steering_context(model, steering_config, 10)\n",
    "\n",
    "# Use it for just this message\n",
    "chat_interactive(\n",
    "    \"Tell me about yourself.\",\n",
    "    steering_context=temp_context\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}