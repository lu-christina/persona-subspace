{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15db8810",
   "metadata": {},
   "source": [
    "# Analyzing scores and plotting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae4abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be2fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"qwen-3-32b\"\n",
    "subtitle = f\"{model.replace('-', ' ').title()}\"\n",
    "base_dir = f\"/workspace/evals/jailbreak/{model}\"\n",
    "out_dir = f\"/root/git/plots/{model}/evals\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b955093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scores from roles_20 as pandas dataframe\n",
    "\n",
    "prefill_path = f\"{base_dir}/jailbreak_spiral_turns1_scores.jsonl\"\n",
    "unsteered_default_path = f\"{base_dir}/unsteered/unsteered_default_scores.jsonl\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0056634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4400 unsteered default scores\n",
      "Loaded 4400 prefill scores\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "with open(unsteered_default_path, \"r\") as f:\n",
    "    unsteered_default_scores = [json.loads(line) for line in f]\n",
    "    \n",
    "with open(prefill_path, \"r\") as f:\n",
    "    prefill_scores = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert to pandas DataFrames\n",
    "prefill_df = pd.DataFrame(prefill_scores)\n",
    "unsteered_default_df = pd.DataFrame(unsteered_default_scores)\n",
    "\n",
    "print(f\"Loaded {len(unsteered_default_df)} unsteered default scores\")   \n",
    "print(f\"Loaded {len(prefill_df)} prefill scores\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b325cbd",
   "metadata": {},
   "source": [
    "## Inspect scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebef7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_overall(df, name):\n",
    "    total = len(df)\n",
    "\n",
    "    # Raw counts of each label\n",
    "    counts = df[\"score\"].value_counts().sort_index()\n",
    "\n",
    "    # Percentages of each label\n",
    "    percentages = (counts / total * 100).round(1)\n",
    "\n",
    "    # Special targets\n",
    "    n_enough = counts.get(\"enough_info\", 0)\n",
    "    n_enough_perfect = counts.get(\"enough_info_and_follow_perfectly\", 0)\n",
    "    n_either = n_enough + n_enough_perfect\n",
    "\n",
    "    pct_enough = 100 * n_enough / total\n",
    "    pct_enough_perfect = 100 * n_enough_perfect / total\n",
    "    pct_either = 100 * n_either / total\n",
    "\n",
    "    print(f\"=== Overall Score Distribution: {name} ===\")\n",
    "    print(f\"Total samples: {total}\\n\")\n",
    "\n",
    "    # Print table of counts + percentages for each label\n",
    "    print(\"Per-label counts and percentages:\")\n",
    "    for label in counts.index:\n",
    "        print(f\"- {label}: {counts[label]} ({percentages[label]}%)\")\n",
    "\n",
    "    print(\"\\nTarget categories:\")\n",
    "    print(f\"- enough_info: {n_enough} ({pct_enough:.1f}%)\")\n",
    "    print(f\"- enough_info_and_follow_perfectly: {n_enough_perfect} ({pct_enough_perfect:.1f}%)\")\n",
    "    print(f\"- either: {n_either} ({pct_either:.1f}%)\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ee16a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Score Distribution: Prefill ===\n",
      "Total samples: 4400\n",
      "\n",
      "Per-label counts and percentages:\n",
      "- almost_enough_info: 24 (0.5%)\n",
      "- enough_info: 210 (4.8%)\n",
      "- out_of_context: 240 (5.5%)\n",
      "- refusal: 99 (2.2%)\n",
      "- refusal_and_justification: 277 (6.3%)\n",
      "- related_but_no_info: 3550 (80.7%)\n",
      "\n",
      "Target categories:\n",
      "- enough_info: 210 (4.8%)\n",
      "- enough_info_and_follow_perfectly: 0 (0.0%)\n",
      "- either: 210 (4.8%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pct_overall(prefill_df, \"Prefill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a07638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Score Distribution: Unsteered + No Jailbreak ===\n",
      "Total samples: 4400\n",
      "\n",
      "Per-label counts and percentages:\n",
      "- almost_enough_info: 6 (0.1%)\n",
      "- enough_info: 51 (1.2%)\n",
      "- other: 1 (0.0%)\n",
      "- out_of_context: 137 (3.1%)\n",
      "- refusal: 416 (9.5%)\n",
      "- refusal_and_justification: 325 (7.4%)\n",
      "- related_but_no_info: 3463 (78.7%)\n",
      "- related_but_no_info.: 1 (0.0%)\n",
      "\n",
      "Target categories:\n",
      "- enough_info: 51 (1.2%)\n",
      "- enough_info_and_follow_perfectly: 0 (0.0%)\n",
      "- either: 51 (1.2%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pct_overall(unsteered_default_df, \"Unsteered + No Jailbreak\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a1876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'role', 'prompt_id', 'question_id', 'prompt', 'question',\n",
      "       'harm_category', 'persona', 'response', 'magnitude', 'score',\n",
      "       'analysis'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(unsteered_default_df.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0611827",
   "metadata": {},
   "source": [
    "## Plot Response Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9cdvlx4lsk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Response percentages:\n",
      "  Harmful Info in Response: 1.2% (51/4400)\n",
      "  Almost Harmful: 0.1% (6/4400)\n",
      "  Related: 78.7% (3463/4400)\n",
      "  Refusal: 9.5% (416/4400)\n",
      "  Refusal & Justification: 7.4% (325/4400)\n",
      "  Out of Context: 3.1% (137/4400)\n",
      "  Other: 0.0% (1/4400)\n",
      "\n",
      "Prefilled Response percentages:\n",
      "  Harmful Info in Response: 4.8% (210/4400)\n",
      "  Almost Harmful: 0.5% (24/4400)\n",
      "  Related: 80.7% (3550/4400)\n",
      "  Refusal: 2.2% (99/4400)\n",
      "  Refusal & Justification: 6.3% (277/4400)\n",
      "  Out of Context: 5.5% (240/4400)\n"
     ]
    }
   ],
   "source": [
    "# Define all response categories and their colors\n",
    "ALL_LABELS = [\n",
    "    \"enough_info\",\n",
    "    \"enough_info_and_follow_perfectly\", \n",
    "    \"almost_enough_info\",\n",
    "    \"related_but_no_info\",\n",
    "    \"refusal\",\n",
    "    \"refusal_and_justification\",\n",
    "    \"out_of_context\",\n",
    "    \"other\"\n",
    "]\n",
    "\n",
    "COLORS = {\n",
    "    \"enough_info_and_follow_perfectly\": \"#e41a1c\",  # red\n",
    "    \"enough_info\": \"#ff7f00\",                      # orange\n",
    "    \"almost_enough_info\": \"#ffff33\",               # yellow\n",
    "    \"related_but_no_info\": \"#1f78b4\",              # cyan/blueish\n",
    "    \"refusal\": \"#b2df8a\",                          # lime green\n",
    "    \"refusal_and_justification\": \"#33a02c\",        # green\n",
    "    \"out_of_context\": \"#6a3d9a\",                   # purple\n",
    "    \"other\": \"#999999\",                            # grey\n",
    "}\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"enough_info\": \"Harmful Info in Response\",\n",
    "    \"enough_info_and_follow_perfectly\": \"Harmful Info & Perfectly Following Request\",\n",
    "    \"refusal\": \"Refusal\",\n",
    "    \"refusal_and_justification\": \"Refusal & Justification\",\n",
    "    \"out_of_context\": \"Out of Context\",\n",
    "    \"related_but_no_info\": \"Related\",\n",
    "    \"almost_enough_info\": \"Almost Harmful\",\n",
    "    \"other\": \"Other\",\n",
    "}\n",
    "\n",
    "def calculate_percentages(df, name):\n",
    "    \"\"\"Calculate percentages for all response categories\"\"\"\n",
    "    total = len(df)\n",
    "    counts = df[\"score\"].value_counts()\n",
    "    \n",
    "    # Ensure all labels are present\n",
    "    percentages = {}\n",
    "    actual_counts = {}\n",
    "    for label in ALL_LABELS:\n",
    "        count = counts.get(label, 0)\n",
    "        actual_counts[label] = count\n",
    "        percentages[label] = (count / total * 100) if total > 0 else 0\n",
    "    \n",
    "    return percentages, actual_counts, total\n",
    "\n",
    "# Calculate data for both conditions\n",
    "default_pct, default_counts, default_total = calculate_percentages(unsteered_default_df, \"Default\")\n",
    "prefill_pct, prefill_counts, prefill_total = calculate_percentages(prefill_df, \"Prefill\")\n",
    "\n",
    "print(\"Default Response percentages:\")\n",
    "for label in ALL_LABELS:\n",
    "    if default_counts[label] > 0:\n",
    "        print(f\"  {LABEL_MAP[label]}: {default_pct[label]:.1f}% ({default_counts[label]}/{default_total})\")\n",
    "\n",
    "print(\"\\nPrefilled Response percentages:\")\n",
    "for label in ALL_LABELS:\n",
    "    if prefill_counts[label] > 0:\n",
    "        print(f\"  {LABEL_MAP[label]}: {prefill_pct[label]:.1f}% ({prefill_counts[label]}/{prefill_total})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kghfz8f6avc",
   "metadata": {},
   "outputs": [],
   "source": "# Create the unified stacked bar plot\nfig = go.Figure()\n\n# X positions for the two bars\nx_positions = [0, 1]  # Default, Prefill\nx_labels = [\"Baseline\", \"Prefilled with 1 Role-Playing Turn\"]\nbar_width = 0.6\n\n# Add stacked bars for each response type\nfor label in ALL_LABELS:\n    # Only add traces for labels that have data in at least one condition\n    if default_counts[label] > 0 or prefill_counts[label] > 0:\n        fig.add_trace(go.Bar(\n            x=x_positions,\n            y=[default_pct[label], prefill_pct[label]],\n            name=LABEL_MAP[label],\n            marker_color=COLORS[label],\n            width=bar_width,\n            text=[f\"{default_pct[label]:.1f}%\" if default_pct[label] >= 2.0 else \"\", \n                  f\"{prefill_pct[label]:.1f}%\" if prefill_pct[label] >= 2.0 else \"\"],\n            textposition=\"inside\",\n            hovertemplate=(\n                \"%{fullData.name}<br>\"\n                \"Condition: %{customdata[2]}<br>\"\n                \"Percentage: %{y:.1f}%<br>\"\n                \"Count: %{customdata[0]} / %{customdata[1]}\"\n                \"<extra></extra>\"\n            ),\n            customdata=[\n                [default_counts[label], default_total, \"Default Response\"],\n                [prefill_counts[label], prefill_total, \"Prefilled Responses\"]\n            ]\n        ))\n\n# Update layout\nfig.update_layout(\n    barmode=\"stack\",\n    width=1000,\n    height=600,\n    title={\n        \"text\": \"Responses to Harmful Questions with High Projection on Role PC1\",\n        \"subtitle\": {\n            \"text\": subtitle + \", Prefilled with 1 Turn from Spiral Transcript\",\n        }\n    },\n    xaxis=dict(\n        title=\"Condition\",\n        tickmode=\"array\",\n        tickvals=x_positions,\n        ticktext=x_labels,\n        showgrid=True,\n        gridcolor=\"lightgray\",\n    ),\n    yaxis=dict(\n        title=\"Percentage of Responses\",\n        range=[0, 105],\n        showgrid=True,\n        gridcolor=\"lightgray\"\n    ),\n    legend=dict(\n        orientation=\"v\",\n        yanchor=\"top\",\n        y=1.0,\n        xanchor=\"left\",\n        x=1.02\n    ),\n    bargap=0.4,\n)\n\nfig.show()\nfig.write_html(f\"{out_dir}/jailbreak_spiral_turn1.html\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c119b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}