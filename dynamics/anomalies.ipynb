{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6083d828",
   "metadata": {},
   "source": [
    "# Trajectories of role + trait space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e91b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-18 16:36:45 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.inference_utils import *\n",
    "from utils.probing_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f9319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in PCA results\n",
    "CHAT_MODEL_NAME = \"Qwen/Qwen3-32B\"\n",
    "model_readable = \"Qwen 3 32B\"\n",
    "model_short = model_readable.replace(\" \", \"-\").lower()\n",
    "layer = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5738412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"auto40\"\n",
    "components = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13489329",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_dir = \"roles_240\" \n",
    "trait_dir = \"traits_240\"\n",
    "\n",
    "acts_input_dir = f\"/workspace/{model_short}/dynamics\"\n",
    "plot_output_dir = f\"/root/git/plots/{model_short}/trajectory\"\n",
    "os.makedirs(plot_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b9a77",
   "metadata": {},
   "source": [
    "## Load and project all conversation activations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0ea9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in activations\n",
    "role_results = torch.load(f\"/workspace/{model_short}/{role_dir}/pca/layer{layer}_pos23.pt\", weights_only=False)\n",
    "trait_results = torch.load(f\"/workspace/{model_short}/{trait_dir}/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065c40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pc_cosine_similarity(mean_acts_per_turn, pca_results, n_pcs=8):\n",
    "    if isinstance(mean_acts_per_turn, list):\n",
    "        stacked_acts = torch.stack(mean_acts_per_turn)\n",
    "    else:\n",
    "        stacked_acts = mean_acts_per_turn\n",
    "    normalized_acts = F.normalize(stacked_acts, dim=1)\n",
    "    normalized_pcs = pca_results['pca'].components_[:n_pcs] / np.linalg.norm(pca_results['pca'].components_[:n_pcs], axis=1, keepdims=True)\n",
    "    cosine_sims = normalized_acts.float().numpy() @ normalized_pcs.T\n",
    "    return cosine_sims\n",
    "\n",
    "def pc_projection(mean_acts_per_turn, pca_results, n_pcs=8):\n",
    "    if isinstance(mean_acts_per_turn, list):\n",
    "        stacked_acts = torch.stack(mean_acts_per_turn)\n",
    "    else:\n",
    "        stacked_acts = mean_acts_per_turn\n",
    "    stacked_acts = stacked_acts.float().numpy()\n",
    "    scaled_acts = pca_results['scaler'].transform(stacked_acts)\n",
    "    projected_acts = pca_results['pca'].transform(scaled_acts)\n",
    "    return projected_acts[:, :n_pcs]\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c09da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load every activation file in the directory if the name matches a regex\n",
    "all_objs = []\n",
    "# for file in os.listdir(acts_input_dir):\n",
    "#     if file.endswith('.pt'):\n",
    "#         obj = torch.load(f\"{acts_input_dir}/{file}\", weights_only=False, map_location=\"cpu\")\n",
    "#         A = obj['activations'][:, layer, :]\n",
    "#         A = A[::2]\n",
    "\n",
    "#         role_sims = pc_cosine_similarity(A, role_results, r_components)\n",
    "#         trait_sims = pc_cosine_similarity(A, trait_results, t_components)\n",
    "#         print(role_sims.shape)\n",
    "\n",
    "#         role_projs = pc_projection(A, role_results, r_components)\n",
    "#         trait_projs = pc_projection(A, trait_results, t_components)\n",
    "#         print(role_projs.shape)\n",
    "\n",
    "#         obj['role_sims'] = role_sims\n",
    "#         obj['trait_sims'] = trait_sims\n",
    "#         obj['role_projs'] = role_projs\n",
    "#         obj['trait_projs'] = trait_projs\n",
    "\n",
    "#         all_objs.append(obj)\n",
    "\n",
    "#         torch.save(obj, f\"{acts_input_dir}/projected/{file}\")\n",
    "for file in os.listdir(f\"{acts_input_dir}/projected\"):\n",
    "\n",
    "    obj = torch.load(f\"{acts_input_dir}/projected/{file}\", weights_only=False, map_location=\"cpu\")\n",
    "    all_objs.append(obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_role_projs = [obj['role_projs'] for obj in all_objs]\n",
    "all_trait_projs = [obj['trait_projs'] for obj in all_objs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbadca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_role_projs = [obj[:, :components] for obj in all_role_projs]\n",
    "sliced_trait_projs = [obj[:, :components] for obj in all_trait_projs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "986b6131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['writing_persona9_topic9', 'writing_persona9_topic8', 'writing_persona9_topic7', 'writing_persona9_topic6', 'writing_persona9_topic5', 'writing_persona9_topic4', 'writing_persona9_topic3', 'writing_persona9_topic2', 'writing_persona9_topic19', 'writing_persona9_topic18']\n"
     ]
    }
   ],
   "source": [
    "files = [f\"{obj['domain']}_persona{obj['persona_id']}_topic{obj['topic_id']}\" for obj in all_objs]\n",
    "print(files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5ca7b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'auditor_model', 'domain', 'persona_id', 'persona', 'topic_id', 'topic', 'turns', 'conversation', 'activations', 'role_sims', 'trait_sims', 'role_projs', 'trait_projs'])\n"
     ]
    }
   ],
   "source": [
    "print(obj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "247dde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['filenames'] = files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cumulative path length for each conversation\n",
    "role_path_lengths = [np.sum(np.linalg.norm(np.diff(obj['role_projs'], axis=0), axis=1)) for obj in all_objs]\n",
    "trait_path_lengths = [np.sum(np.linalg.norm(np.diff(obj['trait_projs'], axis=0), axis=1)) for obj in all_objs]\n",
    "\n",
    "df['role_path_length'] = role_path_lengths\n",
    "df['trait_path_length'] = trait_path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "923b5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv from file into df\n",
    "df = pd.read_csv(f\"./path_lengths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7d0464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also get largest single jump\n",
    "role_max_jump = [np.max(np.linalg.norm(np.diff(obj['role_projs'], axis=0), axis=1)) for obj in all_objs]\n",
    "trait_max_jump = [np.max(np.linalg.norm(np.diff(obj['trait_projs'], axis=0), axis=1)) for obj in all_objs]\n",
    "df['role_max_jump'] = role_max_jump\n",
    "df['trait_max_jump'] = trait_max_jump\n",
    "\n",
    "df.to_csv(f\"./path_lengths.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2727ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role pc1 biggest jump and distance\n",
    "role_pc1_path_lengths = [\n",
    "    np.sum(np.abs(np.diff(obj['role_projs'][:, 0])))  # Only PC1 (column 0)\n",
    "    for obj in all_objs\n",
    "]\n",
    "\n",
    "role_pc1_max_jumps = [\n",
    "    np.max(np.abs(np.diff(obj['role_projs'][:, 0])))  # Max jump in PC1\n",
    "    for obj in all_objs\n",
    "]\n",
    "\n",
    "df['role_pc1_path_length'] = role_pc1_path_lengths\n",
    "df['role_pc1_max_jump'] = role_pc1_max_jumps\n",
    "\n",
    "\n",
    "df.to_csv(f\"./path_lengths.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a92d4",
   "metadata": {},
   "source": [
    "## Cosine similarity with trait and role PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfee379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387c10f",
   "metadata": {},
   "source": [
    "## Plot trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536422d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_response_trajectory(similarity_matrix, conversation=None, title=None, pc_titles=None, projection=False):\n",
    "    \"\"\"\n",
    "    Create a single line plot showing mean response per turn.\n",
    "    \n",
    "    Parameters:\n",
    "    - similarity_matrix: Numpy matrix of shape (n_turns, n_pcs)\n",
    "    - conversation: Optional conversation data for turn context\n",
    "    - title: Optional custom title\n",
    "    - pc_titles: Optional list of PC titles\n",
    "    \n",
    "    Returns:\n",
    "    - Plotly figure object\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Creating mean response trajectory plot...\")\n",
    "    \n",
    "    # Get dimensions\n",
    "    n_turns, n_pcs = similarity_matrix.shape\n",
    "    turn_indices = np.arange(n_turns)\n",
    "    \n",
    "    # Create default PC titles if not provided\n",
    "    if pc_titles is None:\n",
    "        pc_titles = [f\"PC{i+1}\" for i in range(n_pcs)]\n",
    "    \n",
    "    # Define color palette for PCs\n",
    "    pc_colors = [\n",
    "        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', \n",
    "        '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "        '#bcbd22', '#17becf', '#aec7e8', '#ffbb78'\n",
    "    ]\n",
    "    \n",
    "    # Helper function to wrap text for hover display\n",
    "    def wrap_text(text, max_chars_per_line=70):\n",
    "        \"\"\"Wrap text to specified line length with HTML breaks.\"\"\"\n",
    "        if len(text) <= max_chars_per_line:\n",
    "            return text\n",
    "        \n",
    "        words = text.split()\n",
    "        lines = []\n",
    "        current_line = []\n",
    "        current_length = 0\n",
    "        \n",
    "        for word in words:\n",
    "            if current_length + len(word) + len(current_line) > max_chars_per_line:\n",
    "                if current_line:  # Don't add empty lines\n",
    "                    lines.append(' '.join(current_line))\n",
    "                current_line = [word]\n",
    "                current_length = len(word)\n",
    "            else:\n",
    "                current_line.append(word)\n",
    "                current_length += len(word)\n",
    "        \n",
    "        if current_line:  # Add the last line\n",
    "            lines.append(' '.join(current_line))\n",
    "        \n",
    "        return '<br>'.join(lines)\n",
    "    \n",
    "    # Create enhanced turn context for hover text\n",
    "    turn_contexts = []\n",
    "    if conversation is not None:\n",
    "        assistant_turns = [i for i, turn in enumerate(conversation) if turn['role'] == 'assistant']\n",
    "        for turn_idx in range(n_turns):\n",
    "            if turn_idx < len(assistant_turns):\n",
    "                conv_turn_idx = assistant_turns[turn_idx]\n",
    "                if conv_turn_idx < len(conversation):\n",
    "                    # Get assistant response\n",
    "                    assistant_content = conversation[conv_turn_idx]['content']\n",
    "                    \n",
    "                    # Get preceding user question (if exists)\n",
    "                    user_content = \"\"\n",
    "                    if conv_turn_idx > 0 and conversation[conv_turn_idx - 1]['role'] == 'user':\n",
    "                        user_content = conversation[conv_turn_idx - 1]['content']\n",
    "                    \n",
    "                    # Format hover text with both user question and assistant response\n",
    "                    hover_parts = [f\"<b>Turn {turn_idx}</b>\"]\n",
    "                    \n",
    "                    if user_content:\n",
    "                        # Truncate user content to reasonable length and wrap\n",
    "                        user_truncated = user_content[:200] + \"...\" if len(user_content) > 200 else user_content\n",
    "                        user_wrapped = wrap_text(user_truncated, 70)\n",
    "                        hover_parts.append(f\"<b>User:</b> {user_wrapped}\")\n",
    "                    \n",
    "                    # Show more of the assistant response (150-200 chars) and wrap\n",
    "                    assistant_truncated = assistant_content[:300] + \"...\" if len(assistant_content) > 180 else assistant_content\n",
    "                    assistant_wrapped = wrap_text(assistant_truncated, 70)\n",
    "                    hover_parts.append(f\"<b>Assistant:</b> {assistant_wrapped}\")\n",
    "                    \n",
    "                    turn_contexts.append('<br>'.join(hover_parts))\n",
    "                else:\n",
    "                    turn_contexts.append(f\"<b>Turn {turn_idx}</b>\")\n",
    "            else:\n",
    "                turn_contexts.append(f\"<b>Turn {turn_idx}</b>\")\n",
    "    else:\n",
    "        turn_contexts = [f\"<b>Turn {turn_idx}</b>\" for turn_idx in range(n_turns)]\n",
    "    \n",
    "    # Create Plotly figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add line traces for each PC with markers\n",
    "    for pc_idx in range(n_pcs):\n",
    "        pc_name = pc_titles[pc_idx]\n",
    "        similarities = similarity_matrix[:, pc_idx]\n",
    "        color = pc_colors[pc_idx % len(pc_colors)]\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=turn_indices,\n",
    "            y=similarities,\n",
    "            mode='lines+markers',\n",
    "            name=pc_name,\n",
    "            line=dict(color=color, width=2),\n",
    "            marker=dict(color=color, size=4, opacity=0.8),\n",
    "            hovertemplate='<b>%{fullData.name}</b><br>' +\n",
    "                         '%{text}<br>' +\n",
    "                         '<b>Cosine Similarity:</b> %{y:.3f}<br>' +\n",
    "                         '<extra></extra>',\n",
    "            text=turn_contexts\n",
    "        ))\n",
    "    \n",
    "    # Update layout\n",
    "    default_title = f\"Mean Response PC Trajectory\"\n",
    "    if projection:\n",
    "        yaxis_title = \"PC Projection\"\n",
    "    else:\n",
    "        yaxis_title = \"Cosine Similarity with PC\"\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=title if title else default_title,\n",
    "            x=0.5,\n",
    "            font=dict(size=16),\n",
    "            subtitle={\"text\": f\"{model_readable}, Layer {layer}\"}\n",
    "        ),\n",
    "        xaxis_title=\"Conversation Turn\",\n",
    "        yaxis_title=yaxis_title,\n",
    "        width=1400,\n",
    "        height=600,\n",
    "        hovermode='closest',\n",
    "        legend=dict(\n",
    "            yanchor=\"middle\",\n",
    "            y=0.5,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02,\n",
    "            bgcolor=\"rgba(255,255,255,0.8)\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add grid for easier reading\n",
    "    fig.update_xaxes(\n",
    "        showgrid=True, \n",
    "        gridwidth=1, \n",
    "        gridcolor='lightgray',\n",
    "        zeroline=True,\n",
    "        tick0=0,\n",
    "        dtick=1  # Show every turn\n",
    "    )\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', zeroline=True)\n",
    "    \n",
    "    # Add light vertical lines between turns for clarity\n",
    "    for turn_idx in range(1, n_turns):\n",
    "        fig.add_vline(\n",
    "            x=turn_idx - 0.5,\n",
    "            line_dash=\"dot\",\n",
    "            line_color=\"lightgray\",\n",
    "            line_width=1,\n",
    "            opacity=0.3\n",
    "        )\n",
    "    \n",
    "    print(f\"Created trajectory plot with {n_pcs} PC lines across {n_turns} turns\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t33zwajz7ei",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create role PC titles\n",
    "if model_short == \"qwen-3-32b\":\n",
    "    role_pc_titles = ['Assistant-like ↔ role-playing', \"mystical/transcendent ↔ mundane/irreverent\", \"empathetic/vulnerable ↔ analytical/predatory\", \"concrete/practical ↔ abstract/ideological\", \"thinking/passive ↔ doing/active\", \"creative/expressive ↔ rigid/constrained\"]\n",
    "elif model_short == \"gemma-2-27b\":\n",
    "    role_pc_titles = ['Assistant-like ↔ role-playing', \"inhuman ↔ human\", \"independent ↔ dependent\", \"nurturing ↔ adversarial\", \"social ↔ technical\", \"structured ↔ liminal\"]\n",
    "\n",
    "# # Plot role trajectory\n",
    "# role_fig = plot_mean_response_trajectory(\n",
    "#     role_sims, \n",
    "#     conversation=conversation, \n",
    "#     title=f\"Conversation Trajectory in Role PC Space: {filename.capitalize()}\", \n",
    "#     pc_titles=role_pc_titles\n",
    "# )\n",
    "# role_fig.show()\n",
    "# role_fig.write_html(f\"{plot_output_dir}/{filename}_role_cossim.html\")\n",
    "\n",
    "# role_fig = plot_mean_response_trajectory(\n",
    "#     role_projs, \n",
    "#     conversation=conversation, \n",
    "#     title=f\"Conversation Trajectory in Role PC Space: {filename.capitalize()}\", \n",
    "#     pc_titles=role_pc_titles,\n",
    "#     projection=True\n",
    "# )\n",
    "# role_fig.show()\n",
    "# role_fig.write_html(f\"{plot_output_dir}/{filename}_role_proj.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hnqktqubkub",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trait PC titles\n",
    "if model_short == \"qwen-3-32b\":\n",
    "    trait_pc_titles = [\"expressive/irreverent ↔ controlled/professional\", \"analytical ↔ intuitive\", \"accessible/practical ↔ esoteric/complex\", \"active/flexible ↔ passsive/rigid\", \"questioning ↔ confident\", \"indirect/diplomatic ↔ direct/assertive\"]\n",
    "elif model_short == \"gemma-2-27b\":\n",
    "    trait_pc_titles = [\"benevolent ↔ evil\", \"analytical ↔ emotional\", \"accommodating ↔ confrontational\", \"grounded ↔ mystical\", \"thoughtful ↔ decisive\", \"conformist ↔ defiant\"]\n",
    "\n",
    "# Plot trait trajectory\n",
    "# trait_fig = plot_mean_response_trajectory(\n",
    "#     trait_sims, \n",
    "#     conversation=conversation, \n",
    "#     title=f\"Conversation Trajectory in Trait PC Space: {filename.capitalize()}\", \n",
    "#     pc_titles=trait_pc_titles\n",
    "# )\n",
    "# trait_fig.show()\n",
    "# trait_fig.write_html(f\"{plot_output_dir}/{filename}_trait_cossim.html\")\n",
    "\n",
    "# trait_fig = plot_mean_response_trajectory(\n",
    "#     trait_projs, \n",
    "#     conversation=conversation, \n",
    "#     title=f\"Conversation Trajectory in Trait PC Space: {filename.capitalize()}\", \n",
    "#     pc_titles=trait_pc_titles,\n",
    "#     projection=True\n",
    "# )\n",
    "\n",
    "# trait_fig.show()\n",
    "# trait_fig.write_html(f\"{plot_output_dir}/{filename}_trait_proj.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kbhzrwz949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined plot showing both role and trait trajectories\n",
    "\n",
    "import plotly.subplots as sp\n",
    "\n",
    "\n",
    "# Create subplot figure\n",
    "combined_fig = sp.make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(\"Trajectory in Role PC Space\", \"Trajectory in Trait PC Space\"),\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "for tr in plot_mean_response_trajectory(\n",
    "        role_projs, conversation=None, title=\"<b>Role PCs</b>\", pc_titles=role_pc_titles, projection=True\n",
    "    ).data:\n",
    "    tr.update(\n",
    "        showlegend=True,\n",
    "        legendgroup=\"role\",\n",
    "        legendgrouptitle_text=\"Role PCs\"\n",
    "    )\n",
    "    combined_fig.add_trace(tr, row=1, col=1)\n",
    "\n",
    "# Add trait traces to second subplot\n",
    "for tr in plot_mean_response_trajectory(\n",
    "        trait_projs, conversation=None, title=\"<b>Trait PCs</b>\", pc_titles=trait_pc_titles, projection=True\n",
    "    ).data:\n",
    "    tr.update(\n",
    "        showlegend=True,\n",
    "        legendgroup=\"trait\",\n",
    "        legendgrouptitle_text=\"Trait PCs\"\n",
    "    )\n",
    "    combined_fig.add_trace(tr, row=2, col=1)\n",
    "\n",
    "combined_fig.update_layout(\n",
    "    height=800,\n",
    "    width=1200,\n",
    "    title={\n",
    "        \"text\": f\"Conversation Trajectories in Persona Subspace: 100 Coding Conversations (code blocks filtered out)\",\n",
    "        \"subtitle\": {\"text\": f\"{model_readable}, Layer {layer}\"}\n",
    "    },\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        traceorder=\"grouped\",     # keeps groups together\n",
    "        groupclick=\"toggleitem\",\n",
    "        x=1.02, xanchor=\"left\",   # place legend outside on the right\n",
    "        y=1, yanchor=\"top\"\n",
    "    ),\n",
    "    legend_tracegroupgap=12       # space between groups\n",
    ")\n",
    "# Bottom x-axis label only\n",
    "combined_fig.update_xaxes(title_text=\"Conversation Turn\", row=2, col=1)\n",
    "\n",
    "# Y-axis labels for both subplots\n",
    "combined_fig.update_yaxes(title_text=\"PC Projection\", row=1, col=1)\n",
    "combined_fig.update_yaxes(title_text=\"PC Projection\", row=2, col=1)\n",
    "\n",
    "combined_fig.show()\n",
    "combined_fig.write_html(f\"{plot_output_dir}/auto_coding_no_code.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
