{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6083d828",
   "metadata": {},
   "source": [
    "# Trajectories of role + trait space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29e91b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.inference_utils import *\n",
    "from utils.probing_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47f9319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in PCA results\n",
    "CHAT_MODEL_NAME = \"Qwen/Qwen3-32B\"\n",
    "model_readable = \"Qwen 3 32B\"\n",
    "model_short = model_readable.replace(\" \", \"-\").lower()\n",
    "layer = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5738412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"auto40\"\n",
    "components = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13489329",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_dir = \"roles_240\" \n",
    "trait_dir = \"traits_240\"\n",
    "\n",
    "acts_input_dir = f\"/workspace/{model_short}/dynamics\"\n",
    "plot_output_dir = f\"/root/git/plots/{model_short}/trajectory\"\n",
    "os.makedirs(plot_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b9a77",
   "metadata": {},
   "source": [
    "## Load and project all conversation activations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ea9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in activations\n",
    "role_results = torch.load(f\"/workspace/{model_short}/{role_dir}/pca/layer{layer}_pos23.pt\", weights_only=False)\n",
    "trait_results = torch.load(f\"/workspace/{model_short}/{trait_dir}/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "065c40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pc_cosine_similarity(mean_acts_per_turn, pca_results, n_pcs=8):\n",
    "    if isinstance(mean_acts_per_turn, list):\n",
    "        stacked_acts = torch.stack(mean_acts_per_turn)\n",
    "    else:\n",
    "        stacked_acts = mean_acts_per_turn\n",
    "    normalized_acts = F.normalize(stacked_acts, dim=1)\n",
    "    normalized_pcs = pca_results['pca'].components_[:n_pcs] / np.linalg.norm(pca_results['pca'].components_[:n_pcs], axis=1, keepdims=True)\n",
    "    cosine_sims = normalized_acts.float().numpy() @ normalized_pcs.T\n",
    "    return cosine_sims\n",
    "\n",
    "def pc_projection(mean_acts_per_turn, pca_results, n_pcs=8):\n",
    "    if isinstance(mean_acts_per_turn, list):\n",
    "        stacked_acts = torch.stack(mean_acts_per_turn)\n",
    "    else:\n",
    "        stacked_acts = mean_acts_per_turn\n",
    "    stacked_acts = stacked_acts.float().numpy()\n",
    "    scaled_acts = pca_results['scaler'].transform(stacked_acts)\n",
    "    projected_acts = pca_results['pca'].transform(scaled_acts)\n",
    "    return projected_acts[:, :n_pcs]\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c09da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(5, 463)\n",
      "(5, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(5, 463)\n",
      "(5, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(5, 463)\n",
      "(5, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(5, 463)\n",
      "(5, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(5, 463)\n",
      "(5, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(5, 463)\n",
      "(5, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(6, 463)\n",
      "(6, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(9, 463)\n",
      "(9, 240)\n",
      "(5, 463)\n",
      "(5, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(13, 463)\n",
      "(13, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(8, 463)\n",
      "(8, 240)\n",
      "(10, 463)\n",
      "(10, 240)\n",
      "(12, 463)\n",
      "(12, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(11, 463)\n",
      "(11, 240)\n",
      "(7, 463)\n",
      "(7, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(6, 463)\n",
      "(6, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n",
      "(14, 463)\n",
      "(14, 240)\n"
     ]
    }
   ],
   "source": [
    "# load every activation file in the directory if the name matches a regex\n",
    "all_objs = []\n",
    "for file in os.listdir(acts_input_dir):\n",
    "    if file.endswith('.pt'):\n",
    "        obj = torch.load(f\"{acts_input_dir}/{file}\", weights_only=False, map_location=\"cpu\")\n",
    "        A = obj['activations'][:, layer, :]\n",
    "        A = A[1::2]\n",
    "\n",
    "        role_sims = pc_cosine_similarity(A, role_results, None)\n",
    "        trait_sims = pc_cosine_similarity(A, trait_results, None)\n",
    "        print(role_sims.shape)\n",
    "        print(trait_sims.shape)\n",
    "\n",
    "        role_projs = pc_projection(A, role_results, None)\n",
    "        trait_projs = pc_projection(A, trait_results, None)\n",
    "\n",
    "        obj['role_sims'] = role_sims\n",
    "        obj['trait_sims'] = trait_sims\n",
    "        obj['role_projs'] = role_projs\n",
    "        obj['trait_projs'] = trait_projs\n",
    "\n",
    "        all_objs.append(obj)\n",
    "\n",
    "        torch.save(obj, f\"{acts_input_dir}/projected/{file}\")\n",
    "# for file in os.listdir(f\"{acts_input_dir}/projected\"):\n",
    "\n",
    "#     obj = torch.load(f\"{acts_input_dir}/projected/{file}\", weights_only=False, map_location=\"cpu\")\n",
    "#     all_objs.append(obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae01fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_role_projs = [obj['role_projs'] for obj in all_objs]\n",
    "all_trait_projs = [obj['trait_projs'] for obj in all_objs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbadca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_role_projs = [obj[:, :components] for obj in all_role_projs]\n",
    "sliced_trait_projs = [obj[:, :components] for obj in all_trait_projs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986b6131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['writing_persona9_topic9', 'writing_persona9_topic8', 'writing_persona9_topic7', 'writing_persona9_topic6', 'writing_persona9_topic5', 'writing_persona9_topic4', 'writing_persona9_topic3', 'writing_persona9_topic2', 'writing_persona9_topic19', 'writing_persona9_topic18']\n"
     ]
    }
   ],
   "source": [
    "files = [f\"{obj['domain']}_persona{obj['persona_id']}_topic{obj['topic_id']}\" for obj in all_objs]\n",
    "print(files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5ca7b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'auditor_model', 'domain', 'persona_id', 'persona', 'topic_id', 'topic', 'turns', 'conversation', 'activations', 'role_sims', 'trait_sims', 'role_projs', 'trait_projs'])\n"
     ]
    }
   ],
   "source": [
    "print(obj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "247dde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['filenames'] = files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3334ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cumulative path length for each conversation\n",
    "role_path_lengths = [np.sum(np.linalg.norm(np.diff(obj['role_projs'], axis=0), axis=1)) for obj in all_objs]\n",
    "trait_path_lengths = [np.sum(np.linalg.norm(np.diff(obj['trait_projs'], axis=0), axis=1)) for obj in all_objs]\n",
    "\n",
    "df['role_path_length'] = role_path_lengths\n",
    "df['trait_path_length'] = trait_path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv from file into df\n",
    "df = pd.read_csv(f\"./path_lengths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b7d0464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also get largest single jump\n",
    "role_max_jump = [np.max(np.linalg.norm(np.diff(obj['role_projs'], axis=0), axis=1)) for obj in all_objs]\n",
    "trait_max_jump = [np.max(np.linalg.norm(np.diff(obj['trait_projs'], axis=0), axis=1)) for obj in all_objs]\n",
    "df['role_max_jump'] = role_max_jump\n",
    "df['trait_max_jump'] = trait_max_jump\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2727ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role pc1 biggest jump and distance\n",
    "role_pc1_path_lengths = [\n",
    "    np.sum(np.abs(np.diff(obj['role_projs'][:, 0])))  # Only PC1 (column 0)\n",
    "    for obj in all_objs\n",
    "]\n",
    "\n",
    "role_pc1_max_jumps = [\n",
    "    np.max(np.abs(np.diff(obj['role_projs'][:, 0])))  # Max jump in PC1\n",
    "    for obj in all_objs\n",
    "]\n",
    "\n",
    "df['role_pc1_path_length'] = role_pc1_path_lengths\n",
    "df['role_pc1_max_jump'] = role_pc1_max_jumps\n",
    "\n",
    "\n",
    "df.to_csv(f\"./stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c236c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-15.46315117 -13.0795536    5.49008361   4.20218061   3.55202424\n",
      "  -7.76324587  -9.99787456  -8.80170644  -7.14331595  12.63595519\n",
      "  -8.40975517   3.94093019   1.6871792   13.69682304]\n"
     ]
    }
   ],
   "source": [
    "pc1 = all_objs[files.index(\"therapy_persona10_topic19\")]['role_projs'][:, 0]\n",
    "print(pc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a92d4",
   "metadata": {},
   "source": [
    "## Getting roles with target projections on role PC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70947347",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/workspace/qwen-3-32b/roles_240'\n",
    "pca_results = torch.load(f'{dir}/pca/layer{layer}_pos23.pt', weights_only=False)\n",
    "pca_transformed = pca_results['pca_transformed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b87ff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    }
   ],
   "source": [
    "def get_role_labels(pca_results):\n",
    "    labels = []\n",
    "    if 'pos_2' in pca_results['roles'].keys():\n",
    "        labels.extend(pca_results['roles']['pos_2'])\n",
    "    if 'pos_3' in pca_results['roles'].keys():\n",
    "        labels.extend(pca_results['roles']['pos_3'])\n",
    "    return labels\n",
    "\n",
    "def get_trait_labels(pca_results):\n",
    "    labels = []\n",
    "    if 'pos_neg' in pca_results['traits'].keys():\n",
    "        labels.extend(pca_results['traits']['pos_neg'])\n",
    "    if 'pos_neg_50' in pca_results['traits'].keys():\n",
    "        labels.extend(pca_results['traits']['pos_neg_50'])\n",
    "    return labels\n",
    "\n",
    "labels = get_role_labels(pca_results)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6bf12d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_by_pc(pc_index):\n",
    "    df = pd.DataFrame({\n",
    "        \"label\": labels,\n",
    "        \"projection\": pca_transformed[:, pc_index],\n",
    "        \"score\": [\"pos_2\"] * len(pca_results['roles']['pos_2']) + [\"pos_3\"] * len(pca_results['roles']['pos_3']) \n",
    "    })\n",
    "    df_sorted = df.sort_values(by=\"projection\", ascending=True)\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f70abee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df = sorted_by_pc(0)\n",
    "#pc_df.to_csv(\"/root/git/persona-subspace/dynamics/results/qwen-3-32b/roles_pc1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "434dff07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_df['projection'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b4b9f2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-38\n",
      "validator -37.98302365995255 pos_3\n",
      "-12\n",
      "podcaster -11.917165905106012 pos_2\n",
      "14\n",
      "visionary 14.000623879678056 pos_3\n",
      "40\n",
      "fool 40.05872476576472 pos_3\n",
      "66\n",
      "whale 66.41810071794757 pos_3\n",
      "92\n",
      "leviathan 92.81104297322707 pos_3\n",
      "['validator', 'podcaster', 'visionary', 'fool', 'whale', 'leviathan']\n"
     ]
    }
   ],
   "source": [
    "target_roles = []\n",
    "target_projections = []\n",
    "\n",
    "for i in range(-38, 102, 26):\n",
    "    print(i)\n",
    "    # get the index of the label that is closest to i\n",
    "    index = np.argmin(np.abs(pc_df['projection'] - i))\n",
    "    #print the label and the projection\n",
    "    print(pc_df['label'].iloc[index], pc_df['projection'].iloc[index], pc_df['score'].iloc[index])\n",
    "    target_roles.append(pc_df['label'].iloc[index])\n",
    "    target_projections.append(i)\n",
    "print(target_roles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db5250de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validator', 'podcaster', 'visionary', 'narcissist', 'whale', 'leviathan']\n"
     ]
    }
   ],
   "source": [
    "target_roles[3] = \"narcissist\"\n",
    "print(target_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "340ffd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validator -38\n",
      "            label  projection  distance\n",
      "779    pos_p3_q59  -37.997406  0.002594\n",
      "594   pos_p2_q114  -37.995072  0.004928\n",
      "1090  pos_p4_q130  -38.031120  0.031120\n",
      "1079  pos_p4_q119  -38.047506  0.047506\n",
      "podcaster -12\n",
      "           label  projection  distance\n",
      "424  pos_p1_q184  -12.018051  0.018051\n",
      "857  pos_p3_q137  -12.032356  0.032356\n",
      "34    pos_p0_q34  -12.033337  0.033337\n",
      "362  pos_p1_q122  -11.966280  0.033720\n",
      "visionary 14\n",
      "           label  projection  distance\n",
      "396  pos_p1_q156   14.066310  0.066310\n",
      "436  pos_p1_q196   13.893611  0.106389\n",
      "139  pos_p0_q139   14.111792  0.111792\n",
      "609  pos_p2_q129   13.839211  0.160789\n",
      "narcissist 40\n",
      "            label  projection  distance\n",
      "405   pos_p1_q165   40.005305  0.005305\n",
      "423   pos_p1_q183   39.980503  0.019497\n",
      "1153  pos_p4_q193   39.970121  0.029879\n",
      "421   pos_p1_q181   39.970005  0.029995\n",
      "whale 66\n",
      "            label  projection  distance\n",
      "215   pos_p0_q215   65.923039  0.076961\n",
      "1071  pos_p4_q111   65.900430  0.099570\n",
      "638   pos_p2_q158   65.816949  0.183051\n",
      "7       pos_p0_q7   65.767598  0.232402\n",
      "leviathan 92\n",
      "            label  projection  distance\n",
      "178   pos_p0_q178   92.002422  0.002422\n",
      "1037   pos_p4_q77   91.974529  0.025471\n",
      "893   pos_p3_q173   92.046493  0.046493\n",
      "166   pos_p0_q166   91.952747  0.047253\n"
     ]
    }
   ],
   "source": [
    "# collect all sorted dataframes to calculate average positions\n",
    "all_sorted_dataframes = []\n",
    "position_data = {}\n",
    "\n",
    "# for each target role, load in the activations and project them onto pc1\n",
    "for role, proj in zip(target_roles, target_projections):\n",
    "    print(role, proj)\n",
    "\n",
    "    acts = torch.load(f\"/workspace/qwen-3-32b/roles_240/response_activations/{role}.pt\", weights_only=False)\n",
    "\n",
    "    stacked_acts = torch.stack([v[layer, :] for v in acts.values()])\n",
    "    role_projs = pc_projection(stacked_acts, pca_results, 1)\n",
    "\n",
    "    role_df = pd.DataFrame({\n",
    "        \"label\": acts.keys(),\n",
    "        \"projection\": role_projs.squeeze(),\n",
    "    })\n",
    "\n",
    "    role_df['distance'] = np.abs(role_df['projection'] - proj)\n",
    "\n",
    "    # sort the question index by closest to the target projection\n",
    "    role_df = role_df.sort_values(by='distance')\n",
    "\n",
    "    # store the sorted dataframe\n",
    "    all_sorted_dataframes.append(role_df)\n",
    "\n",
    "    # record position of each label in this sorted dataframe\n",
    "    for idx, label in enumerate(role_df['label']):\n",
    "        if label not in position_data:\n",
    "            position_data[label] = []\n",
    "        position_data[label].append(idx)\n",
    "\n",
    "    # print the first 4 rows of the sorted dataframe\n",
    "    print(role_df.head(4))\n",
    "    role_df.to_csv(f\"/root/git/persona-subspace/dynamics/results/qwen-3-32b/prefills/{role}_pc1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect distance data for each label per role\n",
    "distance_data = {}\n",
    "\n",
    "# for each dataframe, record the distance for each label  \n",
    "for i, role_df in enumerate(all_sorted_dataframes):\n",
    "    role = target_roles[i]\n",
    "    for _, row in role_df.iterrows():\n",
    "        label = row['label']\n",
    "        distance = row['distance']\n",
    "        \n",
    "        if label not in distance_data:\n",
    "            distance_data[label] = {}\n",
    "        distance_data[label][role] = distance\n",
    "\n",
    "# calculate average position and MSE for each label\n",
    "average_positions = {}\n",
    "mse_scores = {}\n",
    "\n",
    "for label, positions in position_data.items():\n",
    "    average_positions[label] = np.mean(positions)\n",
    "    \n",
    "    # calculate MSE across role distances\n",
    "    if label in distance_data:\n",
    "        distances = []\n",
    "        for role in target_roles:\n",
    "            if role in distance_data[label]:\n",
    "                distances.append(distance_data[label][role])\n",
    "        \n",
    "        if distances:\n",
    "            mse_scores[label] = np.mean(np.array(distances) ** 2)\n",
    "        else:\n",
    "            mse_scores[label] = np.inf\n",
    "    else:\n",
    "        mse_scores[label] = np.inf\n",
    "\n",
    "# create dataframe with average position, MSE, and distance per role\n",
    "rows = []\n",
    "for label in average_positions.keys():\n",
    "    row_data = {\n",
    "        \"label\": label, \n",
    "        \"average_position\": average_positions[label],\n",
    "        \"mse_distance\": mse_scores[label]\n",
    "    }\n",
    "    \n",
    "    # add distance for each role\n",
    "    for role in target_roles:\n",
    "        if label in distance_data and role in distance_data[label]:\n",
    "            row_data[f\"{role}_distance\"] = distance_data[label][role]\n",
    "        else:\n",
    "            row_data[f\"{role}_distance\"] = np.nan\n",
    "    \n",
    "    rows.append(row_data)\n",
    "\n",
    "average_position_df = pd.DataFrame(rows)\n",
    "\n",
    "# sort by MSE instead of average position\n",
    "average_position_df = average_position_df.sort_values(by='mse_distance')\n",
    "\n",
    "\n",
    "print(\"\\nLabels sorted by average position across all dataframes:\")\n",
    "print(average_position_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "awbmtmxfh6m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Questions sorted by MSE distance (best prompt per role per question):\n",
      "     question_id  mse_distance  validator_distance  validator_best_prompt  \\\n",
      "35           132      1.590810            0.427428                      2   \n",
      "137           42      1.715367            2.395581                      0   \n",
      "86           217      1.804398            0.974830                      2   \n",
      "64           133      2.058864            0.737193                      0   \n",
      "100          111      2.079271            1.226899                      4   \n",
      "29           120      2.478459            0.358391                      4   \n",
      "52            31      3.133498            0.609123                      0   \n",
      "139          170      3.680787            2.455120                      0   \n",
      "9            139      3.814337            0.074946                      4   \n",
      "129           23      3.928335            2.036972                      0   \n",
      "11           165      4.089504            0.103096                      0   \n",
      "162          237      4.252244            3.524591                      4   \n",
      "58             1      4.455752            0.672871                      2   \n",
      "138           19      4.473399            2.423543                      1   \n",
      "69            11      5.080869            0.765359                      1   \n",
      "123          197      5.491145            1.866665                      1   \n",
      "70           117      5.598976            0.767527                      2   \n",
      "122          103      6.139645            1.837251                      2   \n",
      "67            39      6.188433            0.755876                      4   \n",
      "4             36      6.199821            0.052706                      3   \n",
      "\n",
      "     podcaster_distance  podcaster_best_prompt  visionary_distance  \\\n",
      "35             1.193255                      0            1.177850   \n",
      "137            0.036034                      1            0.661650   \n",
      "86             1.052576                      3            0.623954   \n",
      "64             0.634048                      0            2.039966   \n",
      "100            1.687536                      0            2.335127   \n",
      "29             1.410205                      1            2.683739   \n",
      "52             1.306289                      0            2.047020   \n",
      "139            0.561666                      0            3.073610   \n",
      "9              0.463649                      2            0.111792   \n",
      "129            2.791411                      0            1.879850   \n",
      "11             2.201927                      0            0.961608   \n",
      "162            1.448158                      3            0.205583   \n",
      "58             3.235309                      2            2.320129   \n",
      "138            0.801261                      4            1.860922   \n",
      "69             1.989733                      2            3.352679   \n",
      "123            2.138200                      3            1.198005   \n",
      "70             0.470289                      3            0.914240   \n",
      "122            2.036814                      2            0.909307   \n",
      "67             4.979800                      2            1.339570   \n",
      "4              1.319227                      1            0.627337   \n",
      "\n",
      "     visionary_best_prompt  narcissist_distance  narcissist_best_prompt  \\\n",
      "35                       2             0.991084                       4   \n",
      "137                      1             1.848568                       2   \n",
      "86                       4             1.136810                       4   \n",
      "64                       3             1.476698                       2   \n",
      "100                      1             1.428270                       3   \n",
      "29                       4             0.481135                       3   \n",
      "52                       3             0.850264                       4   \n",
      "139                      1             0.033695                       3   \n",
      "9                        0             4.712168                       3   \n",
      "129                      3             2.092021                       1   \n",
      "11                       4             0.005305                       1   \n",
      "162                      4             0.699911                       4   \n",
      "58                       3             0.522302                       2   \n",
      "138                      4             0.429513                       4   \n",
      "69                       1             0.966271                       2   \n",
      "123                      2             4.294244                       1   \n",
      "70                       3             1.193794                       3   \n",
      "122                      4             1.374240                       3   \n",
      "67                       4             1.105905                       4   \n",
      "4                        3             0.686995                       0   \n",
      "\n",
      "     whale_distance  whale_best_prompt  leviathan_distance  \\\n",
      "35         2.348354                  2            0.232296   \n",
      "137        0.360123                  3            0.753275   \n",
      "86         1.206340                  3            2.373029   \n",
      "64         1.723226                  2            1.447793   \n",
      "100        0.099570                  4            0.787326   \n",
      "29         2.137125                  4            0.867398   \n",
      "52         3.090788                  2            1.502450   \n",
      "139        2.505485                  1            0.126368   \n",
      "9          0.285065                  4            0.605929   \n",
      "129        1.886259                  3            0.400523   \n",
      "11         3.511158                  1            2.534751   \n",
      "162        1.929695                  0            2.595708   \n",
      "58         3.004449                  0            1.063965   \n",
      "138        0.756056                  1            4.013189   \n",
      "69         2.524246                  0            2.719274   \n",
      "123        1.368192                  2            1.772805   \n",
      "70         1.705058                  0            5.255034   \n",
      "122        5.137807                  2            0.448699   \n",
      "67         0.393125                  3            2.930670   \n",
      "4          2.754675                  1            5.196349   \n",
      "\n",
      "     leviathan_best_prompt  \n",
      "35                       4  \n",
      "137                      1  \n",
      "86                       1  \n",
      "64                       1  \n",
      "100                      4  \n",
      "29                       4  \n",
      "52                       1  \n",
      "139                      0  \n",
      "9                        4  \n",
      "129                      1  \n",
      "11                       3  \n",
      "162                      1  \n",
      "58                       4  \n",
      "138                      3  \n",
      "69                       3  \n",
      "123                      4  \n",
      "70                       0  \n",
      "122                      3  \n",
      "67                       2  \n",
      "4                        3  \n"
     ]
    }
   ],
   "source": [
    "# group by question_id and find minimum distance for each role across prompt_ids\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "question_data = {}\n",
    "\n",
    "# parse labels and group by question_id\n",
    "for label in distance_data.keys():\n",
    "    # extract prompt_id and question_id from label format pos_p{prompt_id}_q{question_id}\n",
    "    match = re.match(r'pos_p(\\d+)_q(\\d+)', label)\n",
    "    if match:\n",
    "        prompt_id = int(match.group(1))\n",
    "        question_id = int(match.group(2))\n",
    "        \n",
    "        if question_id not in question_data:\n",
    "            question_data[question_id] = {}\n",
    "        \n",
    "        # store distance data for this prompt_id, question_id combination\n",
    "        question_data[question_id][prompt_id] = {\n",
    "            'label': label,\n",
    "            'distances': distance_data[label]\n",
    "        }\n",
    "\n",
    "# for each question_id, find the best prompt_id for each role, then calculate MSE\n",
    "question_results = []\n",
    "\n",
    "for question_id, prompt_data in question_data.items():\n",
    "    role_best_distances = {}\n",
    "    role_best_prompts = {}\n",
    "    \n",
    "    # for each role, find the prompt_id that gives minimum distance for this question_id\n",
    "    for role in target_roles:\n",
    "        best_distance = np.inf\n",
    "        best_prompt_id = None\n",
    "        \n",
    "        for prompt_id, data in prompt_data.items():\n",
    "            if role in data['distances']:\n",
    "                distance = data['distances'][role]\n",
    "                if distance < best_distance:\n",
    "                    best_distance = distance\n",
    "                    best_prompt_id = prompt_id\n",
    "        \n",
    "        if best_prompt_id is not None:\n",
    "            role_best_distances[role] = best_distance\n",
    "            role_best_prompts[role] = best_prompt_id\n",
    "    \n",
    "    # calculate MSE across the best distances for each role\n",
    "    if role_best_distances:\n",
    "        distances = list(role_best_distances.values())\n",
    "        mse = np.mean(np.array(distances) ** 2)\n",
    "        \n",
    "        row_data = {\n",
    "            'question_id': question_id,\n",
    "            'mse_distance': mse\n",
    "        }\n",
    "        \n",
    "        # add individual role distances and their best prompt_ids\n",
    "        for role in target_roles:\n",
    "            if role in role_best_distances:\n",
    "                row_data[f\"{role}_distance\"] = role_best_distances[role]\n",
    "                row_data[f\"{role}_best_prompt\"] = role_best_prompts[role]\n",
    "            else:\n",
    "                row_data[f\"{role}_distance\"] = np.nan\n",
    "                row_data[f\"{role}_best_prompt\"] = np.nan\n",
    "        \n",
    "        question_results.append(row_data)\n",
    "\n",
    "# create dataframe and sort by MSE\n",
    "question_df = pd.DataFrame(question_results)\n",
    "question_df = question_df.sort_values(by='mse_distance')\n",
    "\n",
    "question_df.to_csv(f\"./results/qwen-3-32b/prefills/roles_pc1_questions.csv\", index=False)\n",
    "\n",
    "print(\"\\nQuestions sorted by MSE distance (best prompt per role per question):\")\n",
    "print(question_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "n9fswfabwy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best question_id: 132\n",
      "Role: validator, Prompt: 2, PC1: -37.572572, Label: pos_p2_q132\n",
      "Role: podcaster, Prompt: 0, PC1: -10.806745, Label: pos_p0_q132\n",
      "Role: visionary, Prompt: 2, PC1: 15.177850, Label: pos_p2_q132\n",
      "Role: narcissist, Prompt: 4, PC1: 40.991084, Label: pos_p4_q132\n",
      "Role: whale, Prompt: 2, PC1: 68.348354, Label: pos_p2_q132\n",
      "Role: leviathan, Prompt: 4, PC1: 92.232296, Label: pos_p4_q132\n",
      "\n",
      "Saved 6 entries to ./results/qwen-3-32b/prefills/role_pc1_prefills_q132.jsonl\n",
      "\n",
      "Best question ID 132 has MSE: 1.590810\n"
     ]
    }
   ],
   "source": [
    "# get the best question_id and create jsonl output\n",
    "import json\n",
    "\n",
    "# get the best question_id (lowest MSE)\n",
    "best_question_id = int(question_df.iloc[0]['question_id'])\n",
    "print(f\"Best question_id: {best_question_id}\")\n",
    "\n",
    "# collect data for the best question across all roles and their best prompts\n",
    "jsonl_data = []\n",
    "\n",
    "for i, role in enumerate(target_roles):\n",
    "    best_prompt_col = f\"{role}_best_prompt\"\n",
    "    best_prompt_id = question_df.iloc[0][best_prompt_col]\n",
    "    \n",
    "    if pd.notna(best_prompt_id):\n",
    "        best_prompt_id = int(best_prompt_id)\n",
    "        label = f\"pos_p{best_prompt_id}_q{best_question_id}\"\n",
    "        \n",
    "        # find the projection for this specific label\n",
    "        acts = torch.load(f\"/workspace/qwen-3-32b/roles_240/response_activations/{role}.pt\", weights_only=False)\n",
    "        pc1_projection = pc_projection(acts[label][layer, :].reshape(1, -1), pca_results, 1).squeeze()\n",
    "\n",
    "        # get the question text\n",
    "        target_obj = None\n",
    "        with open(f\"/workspace/qwen-3-32b/roles_240/responses/{role}.jsonl\", \"r\") as f:\n",
    "            for line in f:\n",
    "                obj = json.loads(line)\n",
    "                if obj['prompt_index'] == best_prompt_id and obj['question_index'] == best_question_id:\n",
    "                    target_obj = obj\n",
    "\n",
    "        # create the jsonl entry\n",
    "        entry = {\n",
    "            'id': i,\n",
    "            'role': role,\n",
    "            'pc1': float(pc1_projection),\n",
    "            'question_index': best_question_id,\n",
    "            'prompt_index': best_prompt_id,\n",
    "            'label': label,\n",
    "            'conversation': target_obj['conversation']\n",
    "        }\n",
    "        \n",
    "        jsonl_data.append(entry)\n",
    "        print(f\"Role: {role}, Prompt: {best_prompt_id}, PC1: {pc1_projection:.6f}, Label: {label}\")\n",
    "\n",
    "# save to jsonl file\n",
    "output_file = f\"./results/qwen-3-32b/prefills/role_pc1_prefills_q{best_question_id}.jsonl\"\n",
    "with open(output_file, 'w') as f:\n",
    "    for entry in jsonl_data:\n",
    "        f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "print(f\"\\nSaved {len(jsonl_data)} entries to {output_file}\")\n",
    "print(f\"\\nBest question ID {best_question_id} has MSE: {question_df.iloc[0]['mse_distance']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b03cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {}\n",
    "for i in range(6):\n",
    "    pc_df = sorted_by_pc(i)\n",
    "    columns[f\"pc{i+1}\"] = pc_df[\"label\"].values  # Use .values to get numpy array\n",
    "    print(f\"PC{i+1} first 40: {pc_df['label'].head(40).tolist()}\")  # Debug print\n",
    "    print(f\"PC{i+1} last 40: {pc_df['label'].tail(40).tolist()}\")  # Debug print\n",
    "\n",
    "df = pd.DataFrame(columns)\n",
    "df.to_csv(\"/root/git/persona-subspace/dynamics/results/qwen-3-32b/traits_sorted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387c10f",
   "metadata": {},
   "source": [
    "## Plot trajectory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
