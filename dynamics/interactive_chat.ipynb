{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 19:59:48 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.probing_utils import *\n",
    "from utils.inference_utils import *\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_MODEL_NAME = \"google/gemma-2-27b-it\"\n",
    "MODEL_READABLE = \"Gemma 2 27B\"\n",
    "OUTPUT_DIR = \"./results/gemma-2-27b/interactive\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.inference_utils:Using specified tensor_parallel_size: 2\n",
      "INFO:utils.inference_utils:Loading vLLM model: google/gemma-2-27b-it with 2 GPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 20:00:04 [utils.py:328] non-default args: {'trust_remote_code': True, 'max_model_len': 8192, 'distributed_executor_backend': 'mp', 'tensor_parallel_size': 2, 'disable_log_stats': True, 'model': 'google/gemma-2-27b-it'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-22 20:00:04 [__init__.py:742] Resolved architecture: Gemma2ForCausalLM\n",
      "INFO 09-22 20:00:04 [__init__.py:1815] Using max model len 8192\n",
      "INFO 09-22 20:00:05 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:06 [core.py:654] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:06 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='google/gemma-2-27b-it', speculative_config=None, tokenizer='google/gemma-2-27b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=google/gemma-2-27b-it, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m WARNING 09-22 20:00:06 [multiproc_worker_utils.py:273] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:06 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 16777216, 10, 'psm_e0790fb1'), local_subscribe_addr='ipc:///tmp/94200d3f-a276-4a0b-9807-73ccf1e9fa00', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:08 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_66cd253d'), local_subscribe_addr='ipc:///tmp/c3408ddd-979e-4f4f-a362-0e1b236e5b3a', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:09 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_5d22bc9b'), local_subscribe_addr='ipc:///tmp/e3256ec1-ce5d-4ae8-8b2d-19680380fcf9', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:10 [__init__.py:1433] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:10 [pynccl.py:70] vLLM is using nccl==2.27.3\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:10 [__init__.py:1433] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:10 [pynccl.py:70] vLLM is using nccl==2.27.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W922 20:00:10.598361180 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "[W922 20:00:10.608146213 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:10 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:10 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:10 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_ce61f050'), local_subscribe_addr='ipc:///tmp/64f5470b-637a-49c4-9766-be62fd0a9b3d', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:10 [parallel_state.py:1165] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:10 [parallel_state.py:1165] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m WARNING 09-22 20:00:10 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m WARNING 09-22 20:00:10 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:10 [gpu_model_runner.py:2338] Starting to load model google/gemma-2-27b-it...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:10 [gpu_model_runner.py:2338] Starting to load model google/gemma-2-27b-it...\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:11 [gpu_model_runner.py:2370] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:11 [gpu_model_runner.py:2370] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:11 [cuda.py:362] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:11 [cuda.py:362] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:11 [weight_utils.py:348] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5dcd89cd9445f68d5c81b78201cd9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/12 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:11 [weight_utils.py:348] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:19 [default_loader.py:268] Loading weights took 7.67 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:19 [default_loader.py:268] Loading weights took 8.17 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:20 [gpu_model_runner.py:2392] Model loading took 25.3611 GiB and 8.328140 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:20 [gpu_model_runner.py:2392] Model loading took 25.3611 GiB and 8.684465 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:25 [backends.py:539] Using cache directory: /root/.cache/vllm/torch_compile_cache/5ffd2c46f4/rank_1_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:25 [backends.py:550] Dynamo bytecode transform time: 4.58 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:25 [backends.py:539] Using cache directory: /root/.cache/vllm/torch_compile_cache/5ffd2c46f4/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:25 [backends.py:550] Dynamo bytecode transform time: 4.63 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:27 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 1.723 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:27 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 1.730 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:32 [monitor.py:34] torch.compile takes 4.58 s in total\n",
      "INFO 09-22 20:00:32 [monitor.py:34] torch.compile takes 4.63 s in total\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:33 [gpu_worker.py:298] Available KV cache memory: 35.07 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:33 [gpu_worker.py:298] Available KV cache memory: 35.07 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:33 [kv_cache_utils.py:1028] GPU KV cache size: 199,840 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:33 [kv_cache_utils.py:1032] Maximum concurrency for 8,192 tokens per request: 24.37x\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:33 [kv_cache_utils.py:1028] GPU KV cache size: 199,840 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:33 [kv_cache_utils.py:1032] Maximum concurrency for 8,192 tokens per request: 24.37x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 67/67 [00:02<00:00, 24.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:37 [custom_all_reduce.py:203] Registering 6231 cuda graph addresses\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m INFO 09-22 20:00:37 [custom_all_reduce.py:203] Registering 6231 cuda graph addresses\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:37 [gpu_model_runner.py:3118] Graph capturing finished in 4 secs, took 0.88 GiB\n",
      "INFO 09-22 20:00:37 [gpu_model_runner.py:3118] Graph capturing finished in 4 secs, took 0.88 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m INFO 09-22 20:00:37 [gpu_worker.py:391] Free memory on device (78.6/79.2 GiB) on startup. Desired GPU memory utilization is (0.9, 71.28 GiB). Actual usage is 25.36 GiB for weight, 9.47 GiB for peak activation, 1.39 GiB for non-torch memory, and 0.88 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=36558916198` to fit into requested memory, or `--kv-cache-memory=44416427008` to fully utilize gpu memory. Current kv cache memory in use is 37655726694 bytes.\n",
      "INFO 09-22 20:00:37 [gpu_worker.py:391] Free memory on device (78.6/79.2 GiB) on startup. Desired GPU memory utilization is (0.9, 71.28 GiB). Actual usage is 25.36 GiB for weight, 9.47 GiB for peak activation, 1.39 GiB for non-torch memory, and 0.88 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=36558916198` to fit into requested memory, or `--kv-cache-memory=44416427008` to fully utilize gpu memory. Current kv cache memory in use is 37655726694 bytes.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m INFO 09-22 20:00:37 [core.py:218] init engine (profile, create kv cache, warmup model) took 17.31 seconds\n",
      "INFO 09-22 20:00:39 [llm.py:295] Supported_tasks: ['generate']\n",
      "INFO 09-22 20:00:39 [__init__.py:36] No IOProcessor plugins requested by the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.inference_utils:Successfully loaded vLLM model: google/gemma-2-27b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Gemma 2 27B loaded successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654] WorkerProc hit an exception.\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654] WorkerProc hit an exception.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654] Traceback (most recent call last):\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654] Traceback (most recent call last):\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 649, in worker_busy_loop\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     output = func(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 649, in worker_busy_loop\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return func(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     output = func(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py\", line 436, in execute_model\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     output = self.model_runner.execute_model(scheduler_output,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                                              intermediate_tensors)\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return func(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py\", line 436, in execute_model\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return func(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     output = self.model_runner.execute_model(scheduler_output,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 2064, in execute_model\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                                              intermediate_tensors)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     model_output = self.model(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         input_ids=input_ids,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<3 lines>...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return func(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         **model_kwargs,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 2064, in execute_model\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     model_output = self.model(\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         input_ids=input_ids,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<3 lines>...\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         **model_kwargs,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/model_executor/models/gemma2.py\", line 405, in forward\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     hidden_states = self.model(input_ids, positions, intermediate_tensors,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                                inputs_embeds)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py\", line 312, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     model_output = self.forward(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/model_executor/models/gemma2.py\", line 278, in forward\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/model_executor/models/gemma2.py\", line 405, in forward\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     def forward(\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     hidden_states = self.model(input_ids, positions, intermediate_tensors,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py\", line 375, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                                inputs_embeds)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super().__call__(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py\", line 312, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     model_output = self.forward(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/model_executor/models/gemma2.py\", line 278, in forward\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     def forward(\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py\", line 375, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super().__call__(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return fn(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 848, in call_wrapped\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._wrapped_call(self, *args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 424, in __call__\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     raise e\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 411, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return fn(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 848, in call_wrapped\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._wrapped_call(self, *args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 424, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     raise e\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 411, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"<eval_with_key>.94\", line 385, in forward\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     submod_1 = self.submod_1(getitem, s72, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = submod_1 = None\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 848, in call_wrapped\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._wrapped_call(self, *args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 424, in __call__\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     raise e\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 411, in __call__\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"<eval_with_key>.94\", line 385, in forward\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     submod_1 = self.submod_1(getitem, s72, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = submod_1 = None\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 848, in call_wrapped\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._wrapped_call(self, *args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 424, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     raise e\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 411, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"<eval_with_key>.2\", line 5, in forward\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     unified_attention_with_output = torch.ops.vllm.unified_attention_with_output(query_2, key_2, value, output_2, 'model.layers.0.self_attn.attn');  query_2 = key_2 = value = output_2 = unified_attention_with_output = None\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1243, in __call__\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._op(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/attention/layer.py\", line 521, in unified_attention_with_output\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     self.impl.forward(self,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"<eval_with_key>.2\", line 5, in forward\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ~~~~~~~~~~~~~~~~~^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     unified_attention_with_output = torch.ops.vllm.unified_attention_with_output(query_2, key_2, value, output_2, 'model.layers.0.self_attn.attn');  query_2 = key_2 = value = output_2 = unified_attention_with_output = None\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       query,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1243, in __call__\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._op(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<5 lines>...\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       output_scale=output_scale,\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/attention/layer.py\", line 521, in unified_attention_with_output\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     self.impl.forward(self,\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       output_block_scale=output_block_scale)\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ~~~~~~~~~~~~~~~~~^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       query,\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/attention/backends/flash_attn.py\", line 531, in forward\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     flash_attn_varlen_func(\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<5 lines>...\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ~~~~~~~~~~~~~~~~~~~~~~^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       output_scale=output_scale,\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         q=query[:num_actual_tokens],\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       output_block_scale=output_block_scale)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<19 lines>...\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         s_aux=self.sinks,\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/attention/backends/flash_attn.py\", line 531, in forward\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     flash_attn_varlen_func(\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ~~~~~~~~~~~~~~~~~~~~~~^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         q=query[:num_actual_tokens],\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/vllm_flash_attn/flash_attn_interface.py\", line 258, in flash_attn_varlen_func\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     out, softmax_lse, _, _ = torch.ops._vllm_fa3_C.fwd(\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<19 lines>...\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                              ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         s_aux=self.sinks,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         q, k, v,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<22 lines>...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         s_aux             # s_aux\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/vllm_flash_attn/flash_attn_interface.py\", line 258, in flash_attn_varlen_func\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     out, softmax_lse, _, _ = torch.ops._vllm_fa3_C.fwd(\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                              ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1243, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         q, k, v,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._op(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<22 lines>...\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654] RuntimeError: This flash attention build does not support tanh softcapping.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654] Traceback (most recent call last):\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         s_aux             # s_aux\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 649, in worker_busy_loop\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     output = func(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return func(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1243, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py\", line 436, in execute_model\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._op(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     output = self.model_runner.execute_model(scheduler_output,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                                              intermediate_tensors)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654] RuntimeError: This flash attention build does not support tanh softcapping.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654] Traceback (most recent call last):\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return func(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 649, in worker_busy_loop\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 2064, in execute_model\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     output = func(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     model_output = self.model(\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         input_ids=input_ids,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return func(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<3 lines>...\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py\", line 436, in execute_model\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         **model_kwargs,\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     output = self.model_runner.execute_model(scheduler_output,\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                                              intermediate_tensors)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return func(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 2064, in execute_model\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     model_output = self.model(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         input_ids=input_ids,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/model_executor/models/gemma2.py\", line 405, in forward\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<3 lines>...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     hidden_states = self.model(input_ids, positions, intermediate_tensors,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         **model_kwargs,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                                inputs_embeds)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py\", line 312, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     model_output = self.forward(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/model_executor/models/gemma2.py\", line 278, in forward\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     def forward(\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py\", line 375, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/model_executor/models/gemma2.py\", line 405, in forward\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super().__call__(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     hidden_states = self.model(input_ids, positions, intermediate_tensors,\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                                inputs_embeds)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py\", line 312, in __call__\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     model_output = self.forward(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/model_executor/models/gemma2.py\", line 278, in forward\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     def forward(\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py\", line 375, in __call__\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return fn(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super().__call__(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 848, in call_wrapped\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._wrapped_call(self, *args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 424, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     raise e\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 411, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return fn(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 848, in call_wrapped\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._wrapped_call(self, *args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 424, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     raise e\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 411, in __call__\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"<eval_with_key>.94\", line 385, in forward\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     submod_1 = self.submod_1(getitem, s72, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = submod_1 = None\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 848, in call_wrapped\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._wrapped_call(self, *args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 424, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     raise e\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 411, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"<eval_with_key>.94\", line 385, in forward\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     submod_1 = self.submod_1(getitem, s72, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = submod_1 = None\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 848, in call_wrapped\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._wrapped_call(self, *args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 424, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     raise e\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/fx/graph_module.py\", line 411, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"<eval_with_key>.2\", line 5, in forward\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     unified_attention_with_output = torch.ops.vllm.unified_attention_with_output(query_2, key_2, value, output_2, 'model.layers.0.self_attn.attn');  query_2 = key_2 = value = output_2 = unified_attention_with_output = None\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1243, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._op(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._call_impl(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/attention/layer.py\", line 521, in unified_attention_with_output\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     self.impl.forward(self,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return forward_call(*args, **kwargs)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ~~~~~~~~~~~~~~~~~^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"<eval_with_key>.2\", line 5, in forward\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       query,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     unified_attention_with_output = torch.ops.vllm.unified_attention_with_output(query_2, key_2, value, output_2, 'model.layers.0.self_attn.attn');  query_2 = key_2 = value = output_2 = unified_attention_with_output = None\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1243, in __call__\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<5 lines>...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       output_scale=output_scale,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._op(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       output_block_scale=output_block_scale)\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/attention/layer.py\", line 521, in unified_attention_with_output\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     self.impl.forward(self,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/attention/backends/flash_attn.py\", line 531, in forward\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ~~~~~~~~~~~~~~~~~^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     flash_attn_varlen_func(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       query,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ~~~~~~~~~~~~~~~~~~~~~~^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         q=query[:num_actual_tokens],\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<5 lines>...\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<19 lines>...\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       output_scale=output_scale,\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         s_aux=self.sinks,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       output_block_scale=output_block_scale)\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/vllm_flash_attn/flash_attn_interface.py\", line 258, in flash_attn_varlen_func\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/attention/backends/flash_attn.py\", line 531, in forward\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     out, softmax_lse, _, _ = torch.ops._vllm_fa3_C.fwd(\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     flash_attn_varlen_func(\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                              ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ~~~~~~~~~~~~~~~~~~~~~~^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         q, k, v,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         q=query[:num_actual_tokens],\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<22 lines>...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<19 lines>...\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         s_aux             # s_aux\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         s_aux=self.sinks,\n",
      "ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1243, in __call__\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/vllm_flash_attn/flash_attn_interface.py\", line 258, in flash_attn_varlen_func\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._op(*args, **kwargs)\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     out, softmax_lse, _, _ = torch.ops._vllm_fa3_C.fwd(\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]                              ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654] RuntimeError: This flash attention build does not support tanh softcapping.\n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         q, k, v,\n",
      "\u001b[1;36m(Worker_TP1 pid=2226208)\u001b[0;0m \u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654] \n",
      "\u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ...<22 lines>...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         s_aux             # s_aux\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     )\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     ^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1243, in __call__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]     return self._op(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654]            ~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654] RuntimeError: This flash attention build does not support tanh softcapping.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m \u001b[1;36m(Worker_TP0 pid=2226206)\u001b[0;0m ERROR 09-22 20:04:55 [multiproc_executor.py:654] \n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [dump_input.py:69] Dumping input data for V1 LLM engine (v0.10.2) with config: model='google/gemma-2-27b-it', speculative_config=None, tokenizer='google/gemma-2-27b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=google/gemma-2-27b-it, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}, \n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [dump_input.py:76] Dumping scheduler output for model execution: SchedulerOutput(scheduled_new_reqs=[NewRequestData(req_id=0,prompt_token_ids_len=11,mm_kwargs=[],mm_hashes=[],mm_positions=[],sampling_params=SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.7, top_p=0.9, top_k=0, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=3000, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None),block_ids=([1], [2]),num_computed_tokens=0,lora_request=None)], scheduled_cached_reqs=CachedRequestData(req_ids=[], resumed_from_preemption=[], new_token_ids=[], new_block_ids=[], num_computed_tokens=[]), num_scheduled_tokens={0: 11}, total_num_scheduled_tokens=11, scheduled_spec_decode_tokens={}, scheduled_encoder_inputs={}, num_common_prefix_blocks=[1, 0], finished_req_ids=[], free_encoder_mm_hashes=[], structured_output_request_ids={}, grammar_bitmask=null, kv_connector_metadata=null)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720] EngineCore encountered a fatal error.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720] Traceback (most recent call last):\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 711, in run_engine_core\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     engine_core.run_busy_loop()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     ~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 738, in run_busy_loop\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     self._process_engine_step()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     ~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 764, in _process_engine_step\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     outputs, model_executed = self.step_fn()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]                               ~~~~~~~~~~~~^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 292, in step\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     model_output = self.execute_model_with_error_logging(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         self.model_executor.execute_model,  # type: ignore\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         scheduler_output)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 278, in execute_model_with_error_logging\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     raise err\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 269, in execute_model_with_error_logging\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     return model_fn(scheduler_output)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 176, in execute_model\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     (output, ) = self.collective_rpc(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]                  ~~~~~~~~~~~~~~~~~~~^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         \"execute_model\",\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         ^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     ...<2 lines>...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         non_block=non_block,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         timeout=envs.VLLM_EXECUTE_MODEL_TIMEOUT_SECONDS)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 259, in collective_rpc\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     result = get_response(w, dequeue_timeout,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]                           self.shutdown_event)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 243, in get_response\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]     raise RuntimeError(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         f\"Worker failed with error '{result}', please check the\"\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720]         \" stack trace above for the root cause\")\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m ERROR 09-22 20:04:55 [core.py:720] RuntimeError: Worker failed with error 'This flash attention build does not support tanh softcapping.', please check the stack trace above for the root cause\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m Process EngineCore_DP0:\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m Traceback (most recent call last):\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/.local/share/uv/python/cpython-3.13.5-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     self.run()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     ~~~~~~~~^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/.local/share/uv/python/cpython-3.13.5-linux-x86_64-gnu/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     self._target(*self._args, **self._kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 722, in run_engine_core\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     raise e\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 711, in run_engine_core\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     engine_core.run_busy_loop()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     ~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 738, in run_busy_loop\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     self._process_engine_step()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     ~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 764, in _process_engine_step\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     outputs, model_executed = self.step_fn()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m                               ~~~~~~~~~~~~^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 292, in step\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     model_output = self.execute_model_with_error_logging(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         self.model_executor.execute_model,  # type: ignore\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         scheduler_output)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 278, in execute_model_with_error_logging\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     raise err\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py\", line 269, in execute_model_with_error_logging\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     return model_fn(scheduler_output)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 176, in execute_model\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     (output, ) = self.collective_rpc(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m                  ~~~~~~~~~~~~~~~~~~~^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         \"execute_model\",\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         ^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     ...<2 lines>...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         non_block=non_block,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         timeout=envs.VLLM_EXECUTE_MODEL_TIMEOUT_SECONDS)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 259, in collective_rpc\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     result = get_response(w, dequeue_timeout,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m                           self.shutdown_event)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m   File \"/root/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/executor/multiproc_executor.py\", line 243, in get_response\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m     raise RuntimeError(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         f\"Worker failed with error '{result}', please check the\"\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m         \" stack trace above for the root cause\")\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2226181)\u001b[0;0m RuntimeError: Worker failed with error 'This flash attention build does not support tanh softcapping.', please check the stack trace above for the root cause\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load_vllm_model(CHAT_MODEL_NAME, max_model_len=8192, tensor_parallel_size=2)\n",
    "print(f\"✅ Model {MODEL_READABLE} loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_interactive(message, show_history=False, return_response=False):\n",
    "    \"\"\"Interactive chat function\"\"\"\n",
    "    global conversation_history\n",
    "    response, conversation_history = continue_conversation(\n",
    "        model, \n",
    "        conversation_history, \n",
    "        message,\n",
    "        max_tokens=3000,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(f\"👤 You: {message}\")\n",
    "    print(f\"🤖 {MODEL_READABLE}: {response}\")\n",
    "    \n",
    "    if show_history:\n",
    "        print(f\"\\n📜 Conversation so far ({len(conversation_history)} turns):\")\n",
    "        for i, turn in enumerate(conversation_history):\n",
    "            role_emoji = \"👤\" if turn[\"role\"] == \"user\" else \"🤖\" \n",
    "            print(f\"  {i+1}. {role_emoji} {turn['content'][:100]}...\")\n",
    "    \n",
    "    # Only return if explicitly requested\n",
    "    if return_response:\n",
    "        return response\n",
    "\n",
    "# Advanced conversation analysis tools\n",
    "\n",
    "def save_conversation(filename):\n",
    "    \"\"\"Save the current conversation to a file\"\"\"\n",
    "    if not conversation_history:\n",
    "        print(\"No conversation to save!\")\n",
    "        return\n",
    "    \n",
    "    conversation_data = {\n",
    "        \"model\": CHAT_MODEL_NAME,\n",
    "        \"turns\": len(conversation_history),\n",
    "        \"conversation\": conversation_history\n",
    "    }\n",
    "    \n",
    "    with open(f\"{OUTPUT_DIR}/{filename}\", 'w') as f:\n",
    "        json.dump(conversation_data, f, indent=2)\n",
    "    \n",
    "    print(f\"💾 Conversation saved to: {filename}\")\n",
    "    return filename\n",
    "\n",
    "def reset_conversation():\n",
    "    \"\"\"Reset the conversation history\"\"\"\n",
    "    global conversation_history\n",
    "    conversation_history = []\n",
    "    print(\"🔄 Conversation history cleared!\")\n",
    "\n",
    "\n",
    "def delete_last_turn():\n",
    "    \"\"\"Delete the last turn from the conversation history\"\"\"\n",
    "    global conversation_history\n",
    "    if conversation_history:\n",
    "        conversation_history = conversation_history[:-2]\n",
    "        print(\"🔄 Last turn deleted!\")\n",
    "    else:\n",
    "        print(\"No conversation to delete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec77355b53af47c38824ba298408820d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab0c589ea5b45bd8de78b117727ebae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:utils.inference_utils:Error in chat_conversation: EngineCore encountered an issue. See stack trace (above) for the root cause.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Conversation inference failed: EngineCore encountered an issue. See stack trace (above) for the root cause.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEngineDeadError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/dynamics/../utils/inference_utils.py:441\u001b[39m, in \u001b[36mchat_conversation\u001b[39m\u001b[34m(model_wrapper, messages, temperature, max_tokens, top_p, enable_thinking, **kwargs)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m outputs = \u001b[43mmodel_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outputs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outputs[\u001b[32m0\u001b[39m].outputs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/entrypoints/llm.py:396\u001b[39m, in \u001b[36mLLM.generate\u001b[39m\u001b[34m(self, prompts, sampling_params, use_tqdm, lora_request, priority)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_and_add_requests(\n\u001b[32m    389\u001b[39m     prompts=prompts,\n\u001b[32m    390\u001b[39m     params=sampling_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m    393\u001b[39m     priority=priority,\n\u001b[32m    394\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine_class.validate_outputs(outputs, RequestOutput)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/entrypoints/llm.py:1550\u001b[39m, in \u001b[36mLLM._run_engine\u001b[39m\u001b[34m(self, use_tqdm)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_engine.has_unfinished_requests():\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     step_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/llm_engine.py:248\u001b[39m, in \u001b[36mLLMEngine.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;66;03m# 1) Get EngineCoreOutput from the EngineCore.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# 2) Process EngineCoreOutputs.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.13/site-packages/vllm/v1/engine/core_client.py:670\u001b[39m, in \u001b[36mSyncMPClient.get_output\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m670\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_exception(outputs) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs.wave_complete \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mEngineDeadError\u001b[39m: EngineCore encountered an issue. See stack trace (above) for the root cause.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchat_interactive\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhello\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mchat_interactive\u001b[39m\u001b[34m(message, show_history, return_response)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Interactive chat function\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m conversation_history\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response, conversation_history = \u001b[43mcontinue_conversation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconversation_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m👤 You: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🤖 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_READABLE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/dynamics/../utils/inference_utils.py:486\u001b[39m, in \u001b[36mcontinue_conversation\u001b[39m\u001b[34m(model_wrapper, conversation_history, new_message, temperature, max_tokens, top_p, enable_thinking, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m updated_history.append({\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: new_message})\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# Get response\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m response = \u001b[43mchat_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_thinking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# Add assistant response to history\u001b[39;00m\n\u001b[32m    489\u001b[39m updated_history.append({\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: response})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/dynamics/../utils/inference_utils.py:452\u001b[39m, in \u001b[36mchat_conversation\u001b[39m\u001b[34m(model_wrapper, messages, temperature, max_tokens, top_p, enable_thinking, **kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    451\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError in chat_conversation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversation inference failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Conversation inference failed: EngineCore encountered an issue. See stack trace (above) for the root cause."
     ]
    }
   ],
   "source": [
    "chat_interactive(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_conversation(\"spiral_jailbreak.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_last_turn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.inference_utils:Closed vLLM model Qwen/Qwen3-32B\n"
     ]
    }
   ],
   "source": [
    "model.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
