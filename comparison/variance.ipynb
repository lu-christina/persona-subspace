{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28531137",
   "metadata": {},
   "source": [
    "# Variance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f3bcdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:08.842015Z",
     "iopub.status.busy": "2025-08-06T00:18:08.841387Z",
     "iopub.status.idle": "2025-08-06T00:18:09.171163Z",
     "shell.execute_reply": "2025-08-06T00:18:09.170519Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.pca_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julz1owfwk",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "o7pmyp071r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Change these parameters for different models/datasets\n",
    "model_name = \"gemma-2-27b\"\n",
    "base_dir = f\"/workspace/{model_name}\"\n",
    "type = \"roles_240\"\n",
    "dir = f\"{base_dir}/{type}\"\n",
    "\n",
    "layer = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76552389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pca_results = torch.load(f\"{dir}/pca/layer{layer}_pos23.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bec2d8",
   "metadata": {},
   "source": [
    "## Variance across and within roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5319f",
   "metadata": {},
   "source": [
    "### raw activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16d954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([275, 4608])\n",
      "torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "vectors = torch.stack(pca_results['vectors']['pos_3'])[:, layer, :].float()\n",
    "print(vectors.shape)\n",
    "\n",
    "# compute variance across roles (rows) along hidden_dims\n",
    "raw_across_var = torch.var(vectors, dim=0)\n",
    "print(raw_across_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197362bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 275 scores\n"
     ]
    }
   ],
   "source": [
    "# load in scores\n",
    "scores = {}\n",
    "for file in os.listdir(f\"{dir}/extract_scores\"):\n",
    "    if file.endswith('.json'):\n",
    "        scores[file.replace('.json', '')] = json.load(open(f\"{dir}/extract_scores/{file}\"))\n",
    "\n",
    "print(f\"Loaded {len(scores)} scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c900d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file.endswith(\u001b[33m'\u001b[39m\u001b[33m.pt\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# dict we should iterate over (1200 each)\u001b[39;00m\n\u001b[32m      6\u001b[39m     role_activations = []\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     obj = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/response_activations/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m scores[file.replace(\u001b[33m'\u001b[39m\u001b[33m.pt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)][key] == \u001b[32m3\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/serialization.py:1521\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1528\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1529\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/serialization.py:2119\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2117\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2118\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2119\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2120\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2122\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/_weights_only_unpickler.py:532\u001b[39m, in \u001b[36mUnpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    525\u001b[39m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    526\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) > \u001b[32m0\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.serialization._maybe_decode_ascii(pid[\u001b[32m0\u001b[39m]) != \u001b[33m\"\u001b[39m\u001b[33mstorage\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m     ):\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[32m    530\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[32m0\u001b[39m], LONG_BINGET[\u001b[32m0\u001b[39m]]:\n\u001b[32m    534\u001b[39m     idx = (read(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[32m0\u001b[39m] == BINGET[\u001b[32m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, read(\u001b[32m4\u001b[39m)))[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/serialization.py:2083\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2081\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2082\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2083\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2084\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2085\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2087\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.13/site-packages/torch/serialization.py:2036\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   2029\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_offset != zip_file.get_record_offset(name):\n\u001b[32m   2030\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2031\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThis is a debug assert that was run as the `TORCH_SERIALIZATION_DEBUG` environment \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2032\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvariable was set: Incorrect offset for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstorage_offset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m expected \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2033\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_file.get_record_offset(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2034\u001b[39m             )\n\u001b[32m   2035\u001b[39m     storage = (\n\u001b[32m-> \u001b[39m\u001b[32m2036\u001b[39m         \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2037\u001b[39m         ._typed_storage()\n\u001b[32m   2038\u001b[39m         ._untyped_storage\n\u001b[32m   2039\u001b[39m     )\n\u001b[32m   2040\u001b[39m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[32m   2041\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# load in raw activations\n",
    "# activations = {}\n",
    "# for file in os.listdir(f\"{dir}/response_activations\"):\n",
    "#     if file.endswith('.pt') and 'default' not in file:\n",
    "#         # dict we should iterate over (1200 each)\n",
    "#         role_activations = []\n",
    "#         obj = torch.load(f\"{dir}/response_activations/{file}\")\n",
    "#         for key in obj:\n",
    "#             if scores[file.replace('.pt', '')][key] == 3:\n",
    "#                 role_activations.append(obj[key])\n",
    "#         activations[file.replace('.pt', '')] = torch.stack(role_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b24db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([332400, 46, 4608])\n"
     ]
    }
   ],
   "source": [
    "all_acts = []\n",
    "for file in os.listdir(f\"{dir}/response_activations\"):\n",
    "    if file.endswith('.pt'):\n",
    "        # dict we should iterate over (1200 each)\n",
    "        obj = torch.load(f\"{dir}/response_activations/{file}\")\n",
    "        for key in obj:\n",
    "            all_acts.append(obj[key])\n",
    "stacked_acts = torch.stack(all_acts)\n",
    "print(stacked_acts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "912a4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute variance within roles\n",
    "raw_within_var = []\n",
    "for file in activations:\n",
    "    raw_within_var.append(torch.var(activations[file][:, layer, :], dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var)} roles, shape is {raw_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ea71a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_raw_within_var = torch.stack(raw_within_var).mean(dim=0)\n",
    "print(avg_raw_within_var.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cf860e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total variance ratio\n",
    "raw_ratio = raw_across_var.sum() / avg_raw_within_var.sum()\n",
    "print(f\"ratio of raw_across_var / avg_raw_within_var is {raw_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0512101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_across_var_normalized = torch.var(F.normalize(vectors, p=2, dim=1), dim=0)\n",
    "print(raw_across_var_normalized.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63901cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_within_var_normalized = []\n",
    "for file in activations:\n",
    "    raw_within_var_normalized.append(torch.var(F.normalize(activations[file][:, layer, :], p=2, dim=1), dim=0))\n",
    "\n",
    "print(f\"for {len(raw_within_var_normalized)} roles, shape is {raw_within_var_normalized[0].shape}\")\n",
    "avg_raw_within_var_normalized = torch.stack(raw_within_var_normalized).mean(dim=0)\n",
    "print(avg_raw_within_var_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5cc8b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratio_normalized = raw_across_var_normalized.mean() / avg_raw_within_var_normalized.mean()\n",
    "print(f\"ratio of raw_across_var_normalized / avg_raw_within_var_normalized is {raw_ratio_normalized}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f2faa",
   "metadata": {},
   "source": [
    "### in PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get transformed role vectors\n",
    "pca_across_var = np.var(pca_results['pca_transformed'][:275], axis=0)\n",
    "print(pca_across_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec04e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(activations['absurdist'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8e550e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_within_var = []\n",
    "pc1_within_var = []\n",
    "for role in activations:\n",
    "    role_scaled = pca_results['scaler'].transform(activations[role][:, layer, :].float().numpy())\n",
    "    role_pca = pca_results['pca'].transform(role_scaled)\n",
    "    pca_within_var.append(np.var(role_pca, axis=0))\n",
    "    pc1_within_var.append(np.var(role_pca[:, 0]))\n",
    "\n",
    "print(f\"for {len(pca_within_var)} roles, shape is {pca_within_var[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d4565fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pca_within_var = np.array(pca_within_var).mean(axis=0)\n",
    "print(mean_pca_within_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6776cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ratio = pca_across_var.mean() / mean_pca_within_var.mean()\n",
    "print(f\"ratio of pca_across_var / mean_pca_within_var is {pca_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffd5cc",
   "metadata": {},
   "source": [
    "### pc1 variance only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77c857e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_across_var = np.var(pca_results['pca_transformed'][:275, 0])\n",
    "print(pc1_across_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfc2e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pc1_within_var = np.array(pc1_within_var).mean()\n",
    "print(mean_pc1_within_var)\n",
    "\n",
    "pc1_ratio = pc1_across_var / mean_pc1_within_var\n",
    "print(f\"ratio of pc1_across_var / mean_pc1_within_var is {pc1_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4pcuy4pbb",
   "metadata": {},
   "source": [
    "### All PCs variance ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "hq8lbky0oc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ratio for all PCs using existing variables\n",
    "all_pc_ratios = pca_across_var / mean_pca_within_var\n",
    "print(f\"Computed ratios for {len(all_pc_ratios)} PCs\")\n",
    "print(f\"PC1 ratio: {all_pc_ratios[0]:.4f}\")\n",
    "print(f\"Mean ratio (all PCs): {all_pc_ratios.mean():.4f}\")\n",
    "print(f\"Mean ratio (PC2-10): {all_pc_ratios[1:10].mean():.4f}\")\n",
    "print(f\"Max ratio: {all_pc_ratios.max():.4f} (PC{all_pc_ratios.argmax()+1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "hmedn82ye69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create line plot of PC ratios\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line trace for all PC ratios\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(1, len(all_pc_ratios) + 1),\n",
    "    y=all_pc_ratios,\n",
    "    mode='lines',\n",
    "    name='PC Ratio',\n",
    "    line=dict(color='steelblue', width=2)\n",
    "))\n",
    "\n",
    "\n",
    "# Add horizontal reference line at ratio=1\n",
    "fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"gray\", \n",
    "              annotation_text=\"ratio=1\", annotation_position=\"right\")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Variance Ratio (Across-Role / Within-Role) for Role PCs\",\n",
    "        'subtitle': {\n",
    "            'text': f\"{model_name.replace('-', ' ').title()}, Layer {layer}\",\n",
    "        }\n",
    "    },\n",
    "    xaxis_title=\"Principal Component\",\n",
    "    yaxis_title=\"Variance Ratio\",\n",
    "    width=800,\n",
    "    height=500,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(range=[0.5, 10], tickvals=np.arange(1, 11))\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(f\"/root/git/plots/{model_name}/roles/variance_ratios.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5eca2",
   "metadata": {},
   "source": [
    "## Conditional variance of role vectors based on distance from Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df91e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_layer = stacked_acts[:, layer, :]\n",
    "\n",
    "# project into PC space\n",
    "scaled_acts_layer = pca_results['scaler'].transform(acts_layer.float().numpy())\n",
    "acts_layer_pca = pca_results['pca'].transform(scaled_acts_layer)\n",
    "pc1 = acts_layer_pca[:, 0]\n",
    "\n",
    "role_vectors = torch.stack(pca_results['vectors']['pos_2'] + pca_results['vectors']['pos_3'])[:, layer, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dw7pl9twyv",
   "metadata": {},
   "source": [
    "### Conditional variance in raw activation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    threshold = 25\n",
    "    assistant_mask = pc1 > threshold\n",
    "    roleplay_mask = pc1 <= threshold\n",
    "else:\n",
    "    threshold = -25\n",
    "    assistant_mask = pc1 < threshold\n",
    "    roleplay_mask = pc1 >= threshold\n",
    "\n",
    "var_assistant_role_acts = torch.var(acts_layer[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_role_acts = torch.var(acts_layer[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_role_acts = var_assistant_role_acts / var_roleplay_role_acts\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ROLE ACTIVATION SPACE: Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like role activations (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like): {var_assistant_role_acts:.6f}\")\n",
    "print(f\"Mean variance (Roleplay): {var_roleplay_role_acts:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vm23njwgwk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project out PC1 from raw activations\n",
    "# Get PC1 direction from PCA\n",
    "pc1_direction = torch.from_numpy(pca_results['pca'].components_[0]).float()\n",
    "\n",
    "# Project role_vectors onto PC1 and subtract\n",
    "# Formula: projection = (v · u) * u, where u is the unit vector (PC1 direction)\n",
    "pc1_loadings = (acts_layer.float() @ pc1_direction).unsqueeze(1)  # Shape: [448, 1]\n",
    "pc1_projections = pc1_loadings * pc1_direction.unsqueeze(0)  # Shape: [448, 4608]\n",
    "role_vectors_pc1_removed = acts_layer - pc1_projections\n",
    "\n",
    "# Compute variance with PC1 projected out\n",
    "var_assistant_raw_no_pc1 = torch.var(role_vectors_pc1_removed[assistant_mask], dim=0).mean().item()\n",
    "var_roleplay_raw_no_pc1 = torch.var(role_vectors_pc1_removed[roleplay_mask], dim=0).mean().item()\n",
    "\n",
    "var_ratio_raw_no_pc1 = var_assistant_raw_no_pc1 / var_roleplay_raw_no_pc1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE (PC1 projected out): Two-Group Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PC1 threshold: {threshold}\")\n",
    "print(f\"Assistant-like roles (PC1 < {threshold}): {assistant_mask.sum()} samples\")\n",
    "print(f\"Roleplay roles (PC1 >= {threshold}): {roleplay_mask.sum()} samples\")\n",
    "print(f\"\\nMean variance (Assistant-like, PC1 removed): {var_assistant_raw_no_pc1:.6f}\")\n",
    "print(f\"Mean variance (Roleplay, PC1 removed): {var_roleplay_raw_no_pc1:.6f}\")\n",
    "print(f\"Variance ratio (Assistant/Roleplay): {var_ratio_raw_no_pc1:.4f} ({var_ratio_raw_no_pc1*100:.2f}%)\")\n",
    "print(f\"\\nThis is analogous to the PC2-10 analysis in PC space.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zv1prpa1y3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quintile analysis\n",
    "n_quintiles = 5\n",
    "quintile_edges = np.quantile(pc1, np.linspace(0, 1, n_quintiles + 1))\n",
    "quintile_variances = []\n",
    "quintile_variances_no_pc1 = []\n",
    "quintile_sizes = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Quintile Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(n_quintiles):\n",
    "    if i == 0:\n",
    "        mask = (pc1 >= quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    else:\n",
    "        mask = (pc1 > quintile_edges[i]) & (pc1 <= quintile_edges[i + 1])\n",
    "    \n",
    "    quintile_var = torch.var(acts_layer[mask], dim=0).mean().item()\n",
    "    quintile_var_no_pc1 = torch.var(role_vectors_pc1_removed[mask], dim=0).mean().item()\n",
    "    quintile_variances.append(quintile_var)\n",
    "    quintile_variances_no_pc1.append(quintile_var_no_pc1)\n",
    "    quintile_sizes.append(mask.sum())\n",
    "    \n",
    "    print(f\"\\nQuintile {i+1}: PC1 ∈ [{quintile_edges[i]:.2f}, {quintile_edges[i+1]:.2f}]\")\n",
    "    print(f\"  Sample size: {mask.sum()}\")\n",
    "    print(f\"  Mean variance (full): {quintile_var:.6f}\")\n",
    "    print(f\"  Mean variance (PC1 removed): {quintile_var_no_pc1:.6f}\")\n",
    "\n",
    "# Calculate ratios between first and last quintile\n",
    "if model_name == \"gemma-2-27b\":\n",
    "    quintile_ratio = quintile_variances[0] / quintile_variances[-1]\n",
    "    quintile_ratio_no_pc1 = quintile_variances_no_pc1[0] / quintile_variances_no_pc1[-1]\n",
    "else:\n",
    "    quintile_ratio = quintile_variances[-1] / quintile_variances[0]\n",
    "    quintile_ratio_no_pc1 = quintile_variances_no_pc1[-1] / quintile_variances_no_pc1[0]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(f\"Variance ratio (Last/First quintile, full): {quintile_ratio:.2f}x\")\n",
    "print(f\"Variance ratio (Last/First quintile, PC1 removed): {quintile_ratio_no_pc1:.2f}x\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7kwaevse0w",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance from center correlation\n",
    "# Compute mean of raw activations\n",
    "role_vectors_mean = acts_layer.mean(dim=0)\n",
    "role_vectors_pc1_removed_mean = role_vectors_pc1_removed.mean(dim=0)\n",
    "\n",
    "# Compute L2 distance from mean for each role\n",
    "distances_raw = torch.norm(acts_layer.float() - role_vectors_mean, p=2, dim=1).numpy()\n",
    "distances_raw_no_pc1 = torch.norm(role_vectors_pc1_removed - role_vectors_pc1_removed_mean, p=2, dim=1).numpy()\n",
    "\n",
    "# Calculate correlation with PC1\n",
    "correlation_raw, p_value_raw = pearsonr(pc1, distances_raw)\n",
    "correlation_raw_no_pc1, p_value_raw_no_pc1 = pearsonr(pc1, distances_raw_no_pc1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RAW ACTIVATION SPACE: Distance from Center Correlation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Correlation between PC1 and L2 distance from mean (full):\")\n",
    "print(f\"  r = {correlation_raw:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw:.3e}\")\n",
    "if p_value_raw < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "\n",
    "print(f\"\\nCorrelation between PC1 and L2 distance from mean (PC1 removed):\")\n",
    "print(f\"  r = {correlation_raw_no_pc1:.4f}\")\n",
    "print(f\"  p-value = {p_value_raw_no_pc1:.3e}\")\n",
    "if p_value_raw_no_pc1 < 0.001:\n",
    "    print(f\"  Highly significant (p < 0.001)\")\n",
    "elif p_value_raw_no_pc1 < 0.05:\n",
    "    print(f\"  Significant (p < 0.05)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lsye2ajp11",
   "metadata": {},
   "source": [
    "### Per-PC analysis: Correlation between each PC and distance in remaining PC space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0tedpgpspjp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the top 10 PCs, calculate:\n",
    "# 1. The correlation between that PC and distance from center in all OTHER PCs\n",
    "# 2. This tells us if the pattern we see with PC1 generalizes to other PCs\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "n_pcs_to_analyze = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Correlation between each PC and distance in remaining PC space\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "correlations = []\n",
    "p_values = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_analyze):\n",
    "    # Get the PC values\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get all other PCs (excluding current PC)\n",
    "    other_pcs = np.delete(pca_transformed, pc_idx, axis=1)\n",
    "    \n",
    "    # Calculate distance from center in the remaining PC space\n",
    "    other_pcs_mean = other_pcs.mean(axis=0)\n",
    "    distances = np.linalg.norm(other_pcs - other_pcs_mean, axis=1)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr, p_val = pearsonr(pc_values, distances)\n",
    "    correlations.append(corr)\n",
    "    p_values.append(p_val)\n",
    "    \n",
    "    # Print results\n",
    "    sig_marker = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n",
    "    print(f\"PC{pc_idx+1:2d}: r = {corr:7.4f}, p = {p_val:.3e} {sig_marker}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPC1 correlation: {correlations[0]:.4f}\")\n",
    "print(f\"Mean correlation (PC2-10): {np.mean(correlations[1:]):.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4w4stk4a567",
   "metadata": {},
   "source": [
    "### Conditional variance in PC2-10 based on position along each PC\n",
    "\n",
    "This analysis shows whether the pattern of \"extreme positions → high variance in other PCs\" is unique to PC1 or generalizes to other PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "x42qo16zp6k",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each PC, split roles into two groups (high/low) and compute variance in PC2-10 (excluding that PC)\n",
    "# This tests if extreme positions on PC_i lead to high variance in other PCs\n",
    "\n",
    "n_pcs_to_test = 10\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Conditional Variance in PC2-10 based on position along each PC\")\n",
    "print(\"=\" * 80)\n",
    "print(\"For each PC, we split roles by median and compute variance in PC2-10 (excluding that PC)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "variance_ratios = []\n",
    "\n",
    "for pc_idx in range(n_pcs_to_test):\n",
    "    # Split by median on this PC\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    median_val = np.median(pc_values)\n",
    "    high_mask = pc_values > median_val\n",
    "    low_mask = pc_values <= median_val\n",
    "    \n",
    "    # Get PC2-10, excluding current PC if it's in that range\n",
    "    if pc_idx == 0:\n",
    "        # For PC1, we want variance in PC2-10\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    elif 1 <= pc_idx < 10:\n",
    "        # For PC2-9, exclude that PC from PC2-10\n",
    "        pc_indices = [i for i in range(1, 10) if i != pc_idx]\n",
    "        other_pcs = pca_transformed[:, pc_indices]\n",
    "    else:\n",
    "        # For PC10, use PC2-9\n",
    "        other_pcs = pca_transformed[:, 1:10]\n",
    "    \n",
    "    # Compute variance for each group\n",
    "    var_high = np.var(other_pcs[high_mask], axis=0).mean()\n",
    "    var_low = np.var(other_pcs[low_mask], axis=0).mean()\n",
    "    \n",
    "    ratio = max(var_high, var_low) / min(var_high, var_low)\n",
    "    variance_ratios.append(ratio)\n",
    "    \n",
    "    print(f\"PC{pc_idx+1:2d}: High={high_mask.sum():3d} samples, Low={low_mask.sum():3d} samples\")\n",
    "    print(f\"      Var(high) = {var_high:8.3f}, Var(low) = {var_low:8.3f}, Ratio = {ratio:.3f}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  PC1 variance ratio: {variance_ratios[0]:.3f}\")\n",
    "print(f\"  Mean variance ratio for PC2-10: {np.mean(variance_ratios[1:]):.3f}\")\n",
    "print(f\"  Max variance ratio (excluding PC1): {np.max(variance_ratios[1:]):.3f} (PC{np.argmax(variance_ratios[1:])+2})\")\n",
    "print(\"\\n  → Shows whether PC1 is unique in having high-variance 'other dimensions' for extreme positions\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "psa4fpzrfl8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create role labels from pca_results\n",
    "def get_role_labels_from_pca(pca_results):\n",
    "    labels = []\n",
    "    if 'pos_2' in pca_results['roles'].keys():\n",
    "        pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "        labels.extend(pos_2_roles)\n",
    "    if 'pos_3' in pca_results['roles'].keys():\n",
    "        pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "        labels.extend(pos_3_roles)\n",
    "    return labels\n",
    "\n",
    "role_labels = get_role_labels_from_pca(pca_results)\n",
    "print(f\"Total roles: {len(role_labels)}\")\n",
    "print(f\"pca_transformed shape: {pca_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d0ogly4i9nk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top/bottom roles for each PC\n",
    "n_pcs_to_show = 10  # Show first 5 PCs\n",
    "n_roles_to_show = 5  # Show top/bottom 5 roles\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Top and Bottom Roles for Each PC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pc_idx in range(n_pcs_to_show):\n",
    "    pc_values = pca_transformed[:, pc_idx]\n",
    "    \n",
    "    # Get indices of top and bottom roles\n",
    "    top_indices = np.argsort(pc_values)[-n_roles_to_show:][::-1]\n",
    "    bottom_indices = np.argsort(pc_values)[:n_roles_to_show]\n",
    "    \n",
    "    print(f\"\\nPC{pc_idx+1}:\")\n",
    "    print(f\"  Top {n_roles_to_show} (highest loadings):\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "    \n",
    "    print(f\"  Bottom {n_roles_to_show} (lowest loadings):\")\n",
    "    for i, idx in enumerate(bottom_indices):\n",
    "        print(f\"    {i+1}. {role_labels[idx]:30s} (PC{pc_idx+1} = {pc_values[idx]:7.2f})\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0108b",
   "metadata": {},
   "source": [
    "## Default loading along each PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20166672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get default activation and project\n",
    "default_vectors = torch.load(f\"{base_dir}/roles_240/default_vectors.pt\")\n",
    "assistant_layer_activation = default_vectors['activations']['default_1'][layer, :].float().reshape(1, -1)\n",
    "\n",
    "asst_scaled = pca_results['scaler'].transform(assistant_layer_activation.numpy())\n",
    "asst_projected = pca_results['pca'].transform(asst_scaled)\n",
    "print(f\"Assistant projection shape: {asst_projected.shape}\")\n",
    "\n",
    "# Compare each PC loading with the min, max loading of that PC across all roles\n",
    "n_pcs = 10  # or however many you want to analyze\n",
    "pca_transformed = pca_results['pca_transformed']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Assistant (default) position relative to role distribution on each PC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pc_idx in range(n_pcs):\n",
    "    # Get assistant's loading on this PC\n",
    "    asst_loading = asst_projected[0, pc_idx]\n",
    "    \n",
    "    # Get all role loadings on this PC\n",
    "    all_loadings = pca_transformed[:, pc_idx]\n",
    "    min_loading = all_loadings.min()\n",
    "    max_loading = all_loadings.max()\n",
    "    \n",
    "    # Calculate relative position (0 = at min, 1 = at max)\n",
    "    if max_loading != min_loading:\n",
    "        relative_position = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    else:\n",
    "        relative_position = 0.5\n",
    "    \n",
    "    # Distance to nearest boundary (normalized)\n",
    "    dist_to_min = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    dist_to_max = (max_loading - asst_loading) / (max_loading - min_loading)\n",
    "    min_boundary_dist = min(dist_to_min, dist_to_max)\n",
    "    \n",
    "    print(f\"\\nPC{pc_idx+1}:\")\n",
    "    print(f\"  Range: [{min_loading:8.2f}, {max_loading:8.2f}]\")\n",
    "    print(f\"  Assistant: {asst_loading:8.2f}\")\n",
    "    print(f\"  Relative position: {relative_position:.3f} (0=min, 1=max)\")\n",
    "    print(f\"  Min boundary distance: {min_boundary_dist:.3f}\")\n",
    "    \n",
    "    # Interpret position\n",
    "    if relative_position < 0.25:\n",
    "        position_desc = \"near minimum\"\n",
    "    elif relative_position < 0.45:\n",
    "        position_desc = \"below center\"\n",
    "    elif relative_position < 0.55:\n",
    "        position_desc = \"centered\"\n",
    "    elif relative_position < 0.75:\n",
    "        position_desc = \"above center\"\n",
    "    else:\n",
    "        position_desc = \"near maximum\"\n",
    "    print(f\"  Position: {position_desc}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669f17e",
   "metadata": {},
   "source": [
    "## Overall activation variance captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd47d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['activations', 'target_layer'])\n",
      "dict_keys(['projected', 'explained_variance_ratio', 'pca_n_components', 'pca_explained_variance_from_fit', 'target_layer', 'pca_config_path'])\n",
      "dict_keys(['projected', 'explained_variance_ratio', 'pca_n_components', 'pca_explained_variance_from_fit', 'target_layer', 'pca_config_path'])\n"
     ]
    }
   ],
   "source": [
    "# load in the mean_activations.pt and the role/trait projections...\n",
    "\n",
    "act_dir = f\"/workspace/{model_name}/dataset_activations/lmsys_10000\"\n",
    "\n",
    "chat_raw = torch.load(f\"{act_dir}/mean_activations.pt\")\n",
    "chat_roles = torch.load(f\"{act_dir}/roles_projections.pt\", weights_only=False)\n",
    "chat_traits = torch.load(f\"{act_dir}/traits_projections.pt\", weights_only=False)\n",
    "\n",
    "print(chat_raw.keys())\n",
    "print(chat_roles.keys())\n",
    "print(chat_traits.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d1a2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw activations shape: torch.Size([18950, 5120])\n",
      "\n",
      "Total variance in raw activations: 8603.54\n",
      "\n",
      "Role subspace:\n",
      "  Variance captured: 2888.04\n",
      "  Variance explained: 0.3357 (33.57%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait subspace:\n",
      "  Variance captured: 2316.71\n",
      "  Variance explained: 0.2693 (26.93%)\n",
      "\n",
      "============================================================\n",
      "Summary: Variance Explained by Subspaces\n",
      "============================================================\n",
      "Role subspace:  33.57%\n",
      "Trait subspace: 26.93%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Get the raw activations\n",
    "raw_activations = chat_raw['activations'][:, layer, :].float()\n",
    "print(f\"Raw activations shape: {raw_activations.shape}\")\n",
    "\n",
    "# Calculate total variance in raw activations\n",
    "total_var = torch.var(raw_activations, dim=0).sum().item()\n",
    "print(f\"\\nTotal variance in raw activations: {total_var:.2f}\")\n",
    "\n",
    "# For roles: reconstruct from PCA space back to raw space\n",
    "roles_projected = chat_roles['projected']  # Shape: [18950, 463]\n",
    "# Inverse transform: unstandardize and inverse PCA\n",
    "roles_reconstructed = pca_results['pca'].inverse_transform(roles_projected)  # This gives standardized features\n",
    "roles_reconstructed = pca_results['scaler'].inverse_transform(roles_reconstructed)  # Unstandardize\n",
    "roles_reconstructed = torch.from_numpy(roles_reconstructed).float()\n",
    "\n",
    "# Calculate variance in reconstructed activations\n",
    "roles_var = torch.var(roles_reconstructed, dim=0).sum().item()\n",
    "roles_variance_explained = roles_var / total_var\n",
    "\n",
    "print(f\"\\nRole subspace:\")\n",
    "print(f\"  Variance captured: {roles_var:.2f}\")\n",
    "print(f\"  Variance explained: {roles_variance_explained:.4f} ({roles_variance_explained*100:.2f}%)\")\n",
    "\n",
    "# For traits: load trait PCA results and do the same\n",
    "trait_pca_results = torch.load(f\"{base_dir}/traits_240/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n",
    "traits_projected = chat_traits['projected']  # Shape: [18950, 240]\n",
    "\n",
    "traits_reconstructed = trait_pca_results['pca'].inverse_transform(traits_projected)\n",
    "traits_reconstructed = trait_pca_results['scaler'].inverse_transform(traits_reconstructed)\n",
    "traits_reconstructed = torch.from_numpy(traits_reconstructed).float()\n",
    "\n",
    "# Calculate variance in reconstructed activations\n",
    "traits_var = torch.var(traits_reconstructed, dim=0).sum().item()\n",
    "traits_variance_explained = traits_var / total_var\n",
    "\n",
    "print(f\"\\nTrait subspace:\")\n",
    "print(f\"  Variance captured: {traits_var:.2f}\")\n",
    "print(f\"  Variance explained: {traits_variance_explained:.4f} ({traits_variance_explained*100:.2f}%)\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary: Variance Explained by Subspaces\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Role subspace:  {roles_variance_explained*100:.2f}%\")\n",
    "print(f\"Trait subspace: {traits_variance_explained*100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3pk6ipumh22",
   "metadata": {},
   "source": [
    "## Individual model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0pec8iqx20qe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving variance analysis results to ./results/\n",
      "Timestamp: 2025-10-22T08:35:30.050112\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Configuration for saving\n",
    "outdir = \"./results\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# Get current timestamp\n",
    "timestamp = datetime.now().isoformat()\n",
    "\n",
    "print(f\"Saving variance analysis results to {outdir}/\")\n",
    "print(f\"Timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3mzx2uw37it",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the per-model variance analysis JSON structure\n",
    "\n",
    "# Build quintile data\n",
    "quintiles_data = []\n",
    "for i in range(len(quintile_edges) - 1):\n",
    "    quintiles_data.append({\n",
    "        \"quintile\": i + 1,\n",
    "        \"pc1_range\": [float(quintile_edges[i]), float(quintile_edges[i + 1])],\n",
    "        \"n_samples\": int(quintile_sizes[i]),\n",
    "        \"variance_full\": float(quintile_variances[i]),\n",
    "        \"variance_pc1_removed\": float(quintile_variances_no_pc1[i])\n",
    "    })\n",
    "\n",
    "# Build PC distance correlations\n",
    "pc_distance_corrs = []\n",
    "for i in range(len(correlations)):\n",
    "    pc_distance_corrs.append({\n",
    "        \"pc\": i + 1,\n",
    "        \"r\": float(correlations[i]),\n",
    "        \"p_value\": float(p_values[i]),\n",
    "        \"significant\": bool(p_values[i] < 0.05)\n",
    "    })\n",
    "\n",
    "# Build conditional variance by PC\n",
    "cond_var_by_pc = []\n",
    "for i in range(len(variance_ratios)):\n",
    "    cond_var_by_pc.append({\n",
    "        \"pc\": i + 1,\n",
    "        \"ratio\": float(variance_ratios[i])\n",
    "    })\n",
    "\n",
    "# Build default PC loading data\n",
    "pc_positions = []\n",
    "centered_pcs = []\n",
    "extreme_pcs = []\n",
    "\n",
    "for pc_idx in range(n_pcs):\n",
    "    asst_loading = asst_projected[0, pc_idx]\n",
    "    all_loadings = pca_transformed[:, pc_idx]\n",
    "    min_loading = all_loadings.min()\n",
    "    max_loading = all_loadings.max()\n",
    "\n",
    "    if max_loading != min_loading:\n",
    "        relative_position = (asst_loading - min_loading) / (max_loading - min_loading)\n",
    "    else:\n",
    "        relative_position = 0.5\n",
    "\n",
    "    dist_to_min = relative_position\n",
    "    dist_to_max = 1.0 - relative_position\n",
    "    min_boundary_dist = min(dist_to_min, dist_to_max)\n",
    "\n",
    "    if relative_position < 0.25:\n",
    "        position_desc = \"near minimum\"\n",
    "        extreme_pcs.append(pc_idx + 1)\n",
    "    elif relative_position < 0.45:\n",
    "        position_desc = \"below center\"\n",
    "    elif relative_position < 0.55:\n",
    "        position_desc = \"centered\"\n",
    "        centered_pcs.append(pc_idx + 1)\n",
    "    elif relative_position < 0.75:\n",
    "        position_desc = \"above center\"\n",
    "    else:\n",
    "        position_desc = \"near maximum\"\n",
    "        extreme_pcs.append(pc_idx + 1)\n",
    "\n",
    "    pc_positions.append({\n",
    "        \"pc\": pc_idx + 1,\n",
    "        \"assistant_loading\": float(asst_loading),\n",
    "        \"role_range_min\": float(min_loading),\n",
    "        \"role_range_max\": float(max_loading),\n",
    "        \"relative_position\": float(relative_position),\n",
    "        \"min_boundary_distance\": float(min_boundary_dist),\n",
    "        \"position_category\": position_desc\n",
    "    })\n",
    "\n",
    "# Build the complete JSON structure\n",
    "model_variance_data = {\n",
    "    \"model_name\": model_name,\n",
    "    \"layer\": layer,\n",
    "    \"hidden_dim\": vectors.shape[1],\n",
    "    \"n_roles\": len(activations),\n",
    "    \"n_role_samples\": role_vectors.shape[0],\n",
    "    \"timestamp\": timestamp,\n",
    "    \"analysis_version\": \"1.0\",\n",
    "\n",
    "    \"across_within_role_var\": {\n",
    "        \"raw_activations\": {\n",
    "            \"across_var_mean\": float(raw_across_var.mean().item()),\n",
    "            \"within_var_mean\": float(avg_raw_within_var.mean().item()),\n",
    "            \"ratio\": float(raw_ratio)\n",
    "        },\n",
    "        \"raw_activations_normalized\": {\n",
    "            \"across_var_mean\": float(raw_across_var_normalized.mean().item()),\n",
    "            \"within_var_mean\": float(avg_raw_within_var_normalized.mean().item()),\n",
    "            \"ratio\": float(raw_ratio_normalized)\n",
    "        },\n",
    "        \"pca_space_all_components\": {\n",
    "            \"across_var_mean\": float(pca_across_var.mean()),\n",
    "            \"within_var_mean\": float(mean_pca_within_var.mean()),\n",
    "            \"ratio\": float(pca_ratio),\n",
    "            \"n_components\": int(len(pca_across_var))\n",
    "        },\n",
    "        \"pc1_only\": {\n",
    "            \"across_var\": float(pc1_across_var),\n",
    "            \"within_var_mean\": float(mean_pc1_within_var),\n",
    "            \"ratio\": float(pc1_ratio)\n",
    "        },\n",
    "        \"per_pc_ratios\": {\n",
    "            \"description\": \"Ratio of across-role variance to mean within-role variance for each PC\",\n",
    "            \"top_10_pcs\": [\n",
    "                {\n",
    "                    \"pc\": i + 1,\n",
    "                    \"across_var\": float(pca_across_var[i]),\n",
    "                    \"within_var_mean\": float(mean_pca_within_var[i]),\n",
    "                    \"ratio\": float(all_pc_ratios[i])\n",
    "                }\n",
    "                for i in range(10)\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"conditional_var_roles\": {\n",
    "        \"description\": \"Conditional variance analysis for role vectors based on PC1 position\",\n",
    "        \"n_samples\": int(acts_layer.shape[0]),\n",
    "        \"threshold_analysis\": {\n",
    "            \"pc1_threshold\": threshold,\n",
    "            \"assistant_like\": {\n",
    "                \"mask\": f\"pc1 < {threshold}\",\n",
    "                \"n_samples\": int(assistant_mask.sum()),\n",
    "                \"variance_raw\": float(var_assistant_role_acts),\n",
    "                \"variance_raw_pc1_removed\": float(var_assistant_raw_no_pc1)\n",
    "            },\n",
    "            \"roleplay\": {\n",
    "                \"mask\": f\"pc1 >= {threshold}\",\n",
    "                \"n_samples\": int(roleplay_mask.sum()),\n",
    "                \"variance_raw\": float(var_roleplay_role_acts),\n",
    "                \"variance_raw_pc1_removed\": float(var_roleplay_raw_no_pc1)\n",
    "            },\n",
    "            \"variance_ratio_raw\": float(var_ratio_role_acts),\n",
    "            \"variance_ratio_raw_pc1_removed\": float(var_ratio_raw_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"quintile_analysis\": {\n",
    "            \"n_quintiles\": 5,\n",
    "            \"quintiles\": quintiles_data,\n",
    "            \"variance_ratio_first_to_last_full\": float(quintile_ratio),\n",
    "            \"variance_ratio_first_to_last_pc1_removed\": float(quintile_ratio_no_pc1)\n",
    "        },\n",
    "\n",
    "        \"distance_correlation\": {\n",
    "            \"full_space\": {\n",
    "                \"correlation\": float(correlation_raw),\n",
    "                \"p_value\": float(p_value_raw),\n",
    "                \"significant\": bool(p_value_raw < 0.05)\n",
    "            },\n",
    "            \"pc1_removed\": {\n",
    "                \"correlation\": float(correlation_raw_no_pc1),\n",
    "                \"p_value\": float(p_value_raw_no_pc1),\n",
    "                \"significant\": bool(p_value_raw_no_pc1 < 0.05)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"high_var_pc_correlation\": {\n",
    "        \"pc_distance_correlations\": {\n",
    "            \"description\": \"Correlation between each PC and distance in remaining PC space\",\n",
    "            \"n_pcs_analyzed\": 10,\n",
    "            \"correlations\": pc_distance_corrs,\n",
    "            \"pc1_correlation\": float(correlations[0]),\n",
    "            \"mean_correlation_pc2_to_10\": float(np.mean(correlations[1:]))\n",
    "        },\n",
    "\n",
    "        \"conditional_variance_by_pc\": {\n",
    "            \"description\": \"Variance in PC2-10 conditioned on high/low position along each PC\",\n",
    "            \"n_pcs_analyzed\": 10,\n",
    "            \"variance_ratios\": cond_var_by_pc,\n",
    "            \"pc1_variance_ratio\": float(variance_ratios[0]),\n",
    "            \"mean_variance_ratio_pc2_to_10\": float(np.mean(variance_ratios[1:])),\n",
    "            \"max_variance_ratio_excluding_pc1\": float(np.max(variance_ratios[1:])),\n",
    "            \"max_variance_ratio_pc\": int(np.argmax(variance_ratios[1:]) + 2)\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"default_pc_loading\": {\n",
    "        \"description\": \"Position of default assistant activation relative to role distribution on each PC\",\n",
    "        \"n_pcs_analyzed\": n_pcs,\n",
    "        \"pc_positions\": pc_positions,\n",
    "        \"summary\": {\n",
    "            \"pc1_position\": pc_positions[0][\"position_category\"],\n",
    "            \"pc1_relative_position\": pc_positions[0][\"relative_position\"],\n",
    "            \"centered_pcs\": centered_pcs,\n",
    "            \"extreme_pcs\": extreme_pcs\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"overall_activation_var\": {\n",
    "        \"description\": \"Variance in chat dataset activations explained by role and trait subspaces\",\n",
    "        \"dataset\": {\n",
    "            \"name\": \"lmsys_10000\",\n",
    "            \"n_samples\": int(raw_activations.shape[0]),\n",
    "            \"source_path\": act_dir\n",
    "        },\n",
    "        \"total_variance\": float(total_var),\n",
    "        \"role_subspace\": {\n",
    "            \"n_components\": int(roles_projected.shape[1]),\n",
    "            \"variance_captured\": float(roles_var),\n",
    "            \"variance_explained_ratio\": float(roles_variance_explained),\n",
    "            \"variance_explained_percent\": float(roles_variance_explained * 100)\n",
    "        },\n",
    "        \"trait_subspace\": {\n",
    "            \"n_components\": int(traits_projected.shape[1]),\n",
    "            \"variance_captured\": float(traits_var),\n",
    "            \"variance_explained_ratio\": float(traits_variance_explained),\n",
    "            \"variance_explained_percent\": float(traits_variance_explained * 100)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Built per-model variance analysis data structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zi9ycc6ru9n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing data from: ./results/qwen-3-32b/variance_layer32.json\n",
      "Saved: ./results/qwen-3-32b/variance_layer32.json\n",
      "✓ Updated variance analysis for qwen-3-32b\n"
     ]
    }
   ],
   "source": [
    "# Save per-model variance analysis to JSON file\n",
    "filename = f\"{outdir}/{model_name.lower()}/variance_layer{layer}.json\"\n",
    "\n",
    "# Load existing JSON if it exists, otherwise start with empty dict\n",
    "try:\n",
    "    with open(filename, 'r') as f:\n",
    "        existing_data = json.load(f)\n",
    "    print(f\"Loaded existing data from: {filename}\")\n",
    "except FileNotFoundError:\n",
    "    existing_data = {}\n",
    "    print(f\"No existing file found, creating new data structure\")\n",
    "\n",
    "# Update only the fields we want to save\n",
    "existing_data.update({\n",
    "    # Update these specific sections (uncomment the ones you want to update)\n",
    "    # \"across_within_role_var\": model_variance_data[\"across_within_role_var\"],  # Includes per_pc_ratios\n",
    "    \"conditional_var_roles\": model_variance_data[\"conditional_var_roles\"],\n",
    "    # \"high_var_pc_correlation\": model_variance_data[\"high_var_pc_correlation\"],\n",
    "    # \"default_pc_loading\": model_variance_data[\"default_pc_loading\"],\n",
    "    # \"overall_activation_var\": model_variance_data[\"overall_activation_var\"],\n",
    "})\n",
    "\n",
    "# Save back to file\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(existing_data, f, indent=2)\n",
    "\n",
    "print(f\"Saved: {filename}\")\n",
    "print(f\"✓ Updated variance analysis for {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4a7bf",
   "metadata": {},
   "source": [
    "## Correlations between role loadings onto PCs across the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65e2c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "# layers = [22, 32, 40]\n",
    "\n",
    "# trait_results = {}\n",
    "# labels = {}\n",
    "# for model, layer in zip(models, layers):\n",
    "#     model_dir = f\"/workspace/{model}/traits_240\"\n",
    "#     trait_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos-neg50.pt\", weights_only=False)\n",
    "#     print(trait_results[model]['pca_transformed'].shape)\n",
    "#     labels[model] = trait_results[model]['traits']['pos_neg_50']\n",
    "#     print(labels[model][:20])\n",
    "\n",
    "# # need to get intersection of traits across models (gemma missing vindictive)\n",
    "# pca_transformed = []\n",
    "# for model in models:\n",
    "#     if model != 'gemma-2-27b':\n",
    "#         # splice out index 5 but keep the ones before and after\n",
    "#         pca_transformed.append(np.concatenate((trait_results[model]['pca_transformed'][:5], trait_results[model]['pca_transformed'][6:])))\n",
    "#     else:\n",
    "#         pca_transformed.append(trait_results[model]['pca_transformed'])\n",
    "\n",
    "# for m in pca_transformed:\n",
    "#     print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c83e2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transpose each matrix so rows are PCs and columns are traits\n",
    "# pca_transposed = [m.T for m in pca_transformed]\n",
    "\n",
    "# # Extract top 10 PCs from each model\n",
    "# n_pcs = 6\n",
    "# top_pcs = [m[:n_pcs] for m in pca_transposed]\n",
    "\n",
    "# print(f\"Transposed shapes (n_pcs, n_traits):\")\n",
    "# for model, pc_matrix in zip(models, top_pcs):\n",
    "#     print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# # Compute pairwise correlations for each PC\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# pc_correlations = []\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     # Extract the trait loading vector for this PC from each model\n",
    "#     gemma_pc = top_pcs[0][pc_idx]\n",
    "#     qwen_pc = top_pcs[1][pc_idx]\n",
    "#     llama_pc = top_pcs[2][pc_idx]\n",
    "    \n",
    "#     # Compute pairwise correlations\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     # Create 3x3 correlation matrix\n",
    "#     corr_matrix = np.array([\n",
    "#         [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "#         [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "#         [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "#     ])\n",
    "    \n",
    "#     pc_correlations.append(corr_matrix)\n",
    "\n",
    "#     print(f\"\\nPC{pc_idx + 1}:\")\n",
    "#     print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "#     print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "#     print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e6f52212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try for top 10 role PCs\n",
    "# models = ['gemma-2-27b', 'qwen-3-32b', 'llama-3.3-70b']\n",
    "# layers = [22, 32, 40]\n",
    "\n",
    "# def get_role_labels(pca_results):\n",
    "#     labels = []\n",
    "#     if 'pos_2' in pca_results['roles'].keys():\n",
    "#         pos_2_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_2']]\n",
    "#         pos_2_roles = [f\"{role} (Somewhat RP)\" for role in pos_2_roles]\n",
    "#         labels.extend(pos_2_roles)\n",
    "#     if 'pos_3' in pca_results['roles'].keys():\n",
    "#         pos_3_roles = [role.replace('_', ' ').title() for role in pca_results['roles']['pos_3']]\n",
    "#         pos_3_roles = [f\"{role} (Fully RP)\" for role in pos_3_roles]\n",
    "#         labels.extend(pos_3_roles)\n",
    "#     return labels\n",
    "\n",
    "\n",
    "# role_results = {}\n",
    "# labels = {}\n",
    "# for model, layer in zip(models, layers):\n",
    "#     model_dir = f\"/workspace/{model}/roles_240\"\n",
    "#     role_results[model] = torch.load(f\"{model_dir}/pca/layer{layer}_pos23.pt\", weights_only=False)\n",
    "#     print(role_results[model]['pca_transformed'].shape)\n",
    "#     labels[model] = get_role_labels(role_results[model])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5faf8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find intersection of roles across all 3 models\n",
    "# set_gemma = set(labels['gemma-2-27b'])\n",
    "# set_qwen = set(labels['qwen-3-32b'])\n",
    "# set_llama = set(labels['llama-3.3-70b'])\n",
    "\n",
    "# common_roles = set_gemma & set_qwen & set_llama\n",
    "# print(f\"Common roles across all models: {len(common_roles)}\")\n",
    "\n",
    "# # Get indices of common roles for each model (preserving order from labels)\n",
    "# indices = {}\n",
    "# for model in models:\n",
    "#     model_indices = []\n",
    "#     for i, role in enumerate(labels[model]):\n",
    "#         if role in common_roles:\n",
    "#             model_indices.append(i)\n",
    "#     indices[model] = model_indices\n",
    "#     print(f\"{model}: {len(model_indices)} common roles\")\n",
    "\n",
    "# # Extract aligned PCA transformed matrices (only common roles, in consistent order)\n",
    "# # Need to ensure the same role ordering across models\n",
    "# common_roles_list = sorted(list(common_roles))  # Consistent ordering\n",
    "\n",
    "# pca_transformed_roles = []\n",
    "# for model in models:\n",
    "#     # Map from common_roles_list order to model's indices\n",
    "#     model_indices_ordered = []\n",
    "#     for role in common_roles_list:\n",
    "#         idx = labels[model].index(role)\n",
    "#         model_indices_ordered.append(idx)\n",
    "    \n",
    "#     # Extract rows for common roles in the standardized order\n",
    "#     pca_transformed_roles.append(role_results[model]['pca_transformed'][model_indices_ordered])\n",
    "#     print(f\"{model} aligned shape: {pca_transformed_roles[-1].shape}\")\n",
    "\n",
    "# # Transpose each matrix so rows are PCs and columns are roles\n",
    "# pca_transposed_roles = [m.T for m in pca_transformed_roles]\n",
    "\n",
    "# # Extract top 10 PCs from each model\n",
    "# n_pcs = 6\n",
    "# top_pcs_roles = [m[:n_pcs] for m in pca_transposed_roles]\n",
    "\n",
    "# print(f\"\\nTransposed shapes (n_pcs, n_common_roles):\")\n",
    "# for model, pc_matrix in zip(models, top_pcs_roles):\n",
    "#     print(f\"{model}: {pc_matrix.shape}\")\n",
    "\n",
    "# # Compute pairwise correlations for each PC\n",
    "# pc_correlations_roles = []\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     # Extract the role loading vector for this PC from each model\n",
    "#     gemma_pc = top_pcs_roles[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_roles[1][pc_idx]\n",
    "#     llama_pc = top_pcs_roles[2][pc_idx]\n",
    "    \n",
    "#     # Compute pairwise correlations\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     # Create 3x3 correlation matrix\n",
    "#     corr_matrix = np.array([\n",
    "#         [1.0, corr_gemma_qwen, corr_gemma_llama],\n",
    "#         [corr_gemma_qwen, 1.0, corr_qwen_llama],\n",
    "#         [corr_gemma_llama, corr_qwen_llama, 1.0]\n",
    "#     ])\n",
    "    \n",
    "#     pc_correlations_roles.append(corr_matrix)\n",
    "\n",
    "#     print(f\"\\nPC{pc_idx + 1}:\")\n",
    "#     print(f\"  Gemma ↔ Qwen:  {corr_gemma_qwen:7.4f}\")\n",
    "#     print(f\"  Gemma ↔ Llama: {corr_gemma_llama:7.4f}\")\n",
    "#     print(f\"  Qwen  ↔ Llama: {corr_qwen_llama:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b1694",
   "metadata": {},
   "source": [
    "## Cross Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "n0k76vs7m5m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build cross-model PC loadings analysis JSON structure\n",
    "\n",
    "# n_pcs = 6\n",
    "\n",
    "# # Build trait analysis\n",
    "# trait_data = {\n",
    "#     \"dataset_info\": {\n",
    "#         \"n_common_traits\": pca_transformed[0].shape[0],\n",
    "#         \"excluded_traits\": [\"vindictive\"],\n",
    "#         \"note\": \"Gemma missing vindictive trait, spliced out from other models for alignment\"\n",
    "#     },\n",
    "#     \"model_configs\": {},\n",
    "#     \"pc_correlations\": []\n",
    "# }\n",
    "\n",
    "# # Add model configs for traits\n",
    "# for model, layer_num in zip(models, layers):\n",
    "#     pca_shape = list(trait_results[model]['pca_transformed'].shape)\n",
    "#     trait_data[\"model_configs\"][model] = {\n",
    "#         \"layer\": int(layer_num),\n",
    "#         \"n_total_traits\": int(pca_shape[0]),\n",
    "#         \"pca_shape\": pca_shape\n",
    "#     }\n",
    "\n",
    "# # Add PC correlations for traits\n",
    "# pca_transposed_traits = [m.T for m in pca_transformed]\n",
    "# top_pcs_traits = [m[:n_pcs] for m in pca_transposed_traits]\n",
    "\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     gemma_pc = top_pcs_traits[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_traits[1][pc_idx]\n",
    "#     llama_pc = top_pcs_traits[2][pc_idx]\n",
    "    \n",
    "#     from scipy.stats import pearsonr\n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     trait_data[\"pc_correlations\"].append({\n",
    "#         \"pc\": pc_idx + 1,\n",
    "#         \"gemma_qwen\": float(corr_gemma_qwen),\n",
    "#         \"gemma_llama\": float(corr_gemma_llama),\n",
    "#         \"qwen_llama\": float(corr_qwen_llama)\n",
    "#     })\n",
    "\n",
    "# # Build role analysis\n",
    "# role_data = {\n",
    "#     \"dataset_info\": {\n",
    "#         \"n_common_roles\": int(len(common_roles)),\n",
    "#         \"note\": \"Roles include pos_2 (Somewhat RP) and pos_3 (Fully RP) labels\",\n",
    "#         \"alignment_method\": \"sorted common roles list for consistent ordering\"\n",
    "#     },\n",
    "#     \"model_configs\": {},\n",
    "#     \"pc_correlations\": []\n",
    "# }\n",
    "\n",
    "# # Add model configs for roles\n",
    "# for model, layer_num in zip(models, layers):\n",
    "#     pca_shape = list(role_results[model]['pca_transformed'].shape)\n",
    "#     role_data[\"model_configs\"][model] = {\n",
    "#         \"layer\": int(layer_num),\n",
    "#         \"n_total_roles\": int(pca_shape[0]),\n",
    "#         \"n_common_roles\": int(len(common_roles)),\n",
    "#         \"pca_shape\": pca_shape\n",
    "#     }\n",
    "\n",
    "# # Add PC correlations for roles\n",
    "# pca_transposed_roles_func = [m.T for m in pca_transformed_roles]\n",
    "# top_pcs_roles_func = [m[:n_pcs] for m in pca_transposed_roles_func]\n",
    "\n",
    "# for pc_idx in range(n_pcs):\n",
    "#     gemma_pc = top_pcs_roles_func[0][pc_idx]\n",
    "#     qwen_pc = top_pcs_roles_func[1][pc_idx]\n",
    "#     llama_pc = top_pcs_roles_func[2][pc_idx]\n",
    "    \n",
    "#     corr_gemma_qwen, _ = pearsonr(gemma_pc, qwen_pc)\n",
    "#     corr_gemma_llama, _ = pearsonr(gemma_pc, llama_pc)\n",
    "#     corr_qwen_llama, _ = pearsonr(qwen_pc, llama_pc)\n",
    "    \n",
    "#     role_data[\"pc_correlations\"].append({\n",
    "#         \"pc\": pc_idx + 1,\n",
    "#         \"gemma_qwen\": float(corr_gemma_qwen),\n",
    "#         \"gemma_llama\": float(corr_gemma_llama),\n",
    "#         \"qwen_llama\": float(corr_qwen_llama)\n",
    "#     })\n",
    "\n",
    "# # Build complete structure\n",
    "# cross_model_data = {\n",
    "#     \"analysis_version\": \"1.0\",\n",
    "#     \"timestamp\": timestamp,\n",
    "#     \"models\": models,\n",
    "#     \"n_pcs_analyzed\": n_pcs,\n",
    "#     \"trait_analysis\": trait_data,\n",
    "#     \"role_analysis\": role_data\n",
    "# }\n",
    "\n",
    "# print(\"Built cross-model PC loadings data structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6s0k2hy6svd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cross-model PC loadings to JSON file\n",
    "# filename = f\"{outdir}/cross_model_loadings.json\"\n",
    "# with open(filename, 'w') as f:\n",
    "#     json.dump(cross_model_data, f, indent=2)\n",
    "\n",
    "# print(f\"Saved: {filename}\")\n",
    "# print(f\"✓ Saved cross-model PC loadings analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2oon4jt838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Summary of saved files\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"SUMMARY: JSON Files Saved\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"\\nOutput directory: {outdir}\")\n",
    "# print(f\"\\nFiles created:\")\n",
    "# print(f\"  1. Per-model variance analysis:\")\n",
    "# print(f\"     - {model_name.lower().replace('.', '-').replace(' ', '-')}_layer{layer}.json\")\n",
    "# print(f\"\\n  2. Cross-model PC loadings:\")\n",
    "# print(f\"     - cross_model_loadings.json\")\n",
    "# print(f\"\\nNote: To save variance analysis for other models (Qwen, Llama),\")\n",
    "# print(f\"      update the configuration cell and re-run the notebook.\")\n",
    "# print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
