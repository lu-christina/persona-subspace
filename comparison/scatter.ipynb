{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9c9514",
   "metadata": {},
   "source": [
    "## Between Class Scatter (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5277cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.pca_utils import L2MeanScaler, MeanScaler, compute_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb8efa",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0430319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Change these parameters for different models/datasets\n",
    "base_dir = \"/workspace/gemma-2-27b\"\n",
    "type = \"roles_240\"\n",
    "dir = f\"{base_dir}/{type}\"\n",
    "model_name = \"Gemma-2-27B\"\n",
    "layer = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f2bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/root/git/persona-subspace/.venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pca_results = torch.load(f\"{dir}/pca/layer{layer}_pos23.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca7202eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([275, 4608])\n"
     ]
    }
   ],
   "source": [
    "# vectors (between class)\n",
    "vectors = torch.stack(pca_results['vectors']['pos_3'])[:, layer, :].float()\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7346d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 275 scores\n"
     ]
    }
   ],
   "source": [
    "# load in scores\n",
    "scores = {}\n",
    "for file in os.listdir(f\"{dir}/extract_scores\"):\n",
    "    if file.endswith('.json'):\n",
    "        scores[file.replace('.json', '')] = json.load(open(f\"{dir}/extract_scores/{file}\"))\n",
    "\n",
    "print(f\"Loaded {len(scores)} scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6014d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 275 roles\n"
     ]
    }
   ],
   "source": [
    "# load in raw activations\n",
    "acts3 = {}\n",
    "acts2 = {}\n",
    "for file in os.listdir(f\"{dir}/response_activations\"):\n",
    "    if file.endswith('.pt') and 'default' not in file:\n",
    "        # dict we should iterate over (1200 each)\n",
    "        role_acts3 = []\n",
    "        role_acts2 = []\n",
    "        obj = torch.load(f\"{dir}/response_activations/{file}\")\n",
    "        for key in obj:\n",
    "            if scores[file.replace('.pt', '')][key] == 3:\n",
    "                role_acts3.append(obj[key])\n",
    "            elif scores[file.replace('.pt', '')][key] == 2:\n",
    "                role_acts2.append(obj[key])\n",
    "        if role_acts3:\n",
    "            acts3[file.replace('.pt', '')] = torch.stack(role_acts3)\n",
    "        if role_acts2:\n",
    "            acts2[file.replace('.pt', '')] = torch.stack(role_acts2)\n",
    "\n",
    "print(f\"Loaded {len(acts3)} roles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7270779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes after filtering: 494\n",
      "Sample counts per class:\n",
      "  aberration_pos_2: 84 samples\n",
      "  aberration_pos_3: 934 samples\n",
      "  absurdist_pos_3: 1199 samples\n",
      "  accountant_pos_2: 417 samples\n",
      "  accountant_pos_3: 585 samples\n",
      "  activist_pos_2: 228 samples\n",
      "  activist_pos_3: 953 samples\n",
      "  actor_pos_2: 39 samples\n",
      "  actor_pos_3: 1148 samples\n",
      "  addict_pos_2: 133 samples\n",
      "  addict_pos_3: 998 samples\n",
      "  adolescent_pos_2: 21 samples\n",
      "  adolescent_pos_3: 1158 samples\n",
      "  advocate_pos_2: 330 samples\n",
      "  advocate_pos_3: 818 samples\n",
      "  alien_pos_3: 1196 samples\n",
      "  altruist_pos_2: 726 samples\n",
      "  altruist_pos_3: 463 samples\n",
      "  amateur_pos_2: 141 samples\n",
      "  amateur_pos_3: 1023 samples\n",
      "  ambassador_pos_2: 294 samples\n",
      "  ambassador_pos_3: 721 samples\n",
      "  amnesiac_pos_3: 1190 samples\n",
      "  analyst_pos_2: 355 samples\n",
      "  analyst_pos_3: 842 samples\n",
      "  anarchist_pos_2: 45 samples\n",
      "  anarchist_pos_3: 1154 samples\n",
      "  ancient_pos_3: 1198 samples\n",
      "  angel_pos_2: 29 samples\n",
      "  angel_pos_3: 1168 samples\n",
      "  anthropologist_pos_2: 105 samples\n",
      "  anthropologist_pos_3: 1089 samples\n",
      "  archaeologist_pos_2: 60 samples\n",
      "  archaeologist_pos_3: 1126 samples\n",
      "  architect_pos_2: 180 samples\n",
      "  architect_pos_3: 911 samples\n",
      "  archivist_pos_2: 142 samples\n",
      "  archivist_pos_3: 1015 samples\n",
      "  artisan_pos_2: 82 samples\n",
      "  artisan_pos_3: 1101 samples\n",
      "  ascetic_pos_2: 23 samples\n",
      "  ascetic_pos_3: 1167 samples\n",
      "  assistant_pos_2: 280 samples\n",
      "  assistant_pos_3: 920 samples\n",
      "  auctioneer_pos_2: 26 samples\n",
      "  auctioneer_pos_3: 1156 samples\n",
      "  auditor_pos_2: 269 samples\n",
      "  auditor_pos_3: 827 samples\n",
      "  avatar_pos_3: 1186 samples\n",
      "  bard_pos_3: 1200 samples\n",
      "  bartender_pos_2: 48 samples\n",
      "  bartender_pos_3: 1142 samples\n",
      "  biologist_pos_2: 148 samples\n",
      "  biologist_pos_3: 1009 samples\n",
      "  blogger_pos_2: 45 samples\n",
      "  blogger_pos_3: 1150 samples\n",
      "  bohemian_pos_3: 1186 samples\n",
      "  builder_pos_2: 66 samples\n",
      "  builder_pos_3: 1128 samples\n",
      "  caregiver_pos_2: 448 samples\n",
      "  caregiver_pos_3: 751 samples\n",
      "  cartographer_pos_2: 166 samples\n",
      "  cartographer_pos_3: 964 samples\n",
      "  caveman_pos_3: 1196 samples\n",
      "  celebrity_pos_2: 36 samples\n",
      "  celebrity_pos_3: 1102 samples\n",
      "  chameleon_pos_2: 70 samples\n",
      "  chameleon_pos_3: 1120 samples\n",
      "  chef_pos_2: 118 samples\n",
      "  chef_pos_3: 1046 samples\n",
      "  chemist_pos_2: 210 samples\n",
      "  chemist_pos_3: 867 samples\n",
      "  chimera_pos_3: 1188 samples\n",
      "  coach_pos_2: 228 samples\n",
      "  coach_pos_3: 969 samples\n",
      "  collaborator_pos_2: 326 samples\n",
      "  collaborator_pos_3: 874 samples\n",
      "  collector_pos_2: 135 samples\n",
      "  collector_pos_3: 1037 samples\n",
      "  comedian_pos_2: 31 samples\n",
      "  comedian_pos_3: 1166 samples\n",
      "  competitor_pos_2: 58 samples\n",
      "  competitor_pos_3: 1123 samples\n",
      "  composer_pos_2: 197 samples\n",
      "  composer_pos_3: 944 samples\n",
      "  conservator_pos_2: 116 samples\n",
      "  conservator_pos_3: 1058 samples\n",
      "  consultant_pos_2: 223 samples\n",
      "  consultant_pos_3: 941 samples\n",
      "  contrarian_pos_2: 189 samples\n",
      "  contrarian_pos_3: 996 samples\n",
      "  coordinator_pos_2: 237 samples\n",
      "  coordinator_pos_3: 943 samples\n",
      "  coral_reef_pos_3: 1199 samples\n",
      "  cosmopolitan_pos_2: 189 samples\n",
      "  cosmopolitan_pos_3: 929 samples\n",
      "  counselor_pos_2: 564 samples\n",
      "  counselor_pos_3: 581 samples\n",
      "  criminal_pos_2: 39 samples\n",
      "  criminal_pos_3: 1102 samples\n",
      "  critic_pos_2: 309 samples\n",
      "  critic_pos_3: 616 samples\n",
      "  crystalline_pos_3: 1190 samples\n",
      "  curator_pos_2: 118 samples\n",
      "  curator_pos_3: 1079 samples\n",
      "  cyborg_pos_2: 160 samples\n",
      "  cyborg_pos_3: 1035 samples\n",
      "  cynic_pos_3: 1195 samples\n",
      "  daredevil_pos_2: 50 samples\n",
      "  daredevil_pos_3: 1145 samples\n",
      "  debugger_pos_2: 423 samples\n",
      "  debugger_pos_3: 653 samples\n",
      "  demon_pos_3: 1198 samples\n",
      "  designer_pos_2: 169 samples\n",
      "  designer_pos_3: 970 samples\n",
      "  destroyer_pos_2: 156 samples\n",
      "  destroyer_pos_3: 1017 samples\n",
      "  detective_pos_2: 134 samples\n",
      "  detective_pos_3: 1060 samples\n",
      "  devils_advocate_pos_2: 239 samples\n",
      "  devils_advocate_pos_3: 951 samples\n",
      "  dilettante_pos_2: 22 samples\n",
      "  dilettante_pos_3: 1170 samples\n",
      "  dispatcher_pos_2: 304 samples\n",
      "  dispatcher_pos_3: 824 samples\n",
      "  divorcee_pos_2: 60 samples\n",
      "  divorcee_pos_3: 1116 samples\n",
      "  doctor_pos_2: 464 samples\n",
      "  doctor_pos_3: 397 samples\n",
      "  dreamer_pos_3: 1196 samples\n",
      "  echo_pos_3: 1200 samples\n",
      "  economist_pos_2: 251 samples\n",
      "  economist_pos_3: 870 samples\n",
      "  ecosystem_pos_2: 221 samples\n",
      "  ecosystem_pos_3: 965 samples\n",
      "  editor_pos_2: 533 samples\n",
      "  editor_pos_3: 591 samples\n",
      "  egregore_pos_2: 21 samples\n",
      "  egregore_pos_3: 1169 samples\n",
      "  elder_pos_3: 1187 samples\n",
      "  eldritch_pos_3: 1195 samples\n",
      "  emissary_pos_2: 241 samples\n",
      "  emissary_pos_3: 929 samples\n",
      "  empath_pos_2: 105 samples\n",
      "  empath_pos_3: 1094 samples\n",
      "  engineer_pos_2: 288 samples\n",
      "  engineer_pos_3: 815 samples\n",
      "  entrepreneur_pos_2: 84 samples\n",
      "  entrepreneur_pos_3: 1081 samples\n",
      "  evaluator_pos_2: 319 samples\n",
      "  evaluator_pos_3: 854 samples\n",
      "  evangelist_pos_2: 41 samples\n",
      "  evangelist_pos_3: 1152 samples\n",
      "  examiner_pos_2: 506 samples\n",
      "  examiner_pos_3: 625 samples\n",
      "  exile_pos_3: 1185 samples\n",
      "  expatriate_pos_2: 119 samples\n",
      "  expatriate_pos_3: 1040 samples\n",
      "  facilitator_pos_2: 252 samples\n",
      "  facilitator_pos_3: 934 samples\n",
      "  familiar_pos_3: 1198 samples\n",
      "  fixer_pos_2: 135 samples\n",
      "  fixer_pos_3: 819 samples\n",
      "  flaneur_pos_3: 1199 samples\n",
      "  fool_pos_3: 1196 samples\n",
      "  forecaster_pos_2: 321 samples\n",
      "  forecaster_pos_3: 826 samples\n",
      "  futurist_pos_2: 70 samples\n",
      "  futurist_pos_3: 1121 samples\n",
      "  gamer_pos_3: 1197 samples\n",
      "  generalist_pos_2: 632 samples\n",
      "  generalist_pos_3: 361 samples\n",
      "  genie_pos_3: 1196 samples\n",
      "  geographer_pos_2: 124 samples\n",
      "  geographer_pos_3: 1018 samples\n",
      "  ghost_pos_3: 1200 samples\n",
      "  golem_pos_3: 1198 samples\n",
      "  gossip_pos_2: 13 samples\n",
      "  gossip_pos_3: 1176 samples\n",
      "  grader_pos_2: 316 samples\n",
      "  grader_pos_3: 554 samples\n",
      "  graduate_pos_2: 59 samples\n",
      "  graduate_pos_3: 1105 samples\n",
      "  grandparent_pos_3: 1197 samples\n",
      "  guardian_pos_2: 191 samples\n",
      "  guardian_pos_3: 999 samples\n",
      "  guide_pos_2: 112 samples\n",
      "  guide_pos_3: 1088 samples\n",
      "  guru_pos_2: 16 samples\n",
      "  guru_pos_3: 1184 samples\n",
      "  hacker_pos_2: 317 samples\n",
      "  hacker_pos_3: 537 samples\n",
      "  healer_pos_2: 153 samples\n",
      "  healer_pos_3: 1044 samples\n",
      "  hedonist_pos_2: 18 samples\n",
      "  hedonist_pos_3: 1178 samples\n",
      "  hermit_pos_3: 1189 samples\n",
      "  historian_pos_2: 132 samples\n",
      "  historian_pos_3: 1051 samples\n",
      "  hive_pos_2: 72 samples\n",
      "  hive_pos_3: 1045 samples\n",
      "  hoarder_pos_2: 43 samples\n",
      "  hoarder_pos_3: 1136 samples\n",
      "  homunculus_pos_3: 1200 samples\n",
      "  hybrid_pos_2: 129 samples\n",
      "  hybrid_pos_3: 1043 samples\n",
      "  idealist_pos_2: 210 samples\n",
      "  idealist_pos_3: 983 samples\n",
      "  immigrant_pos_2: 19 samples\n",
      "  immigrant_pos_3: 1174 samples\n",
      "  improviser_pos_2: 91 samples\n",
      "  improviser_pos_3: 1106 samples\n",
      "  infant_pos_3: 1187 samples\n",
      "  influencer_pos_2: 84 samples\n",
      "  influencer_pos_3: 1113 samples\n",
      "  instructor_pos_2: 149 samples\n",
      "  instructor_pos_3: 1046 samples\n",
      "  interpreter_pos_2: 551 samples\n",
      "  interpreter_pos_3: 614 samples\n",
      "  interviewer_pos_2: 128 samples\n",
      "  interviewer_pos_3: 988 samples\n",
      "  jester_pos_2: 52 samples\n",
      "  jester_pos_3: 1140 samples\n",
      "  journalist_pos_2: 243 samples\n",
      "  journalist_pos_3: 659 samples\n",
      "  judge_pos_2: 207 samples\n",
      "  judge_pos_3: 952 samples\n",
      "  lawyer_pos_2: 676 samples\n",
      "  lawyer_pos_3: 366 samples\n",
      "  leviathan_pos_3: 1200 samples\n",
      "  librarian_pos_2: 244 samples\n",
      "  librarian_pos_3: 901 samples\n",
      "  linguist_pos_2: 410 samples\n",
      "  linguist_pos_3: 726 samples\n",
      "  loner_pos_2: 146 samples\n",
      "  loner_pos_3: 1027 samples\n",
      "  luddite_pos_3: 1186 samples\n",
      "  marketer_pos_2: 146 samples\n",
      "  marketer_pos_3: 1002 samples\n",
      "  martyr_pos_2: 156 samples\n",
      "  martyr_pos_3: 1010 samples\n",
      "  mathematician_pos_2: 351 samples\n",
      "  mathematician_pos_3: 778 samples\n",
      "  maverick_pos_2: 105 samples\n",
      "  maverick_pos_3: 1071 samples\n",
      "  mechanic_pos_2: 179 samples\n",
      "  mechanic_pos_3: 889 samples\n",
      "  mediator_pos_2: 389 samples\n",
      "  mediator_pos_3: 785 samples\n",
      "  mentor_pos_2: 257 samples\n",
      "  mentor_pos_3: 917 samples\n",
      "  merchant_pos_2: 55 samples\n",
      "  merchant_pos_3: 1094 samples\n",
      "  minimalist_pos_2: 170 samples\n",
      "  minimalist_pos_3: 992 samples\n",
      "  moderator_pos_2: 212 samples\n",
      "  moderator_pos_3: 945 samples\n",
      "  musician_pos_2: 50 samples\n",
      "  musician_pos_3: 1148 samples\n",
      "  mycorrhizal_pos_3: 1200 samples\n",
      "  mystic_pos_2: 16 samples\n",
      "  mystic_pos_3: 1184 samples\n",
      "  narcissist_pos_3: 1180 samples\n",
      "  narrator_pos_2: 15 samples\n",
      "  narrator_pos_3: 1185 samples\n",
      "  naturalist_pos_2: 74 samples\n",
      "  naturalist_pos_3: 1095 samples\n",
      "  navigator_pos_2: 303 samples\n",
      "  navigator_pos_3: 785 samples\n",
      "  negotiator_pos_2: 375 samples\n",
      "  negotiator_pos_3: 795 samples\n",
      "  networker_pos_2: 276 samples\n",
      "  networker_pos_3: 918 samples\n",
      "  newlywed_pos_2: 42 samples\n",
      "  newlywed_pos_3: 1133 samples\n",
      "  nomad_pos_3: 1187 samples\n",
      "  novelist_pos_2: 173 samples\n",
      "  novelist_pos_3: 1007 samples\n",
      "  nutritionist_pos_2: 167 samples\n",
      "  nutritionist_pos_3: 940 samples\n",
      "  observer_pos_2: 548 samples\n",
      "  observer_pos_3: 605 samples\n",
      "  optimist_pos_2: 141 samples\n",
      "  optimist_pos_3: 1059 samples\n",
      "  oracle_pos_2: 11 samples\n",
      "  oracle_pos_3: 1186 samples\n",
      "  organizer_pos_2: 210 samples\n",
      "  organizer_pos_3: 983 samples\n",
      "  orphan_pos_2: 25 samples\n",
      "  orphan_pos_3: 1149 samples\n",
      "  pacifist_pos_2: 291 samples\n",
      "  pacifist_pos_3: 889 samples\n",
      "  paramedic_pos_2: 141 samples\n",
      "  paramedic_pos_3: 1003 samples\n",
      "  parasite_pos_2: 27 samples\n",
      "  parasite_pos_3: 1147 samples\n",
      "  parent_pos_2: 43 samples\n",
      "  parent_pos_3: 1137 samples\n",
      "  patient_pos_2: 121 samples\n",
      "  patient_pos_3: 959 samples\n",
      "  peacekeeper_pos_2: 296 samples\n",
      "  peacekeeper_pos_3: 893 samples\n",
      "  perfectionist_pos_2: 395 samples\n",
      "  perfectionist_pos_3: 718 samples\n",
      "  pharmacist_pos_2: 148 samples\n",
      "  pharmacist_pos_3: 929 samples\n",
      "  philosopher_pos_2: 96 samples\n",
      "  philosopher_pos_3: 1104 samples\n",
      "  photographer_pos_2: 45 samples\n",
      "  photographer_pos_3: 1140 samples\n",
      "  physicist_pos_2: 146 samples\n",
      "  physicist_pos_3: 993 samples\n",
      "  pilgrim_pos_3: 1194 samples\n",
      "  pilot_pos_2: 280 samples\n",
      "  pilot_pos_3: 773 samples\n",
      "  pirate_pos_3: 1200 samples\n",
      "  planner_pos_2: 209 samples\n",
      "  planner_pos_3: 948 samples\n",
      "  playwright_pos_2: 54 samples\n",
      "  playwright_pos_3: 1141 samples\n",
      "  podcaster_pos_2: 48 samples\n",
      "  podcaster_pos_3: 1151 samples\n",
      "  poet_pos_2: 24 samples\n",
      "  poet_pos_3: 1174 samples\n",
      "  polymath_pos_2: 286 samples\n",
      "  polymath_pos_3: 872 samples\n",
      "  pragmatist_pos_2: 130 samples\n",
      "  pragmatist_pos_3: 1066 samples\n",
      "  predator_pos_2: 45 samples\n",
      "  predator_pos_3: 1110 samples\n",
      "  presenter_pos_2: 118 samples\n",
      "  presenter_pos_3: 1082 samples\n",
      "  prey_pos_2: 10 samples\n",
      "  prey_pos_3: 1183 samples\n",
      "  prisoner_pos_2: 14 samples\n",
      "  prisoner_pos_3: 1182 samples\n",
      "  procrastinator_pos_3: 1192 samples\n",
      "  prodigy_pos_2: 481 samples\n",
      "  prodigy_pos_3: 361 samples\n",
      "  producer_pos_2: 97 samples\n",
      "  producer_pos_3: 1050 samples\n",
      "  programmer_pos_2: 285 samples\n",
      "  programmer_pos_3: 638 samples\n",
      "  proofreader_pos_2: 305 samples\n",
      "  proofreader_pos_3: 272 samples\n",
      "  prophet_pos_2: 16 samples\n",
      "  prophet_pos_3: 1178 samples\n",
      "  provincial_pos_2: 17 samples\n",
      "  provincial_pos_3: 1149 samples\n",
      "  provocateur_pos_2: 43 samples\n",
      "  provocateur_pos_3: 1155 samples\n",
      "  psychologist_pos_2: 282 samples\n",
      "  psychologist_pos_3: 903 samples\n",
      "  publisher_pos_2: 155 samples\n",
      "  publisher_pos_3: 965 samples\n",
      "  purist_pos_2: 46 samples\n",
      "  purist_pos_3: 1122 samples\n",
      "  realist_pos_2: 333 samples\n",
      "  realist_pos_3: 843 samples\n",
      "  rebel_pos_2: 18 samples\n",
      "  rebel_pos_3: 1181 samples\n",
      "  recruiter_pos_2: 153 samples\n",
      "  recruiter_pos_3: 900 samples\n",
      "  refugee_pos_2: 40 samples\n",
      "  refugee_pos_3: 1142 samples\n",
      "  reporter_pos_2: 120 samples\n",
      "  reporter_pos_3: 986 samples\n",
      "  researcher_pos_2: 326 samples\n",
      "  researcher_pos_3: 871 samples\n",
      "  retiree_pos_3: 1184 samples\n",
      "  revenant_pos_3: 1200 samples\n",
      "  reviewer_pos_2: 385 samples\n",
      "  reviewer_pos_3: 769 samples\n",
      "  revolutionary_pos_2: 71 samples\n",
      "  revolutionary_pos_3: 1125 samples\n",
      "  robot_pos_2: 622 samples\n",
      "  robot_pos_3: 522 samples\n",
      "  rogue_pos_2: 15 samples\n",
      "  rogue_pos_3: 1177 samples\n",
      "  romantic_pos_3: 1193 samples\n",
      "  saboteur_pos_2: 144 samples\n",
      "  saboteur_pos_3: 808 samples\n",
      "  sage_pos_3: 1191 samples\n",
      "  scheduler_pos_2: 374 samples\n",
      "  scheduler_pos_3: 714 samples\n",
      "  scholar_pos_2: 312 samples\n",
      "  scholar_pos_3: 873 samples\n",
      "  scientist_pos_2: 172 samples\n",
      "  scientist_pos_3: 1018 samples\n",
      "  scout_pos_2: 54 samples\n",
      "  scout_pos_3: 1145 samples\n",
      "  screener_pos_2: 366 samples\n",
      "  screener_pos_3: 387 samples\n",
      "  secretary_pos_2: 367 samples\n",
      "  secretary_pos_3: 653 samples\n",
      "  shaman_pos_3: 1191 samples\n",
      "  shapeshifter_pos_2: 83 samples\n",
      "  shapeshifter_pos_3: 1108 samples\n",
      "  simulacrum_pos_2: 142 samples\n",
      "  simulacrum_pos_3: 1055 samples\n",
      "  skeptic_pos_2: 198 samples\n",
      "  skeptic_pos_3: 995 samples\n",
      "  smuggler_pos_3: 1182 samples\n",
      "  sociologist_pos_2: 81 samples\n",
      "  sociologist_pos_3: 1107 samples\n",
      "  soldier_pos_2: 32 samples\n",
      "  soldier_pos_3: 1161 samples\n",
      "  sommelier_pos_2: 90 samples\n",
      "  sommelier_pos_3: 1086 samples\n",
      "  specialist_pos_2: 735 samples\n",
      "  specialist_pos_3: 417 samples\n",
      "  spirit_pos_3: 1195 samples\n",
      "  spy_pos_2: 172 samples\n",
      "  spy_pos_3: 956 samples\n",
      "  statistician_pos_2: 217 samples\n",
      "  statistician_pos_3: 950 samples\n",
      "  stoic_pos_2: 68 samples\n",
      "  stoic_pos_3: 1123 samples\n",
      "  strategist_pos_2: 114 samples\n",
      "  strategist_pos_3: 1079 samples\n",
      "  student_pos_2: 148 samples\n",
      "  student_pos_3: 988 samples\n",
      "  summarizer_pos_2: 450 samples\n",
      "  summarizer_pos_3: 660 samples\n",
      "  supervisor_pos_2: 230 samples\n",
      "  supervisor_pos_3: 879 samples\n",
      "  surfer_pos_3: 1199 samples\n",
      "  survivor_pos_2: 39 samples\n",
      "  survivor_pos_3: 1151 samples\n",
      "  swarm_pos_2: 93 samples\n",
      "  swarm_pos_3: 1096 samples\n",
      "  symbiont_pos_2: 71 samples\n",
      "  symbiont_pos_3: 1127 samples\n",
      "  synthesizer_pos_2: 408 samples\n",
      "  synthesizer_pos_3: 772 samples\n",
      "  teacher_pos_2: 157 samples\n",
      "  teacher_pos_3: 1043 samples\n",
      "  technologist_pos_2: 141 samples\n",
      "  technologist_pos_3: 1018 samples\n",
      "  teenager_pos_2: 16 samples\n",
      "  teenager_pos_3: 1169 samples\n",
      "  theorist_pos_2: 87 samples\n",
      "  theorist_pos_3: 1108 samples\n",
      "  therapist_pos_2: 464 samples\n",
      "  therapist_pos_3: 687 samples\n",
      "  toddler_pos_3: 1195 samples\n",
      "  traditionalist_pos_2: 72 samples\n",
      "  traditionalist_pos_3: 1123 samples\n",
      "  trainer_pos_2: 151 samples\n",
      "  trainer_pos_3: 1046 samples\n",
      "  translator_pos_2: 366 samples\n",
      "  translator_pos_3: 192 samples\n",
      "  tree_pos_3: 1199 samples\n",
      "  trickster_pos_2: 21 samples\n",
      "  trickster_pos_3: 1179 samples\n",
      "  tulpa_pos_2: 52 samples\n",
      "  tulpa_pos_3: 1063 samples\n",
      "  tutor_pos_2: 128 samples\n",
      "  tutor_pos_3: 1072 samples\n",
      "  validator_pos_2: 569 samples\n",
      "  validator_pos_3: 568 samples\n",
      "  vampire_pos_3: 1194 samples\n",
      "  vegan_pos_2: 138 samples\n",
      "  vegan_pos_3: 1030 samples\n",
      "  veteran_pos_2: 49 samples\n",
      "  veteran_pos_3: 1147 samples\n",
      "  veterinarian_pos_2: 106 samples\n",
      "  veterinarian_pos_3: 1048 samples\n",
      "  vigilante_pos_2: 150 samples\n",
      "  vigilante_pos_3: 837 samples\n",
      "  virtuoso_pos_2: 350 samples\n",
      "  virtuoso_pos_3: 792 samples\n",
      "  virus_pos_2: 209 samples\n",
      "  virus_pos_3: 624 samples\n",
      "  visionary_pos_2: 214 samples\n",
      "  visionary_pos_3: 972 samples\n",
      "  void_pos_3: 1199 samples\n",
      "  wanderer_pos_3: 1190 samples\n",
      "  warrior_pos_2: 32 samples\n",
      "  warrior_pos_3: 1166 samples\n",
      "  whale_pos_3: 1199 samples\n",
      "  widow_pos_2: 28 samples\n",
      "  widow_pos_3: 1164 samples\n",
      "  wind_pos_3: 1200 samples\n",
      "  witch_pos_3: 1188 samples\n",
      "  witness_pos_2: 509 samples\n",
      "  witness_pos_3: 426 samples\n",
      "  workaholic_pos_2: 73 samples\n",
      "  workaholic_pos_3: 1098 samples\n",
      "  wraith_pos_3: 1200 samples\n",
      "  writer_pos_2: 385 samples\n",
      "  writer_pos_3: 758 samples\n",
      "  zealot_pos_3: 1196 samples\n",
      "  zeitgeist_pos_3: 1188 samples\n"
     ]
    }
   ],
   "source": [
    "def prepare_class_data(acts2, acts3, layer, min_samples=10):\n",
    "    \"\"\"\n",
    "    Combine acts2 and acts3 dictionaries into class-based structure.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    acts2 : dict\n",
    "        Dictionary mapping role names to tensors of shape [n_samples, n_layers, N]\n",
    "    acts3 : dict\n",
    "        Dictionary mapping role names to tensors of shape [n_samples, n_layers, N]\n",
    "    layer : int\n",
    "        Which layer to extract activations from\n",
    "    min_samples : int\n",
    "        Minimum number of samples required to include a class\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    class_data : dict\n",
    "        Dictionary mapping class names (e.g., \"graduate_pos_2\") to arrays of shape [n_samples, N]\n",
    "    \"\"\"\n",
    "    class_data = {}\n",
    "    \n",
    "    # Process pos_2 samples\n",
    "    for role, activations in acts2.items():\n",
    "        class_name = f\"{role}_pos_2\"\n",
    "        # Extract specified layer\n",
    "        layer_acts = activations[:, layer, :].float().numpy()\n",
    "        if len(layer_acts) >= min_samples:\n",
    "            class_data[class_name] = layer_acts\n",
    "    \n",
    "    # Process pos_3 samples\n",
    "    for role, activations in acts3.items():\n",
    "        class_name = f\"{role}_pos_3\"\n",
    "        # Extract specified layer\n",
    "        layer_acts = activations[:, layer, :].float().numpy()\n",
    "        if len(layer_acts) >= min_samples:\n",
    "            class_data[class_name] = layer_acts\n",
    "    \n",
    "    return class_data\n",
    "\n",
    "# Prepare the data\n",
    "class_data = prepare_class_data(acts2, acts3, layer=layer, min_samples=10)\n",
    "print(f\"Number of classes after filtering: {len(class_data)}\")\n",
    "print(f\"Sample counts per class:\")\n",
    "for class_name, data in sorted(class_data.items()):\n",
    "    print(f\"  {class_name}: {len(data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8mb0xfpkcgs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_role_variance_subspace(class_data, scaler=None, k=None):\n",
    "    \"\"\"\n",
    "    Find subspace maximizing between-class variance using Linear Discriminant Analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    class_data : dict\n",
    "        Dictionary mapping class names to arrays of shape [n_samples, N]\n",
    "    scaler : sklearn-compatible scaler or None\n",
    "        Optional scaler (StandardScaler, L2MeanScaler, MeanScaler, etc.)\n",
    "    k : int, optional\n",
    "        Number of dimensions in subspace. If None, returns all components.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    projection_matrix : array of shape [N, k]\n",
    "        Columns are the optimal projection directions\n",
    "    eigenvalues : array\n",
    "        The eigenvalues (variance ratios)\n",
    "    projected_data : dict\n",
    "        Dictionary mapping class names to projected data of shape [n_samples, k]\n",
    "    \"\"\"\n",
    "    # Gather all data and class information\n",
    "    class_names = list(class_data.keys())\n",
    "    class_samples = [class_data[name] for name in class_names]\n",
    "    class_sizes = [len(samples) for samples in class_samples]\n",
    "    \n",
    "    # Concatenate all data\n",
    "    X = np.vstack(class_samples)  # shape: [total_samples, N]\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    # Apply scaler if provided\n",
    "    if scaler is not None:\n",
    "        X = scaler.fit_transform(X)\n",
    "        # Also transform individual classes for later projection\n",
    "        scaled_class_samples = []\n",
    "        start_idx = 0\n",
    "        for size in class_sizes:\n",
    "            scaled_class_samples.append(X[start_idx:start_idx + size])\n",
    "            start_idx += size\n",
    "        class_samples = scaled_class_samples\n",
    "    \n",
    "    # Compute overall mean\n",
    "    mu_total = X.mean(axis=0)\n",
    "    \n",
    "    # Compute per-class means\n",
    "    class_means = [samples.mean(axis=0) for samples in class_samples]\n",
    "    \n",
    "    # Compute between-class scatter matrix (weighted by number of samples)\n",
    "    S_B = np.zeros((N, N))\n",
    "    for i, (mean, n_samples) in enumerate(zip(class_means, class_sizes)):\n",
    "        diff = mean - mu_total\n",
    "        S_B += n_samples * np.outer(diff, diff)\n",
    "    \n",
    "    # Compute total scatter matrix\n",
    "    S_T = np.zeros((N, N))\n",
    "    for i in range(len(X)):\n",
    "        diff = X[i] - mu_total\n",
    "        S_T += np.outer(diff, diff)\n",
    "    \n",
    "    # Solve generalized eigenvalue problem: S_B w = λ S_T w\n",
    "    # Equivalent to: (S_T^-1 @ S_B) w = λ w\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(\n",
    "        np.linalg.pinv(S_T) @ S_B\n",
    "    )\n",
    "    \n",
    "    # Sort by eigenvalue (descending)\n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues = eigenvalues[idx].real\n",
    "    eigenvectors = eigenvectors[:, idx].real\n",
    "    \n",
    "    # Select top k components\n",
    "    if k is not None:\n",
    "        eigenvectors = eigenvectors[:, :k]\n",
    "        eigenvalues = eigenvalues[:k]\n",
    "    \n",
    "    # Project data onto subspace\n",
    "    projected_data = {}\n",
    "    for name, samples in zip(class_names, class_samples):\n",
    "        projected_data[name] = samples @ eigenvectors\n",
    "    \n",
    "    return eigenvectors, eigenvalues, projected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cmoz2uxnnzi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the between-class scatter analysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# You can try different scalers:\n",
    "# - StandardScaler() - standardize to zero mean and unit variance\n",
    "# - L2MeanScaler() - imported from utils.pca_utils\n",
    "# - MeanScaler() - imported from utils.pca_utils\n",
    "# - None - no scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "k = 10  # Number of dimensions to keep\n",
    "\n",
    "projection_matrix, eigenvalues, projected_data = find_role_variance_subspace(\n",
    "    class_data, \n",
    "    scaler=scaler,\n",
    "    k=k\n",
    ")\n",
    "\n",
    "print(f\"Projection matrix shape: {projection_matrix.shape}\")\n",
    "print(f\"Number of components: {len(eigenvalues)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azjr67wfuc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"=\" * 60)\n",
    "print(\"BETWEEN-CLASS SCATTER ANALYSIS RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show top eigenvalues and variance ratios\n",
    "print(f\"\\nTop {k} eigenvalues:\")\n",
    "for i, eigval in enumerate(eigenvalues):\n",
    "    print(f\"  Component {i+1}: {eigval:.6f}\")\n",
    "\n",
    "# Calculate variance ratios\n",
    "total_variance = eigenvalues.sum()\n",
    "variance_ratios = eigenvalues / total_variance\n",
    "print(f\"\\nVariance ratios (of between-class variance):\")\n",
    "for i, ratio in enumerate(variance_ratios):\n",
    "    print(f\"  Component {i+1}: {ratio:.4f} ({ratio*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nCumulative variance explained:\")\n",
    "cumsum = np.cumsum(variance_ratios)\n",
    "for i, cum in enumerate(cumsum):\n",
    "    print(f\"  Components 1-{i+1}: {cum:.4f} ({cum*100:.2f}%)\")\n",
    "\n",
    "# Show projected data shapes\n",
    "print(f\"\\nProjected data shapes:\")\n",
    "for class_name, proj_data in sorted(projected_data.items()):\n",
    "    print(f\"  {class_name}: {proj_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "vcs4lfqtu",
   "source": "# Project the mean role vectors into the LDA space\nimport sys\nsys.path.append('..')\nsys.path.append('../roles')\nfrom plots import plot_pc\n\n# Extract pos_2 and pos_3 mean vectors from the specified layer\npos_2_vectors = torch.stack(pca_results['vectors']['pos_2'])[:, layer, :].float().numpy()\npos_3_vectors = torch.stack(pca_results['vectors']['pos_3'])[:, layer, :].float().numpy()\n\n# Combine them\ncombined_vectors = np.vstack([pos_2_vectors, pos_3_vectors])\n\n# Apply the same scaler if it was used\nif scaler is not None:\n    combined_vectors_scaled = scaler.transform(combined_vectors)\nelse:\n    combined_vectors_scaled = combined_vectors\n\n# Project onto LDA subspace\ncombined_vectors_projected = combined_vectors_scaled @ projection_matrix\n\nprint(f\"Pos_2 vectors: {pos_2_vectors.shape}\")\nprint(f\"Pos_3 vectors: {pos_3_vectors.shape}\")\nprint(f\"Combined projected shape: {combined_vectors_projected.shape}\")\nprint(f\"Expected: ({len(pos_2_vectors) + len(pos_3_vectors)}, {k})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4o5jpwl2ysi",
   "source": "# Create a results structure compatible with plot_pc\n# Create role labels for both pos_2 and pos_3\npos_2_labels = [role.replace('_', ' ').title() + \" (Somewhat RP)\" for role in pca_results['roles']['pos_2']]\npos_3_labels = [role.replace('_', ' ').title() + \" (Fully RP)\" for role in pca_results['roles']['pos_3']]\nrole_labels = pos_2_labels + pos_3_labels\n\n# Create a mock \"LDA results\" structure compatible with plot_pc\nlda_results = {\n    'pca_transformed': combined_vectors_projected,  # The projected vectors\n    'variance_explained': eigenvalues / eigenvalues.sum(),  # Variance ratios\n    'pca': type('obj', (object,), {\n        'components_': projection_matrix.T  # LDA components (transposed to match PCA format)\n    })(),\n    'scaler': scaler,\n    'roles': {\n        'pos_2': pca_results['roles']['pos_2'],\n        'pos_3': pca_results['roles']['pos_3']\n    },\n    'vectors': {\n        'pos_2': pca_results['vectors']['pos_2'],\n        'pos_3': pca_results['vectors']['pos_3']\n    }\n}\n\nprint(f\"Created LDA results structure\")\nprint(f\"  Projected data shape: {lda_results['pca_transformed'].shape}\")\nprint(f\"  Components shape: {lda_results['pca'].components_.shape}\")\nprint(f\"  Number of roles: {len(role_labels)} ({len(pos_2_labels)} pos_2 + {len(pos_3_labels)} pos_3)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "pfv6w7n8n08",
   "source": "# Plot the LDA components using plot_pc\n# Similar to the PCA notebook, we'll plot the first few components\n\nsubtitle = f\"{model_name}, Layer {layer} - LDA Between-Class Scatter Analysis\"\n\nfor i in range(min(6, k)):  # Plot up to 6 components or k, whichever is smaller\n    fig = plot_pc(\n        pca_results=lda_results,\n        role_labels=role_labels,\n        layer=layer,\n        pc_component=i,\n        assistant_activation=None,  # Optional: add if you have default vectors\n        assistant_projection=None,  # Optional: add if you have default vectors\n        title=f\"LDA Component {i+1} - Role-Playing Vectors\",\n        subtitle=subtitle,\n        scaled=False  # We already scaled when creating the LDA projection\n    )\n    fig.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}