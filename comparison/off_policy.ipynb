{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2ad8d5",
   "metadata": {},
   "source": [
    "# Check on vs off policy rollouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0347879",
   "metadata": {},
   "source": [
    "comparing llama vectors generated on llama with those generated on qwen\n",
    "\n",
    "* individual role vectors\n",
    "* default vectors\n",
    "* per layer contrast vector\n",
    "* per layer PCA (mean)\n",
    "\n",
    "maybe later i run some steering experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cbad801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.pca_utils import L2MeanScaler, MeanScaler, compute_pca, plot_variance_explained\n",
    "from plots import plot_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0f6d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama-3.3-70b\"\n",
    "target = \"gemma_roles\"\n",
    "target_model = \"gemma-2-27b\"\n",
    "\n",
    "base_dir = f\"/workspace/{model}/{target}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e1865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pos_0', 'pos_1', 'pos_2', 'pos_3', 'pos_all'])\n",
      "torch.Size([80, 8192])\n"
     ]
    }
   ],
   "source": [
    "vector_dir = f\"{base_dir}/vectors\"\n",
    "single_vector = torch.load(f\"{vector_dir}/aberration.pt\")\n",
    "print(single_vector.keys())\n",
    "print(single_vector['pos_3'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f25cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 275 roles with vectors\n"
     ]
    }
   ],
   "source": [
    "vectors = {}\n",
    "for file in os.listdir(vector_dir):\n",
    "    if file.endswith(\".pt\"):\n",
    "        vec = torch.load(os.path.join(vector_dir, file))\n",
    "        assert vec['pos_3'].shape == single_vector['pos_3'].shape\n",
    "        vectors[file.replace(\".pt\", \"\")] = vec\n",
    "\n",
    "print(f\"Found {len(vectors.keys())} roles with vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b41171c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n",
      "275\n"
     ]
    }
   ],
   "source": [
    "pos_2_roles = []\n",
    "pos_2_vectors = []\n",
    "pos_3_roles = []\n",
    "pos_3_vectors = []\n",
    "\n",
    "# get the vectors keys for pos_2 and pos_3 for each role\n",
    "for role, vector in vectors.items():\n",
    "    if 'pos_2' in vector.keys():\n",
    "        pos_2_roles.append(role)\n",
    "        pos_2_vectors.append(vector['pos_2'])\n",
    "    if 'pos_3' in vector.keys():\n",
    "        pos_3_roles.append(role)\n",
    "        pos_3_vectors.append(vector['pos_3'])\n",
    "\n",
    "print(len(pos_2_roles))\n",
    "print(len(pos_3_roles))\n",
    "\n",
    "combined_vectors = pos_2_vectors + pos_3_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f2d30",
   "metadata": {},
   "source": [
    "## Contrast vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241d87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 8192])\n"
     ]
    }
   ],
   "source": [
    "role_all_layers = torch.stack(pos_3_vectors).mean(dim=0)\n",
    "default_all_layers = torch.load(f\"{base_dir}/default_vectors.pt\")['activations']['default_1']\n",
    "contrast_vector = role_all_layers - default_all_layers\n",
    "print(contrast_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1513d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(contrast_vector, f\"{base_dir}/contrast_vector.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a030f",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cfe666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([448, 80, 8192])\n"
     ]
    }
   ],
   "source": [
    "float_stack_vectors = torch.stack(combined_vectors).float()\n",
    "print(float_stack_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da6c9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1 = []\n",
    "pca_dir = f\"{base_dir}/pca\"\n",
    "os.makedirs(pca_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(float_stack_vectors.shape[1]):\n",
    "    scaler = MeanScaler()\n",
    "    pca_transformed, variance_explained, n_components, pca, scaler = compute_pca(\n",
    "        float_stack_vectors, \n",
    "        layer=i, \n",
    "        scaler=scaler\n",
    "    )\n",
    "    results = {}\n",
    "    results['layer'] = i\n",
    "    results['roles'] = {\n",
    "        'pos_2': pos_2_roles,\n",
    "        'pos_3': pos_3_roles\n",
    "    }\n",
    "    results['vectors'] = {\n",
    "        'pos_2': pos_2_vectors,\n",
    "        'pos_3': pos_3_vectors\n",
    "    }\n",
    "    results['pca_transformed'] = pca_transformed\n",
    "    results['variance_explained'] = variance_explained\n",
    "    results['n_components'] = n_components\n",
    "    results['pca'] = pca\n",
    "    results['scaler'] = scaler\n",
    "\n",
    "    pc1.append(pca.components_[0])\n",
    "    torch.save(results, f\"{pca_dir}/layer{i}_mean_pos23.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
