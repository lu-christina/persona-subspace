{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da516b65",
   "metadata": {},
   "source": [
    "# Compare vectors to behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f5a268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddccc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama-3.3-70b\"\n",
    "layer = 40\n",
    "base_dir = f\"/workspace/{model_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883910a9",
   "metadata": {},
   "source": [
    "## Vector sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "264af471",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspace/qwen-3-32b/roles_240/contrast_vectors.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m default_all_layers = torch.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/roles_240/default_vectors.pt\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mactivations\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mdefault_1\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m contrast_vectors = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/roles_240/contrast_vectors.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.12/site-packages/torch/serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.12/site-packages/torch/serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/persona-subspace/.venv/lib/python3.12/site-packages/torch/serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspace/qwen-3-32b/roles_240/contrast_vectors.pt'"
     ]
    }
   ],
   "source": [
    "default_all_layers = torch.load(f\"{base_dir}/roles_240/default_vectors.pt\")['activations']['default_1']\n",
    "contrast_vectors = torch.load(f\"{base_dir}/roles_240/contrast_vectors.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42d5403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_results = torch.load(f\"{base_dir}/roles_240/pca/layer{layer}_mean_pos23.pt\", weights_only=False)\n",
    "trait_results = torch.load(f\"{base_dir}/traits_240/pca/layer{layer}_mean_pos-neg50.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d27354d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([377, 80, 8192])\n"
     ]
    }
   ],
   "source": [
    "pos_2_vectors = role_results['vectors']['pos_2']\n",
    "pos_3_vectors = role_results['vectors']['pos_3']\n",
    "pos_2_roles = role_results['roles']['pos_2']\n",
    "pos_3_roles = role_results['roles']['pos_3']\n",
    "\n",
    "combined_vectors = pos_2_vectors + pos_3_vectors\n",
    "role_vectors = torch.stack(pos_2_vectors + pos_3_vectors).float()\n",
    "role_labels = pos_2_roles + pos_3_roles\n",
    "print(role_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85389d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 80, 8192])\n"
     ]
    }
   ],
   "source": [
    "trait_vectors = torch.stack(trait_results['vectors']['pos_neg_50']).float()\n",
    "trait_labels = trait_results['traits']['pos_neg_50']\n",
    "\n",
    "print(trait_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ab049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "default_vector = default_all_layers[layer].float()\n",
    "contrast_vector = contrast_vectors[layer].float() * -1\n",
    "\n",
    "default_norm = F.normalize(default_vector.unsqueeze(0), dim=-1)\n",
    "contrast_norm = F.normalize(contrast_vector.unsqueeze(0), dim=-1)\n",
    "\n",
    "# Get role vectors at the specified layer and compute cosine similarity\n",
    "role_vectors_at_layer = role_vectors[:, layer, :]\n",
    "role_vectors_norm = F.normalize(role_vectors_at_layer, dim=-1)\n",
    "role_similarities = (role_vectors_norm @ default_norm.T).squeeze()\n",
    "role_similarities_contrast = (role_vectors_norm @ contrast_norm.T).squeeze()\n",
    "\n",
    "# Get trait vectors at the specified layer and compute cosine similarity\n",
    "trait_vectors_at_layer = trait_vectors[:, layer, :]\n",
    "trait_vectors_norm = F.normalize(trait_vectors_at_layer, dim=-1)\n",
    "trait_similarities = (trait_vectors_norm @ default_norm.T).squeeze()\n",
    "trait_similarities_contrast = (trait_vectors_norm @ contrast_norm.T).squeeze()\n",
    "\n",
    "# Create role type labels (pos_2 or pos_3)\n",
    "num_pos_2 = len(pos_2_roles)\n",
    "num_pos_3 = len(pos_3_roles)\n",
    "role_types = ['pos_2'] * num_pos_2 + ['pos_3'] * num_pos_3\n",
    "\n",
    "# Build separate dataframes\n",
    "role_df = pd.DataFrame({\n",
    "    'name': role_labels,\n",
    "    'role_type': role_types,\n",
    "    'default_similarity': role_similarities.numpy(),\n",
    "    'contrast_similarity': role_similarities_contrast.numpy()\n",
    "})\n",
    "\n",
    "trait_df = pd.DataFrame({\n",
    "    'name': trait_labels,\n",
    "    'default_similarity': trait_similarities.numpy(),\n",
    "    'contrast_similarity': trait_similarities_contrast.numpy()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b92916ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>role_type</th>\n",
       "      <th>default_similarity</th>\n",
       "      <th>contrast_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>assistant</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.997039</td>\n",
       "      <td>0.293464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>summarizer</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.980068</td>\n",
       "      <td>0.283677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>instructor</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.989009</td>\n",
       "      <td>0.253344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>consultant</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.989550</td>\n",
       "      <td>0.243047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>planner</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.981953</td>\n",
       "      <td>0.241452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>organizer</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.985661</td>\n",
       "      <td>0.241123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>analyst</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.984435</td>\n",
       "      <td>0.238824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>researcher</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.985303</td>\n",
       "      <td>0.236318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>reviewer</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.984693</td>\n",
       "      <td>0.233218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>supervisor</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.984356</td>\n",
       "      <td>0.229611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>evaluator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.983265</td>\n",
       "      <td>0.229128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>teacher</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.991012</td>\n",
       "      <td>0.228003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tutor</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>0.227458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>trainer</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.981997</td>\n",
       "      <td>0.223569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>mentor</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.990535</td>\n",
       "      <td>0.222906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>coach</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.986178</td>\n",
       "      <td>0.222043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>screener</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.981254</td>\n",
       "      <td>0.220654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.218440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>strategist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.979273</td>\n",
       "      <td>0.218404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>doctor</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.981602</td>\n",
       "      <td>0.217227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>validator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.980018</td>\n",
       "      <td>0.216678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>grader</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.978867</td>\n",
       "      <td>0.214304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>coordinator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.987019</td>\n",
       "      <td>0.214183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>examiner</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.977727</td>\n",
       "      <td>0.213153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>secretary</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.974560</td>\n",
       "      <td>0.212386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>moderator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.974940</td>\n",
       "      <td>0.208121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>facilitator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.980344</td>\n",
       "      <td>0.206627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>marketer</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.979189</td>\n",
       "      <td>0.206584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>publisher</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.987004</td>\n",
       "      <td>0.205475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>presenter</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.989198</td>\n",
       "      <td>0.204949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>recruiter</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.979638</td>\n",
       "      <td>0.203548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>debugger</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.980661</td>\n",
       "      <td>0.200367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>lawyer</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.974827</td>\n",
       "      <td>0.200109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>sociologist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.977675</td>\n",
       "      <td>0.198477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>student</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.968400</td>\n",
       "      <td>0.198048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>therapist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.971196</td>\n",
       "      <td>0.197287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>specialist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.980827</td>\n",
       "      <td>0.195997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>collaborator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.979779</td>\n",
       "      <td>0.195687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>scheduler</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.975702</td>\n",
       "      <td>0.195676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>mediator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.980446</td>\n",
       "      <td>0.195027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>auditor</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.971113</td>\n",
       "      <td>0.193534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>counselor</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.973403</td>\n",
       "      <td>0.192870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>engineer</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.976638</td>\n",
       "      <td>0.192230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>forecaster</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.978844</td>\n",
       "      <td>0.191529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>editor</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.984536</td>\n",
       "      <td>0.191472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>nutritionist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.962417</td>\n",
       "      <td>0.190637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>scientist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.972997</td>\n",
       "      <td>0.189651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>pragmatist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.969630</td>\n",
       "      <td>0.187350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>producer</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.980827</td>\n",
       "      <td>0.186396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>negotiator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.979012</td>\n",
       "      <td>0.185100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name label role_type  default_similarity  contrast_similarity\n",
       "353     assistant  role     pos_3            0.997039             0.293464\n",
       "143    summarizer  role     pos_3            0.980068             0.283677\n",
       "254    instructor  role     pos_3            0.989009             0.253344\n",
       "328    consultant  role     pos_3            0.989550             0.243047\n",
       "200       planner  role     pos_3            0.981953             0.241452\n",
       "216     organizer  role     pos_3            0.985661             0.241123\n",
       "363       analyst  role     pos_3            0.984435             0.238824\n",
       "174    researcher  role     pos_3            0.985303             0.236318\n",
       "171      reviewer  role     pos_3            0.984693             0.233218\n",
       "142    supervisor  role     pos_3            0.984356             0.229611\n",
       "293     evaluator  role     pos_3            0.983265             0.229128\n",
       "136       teacher  role     pos_3            0.991012             0.228003\n",
       "124         tutor  role     pos_3            0.989898             0.227458\n",
       "129       trainer  role     pos_3            0.981997             0.223569\n",
       "236        mentor  role     pos_3            0.990535             0.222906\n",
       "335         coach  role     pos_3            0.986178             0.222043\n",
       "160      screener  role     pos_3            0.981254             0.220654\n",
       "182  psychologist  role     pos_3            0.972067             0.218440\n",
       "145    strategist  role     pos_3            0.979273             0.218404\n",
       "306        doctor  role     pos_3            0.981602             0.217227\n",
       "123     validator  role     pos_3            0.980018             0.216678\n",
       "274        grader  role     pos_3            0.978867             0.214304\n",
       "326   coordinator  role     pos_3            0.987019             0.214183\n",
       "291      examiner  role     pos_3            0.977727             0.213153\n",
       "159     secretary  role     pos_3            0.974560             0.212386\n",
       "233     moderator  role     pos_3            0.974940             0.208121\n",
       "288   facilitator  role     pos_3            0.980344             0.206627\n",
       "242      marketer  role     pos_3            0.979189             0.206584\n",
       "181     publisher  role     pos_3            0.987004             0.205475\n",
       "193     presenter  role     pos_3            0.989198             0.204949\n",
       "177     recruiter  role     pos_3            0.979638             0.203548\n",
       "315      debugger  role     pos_3            0.980661             0.200367\n",
       "248        lawyer  role     pos_3            0.974827             0.200109\n",
       "153   sociologist  role     pos_3            0.977675             0.198477\n",
       "144       student  role     pos_3            0.968400             0.198048\n",
       "132     therapist  role     pos_3            0.971196             0.197287\n",
       "150    specialist  role     pos_3            0.980827             0.195997\n",
       "334  collaborator  role     pos_3            0.979779             0.195687\n",
       "164     scheduler  role     pos_3            0.975702             0.195676\n",
       "237      mediator  role     pos_3            0.980446             0.195027\n",
       "351       auditor  role     pos_3            0.971113             0.193534\n",
       "323     counselor  role     pos_3            0.973403             0.192870\n",
       "295      engineer  role     pos_3            0.976638             0.192230\n",
       "283    forecaster  role     pos_3            0.978844             0.191529\n",
       "301        editor  role     pos_3            0.984536             0.191472\n",
       "220  nutritionist  role     pos_3            0.962417             0.190637\n",
       "162     scientist  role     pos_3            0.972997             0.189651\n",
       "195    pragmatist  role     pos_3            0.969630             0.187350\n",
       "188      producer  role     pos_3            0.980827             0.186396\n",
       "225    negotiator  role     pos_3            0.979012             0.185100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['role_type'] == 'pos_3'].sort_values(by='contrast_similarity', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5da424f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>role_type</th>\n",
       "      <th>default_similarity</th>\n",
       "      <th>contrast_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>simulacrum</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.883287</td>\n",
       "      <td>-0.054747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>parasite</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.866285</td>\n",
       "      <td>-0.054758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>spirit</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.897585</td>\n",
       "      <td>-0.056028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>narcissist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.747981</td>\n",
       "      <td>-0.060354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>romantic</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.887845</td>\n",
       "      <td>-0.061376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>warrior</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.883315</td>\n",
       "      <td>-0.065532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>smuggler</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.810311</td>\n",
       "      <td>-0.070233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>criminal</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.802728</td>\n",
       "      <td>-0.070508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>narrator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.899819</td>\n",
       "      <td>-0.071091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>predator</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.867048</td>\n",
       "      <td>-0.074169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>chimera</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.888955</td>\n",
       "      <td>-0.074634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>exile</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.871230</td>\n",
       "      <td>-0.075358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>luddite</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.787089</td>\n",
       "      <td>-0.076158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>mycorrhizal</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.852218</td>\n",
       "      <td>-0.078633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>wind</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.873513</td>\n",
       "      <td>-0.079126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>flaneur</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>-0.080256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>provocateur</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.839165</td>\n",
       "      <td>-0.080924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>shaman</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.866307</td>\n",
       "      <td>-0.081136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>mystic</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.875267</td>\n",
       "      <td>-0.083189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>homunculus</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.880295</td>\n",
       "      <td>-0.096083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>crystalline</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.837987</td>\n",
       "      <td>-0.096483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>whale</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.865674</td>\n",
       "      <td>-0.098696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>pilgrim</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.874064</td>\n",
       "      <td>-0.099074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>dreamer</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.878789</td>\n",
       "      <td>-0.100025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>aberration</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.868664</td>\n",
       "      <td>-0.102044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>prophet</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.873673</td>\n",
       "      <td>-0.103063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>oracle</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.872035</td>\n",
       "      <td>-0.104297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>trickster</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.868010</td>\n",
       "      <td>-0.105226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>rogue</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.851260</td>\n",
       "      <td>-0.105277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>bohemian</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.856232</td>\n",
       "      <td>-0.109528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>jester</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.812406</td>\n",
       "      <td>-0.112551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>golem</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.853356</td>\n",
       "      <td>-0.113629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>revenant</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.861850</td>\n",
       "      <td>-0.115594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>echo</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.866393</td>\n",
       "      <td>-0.115656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>witch</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.861482</td>\n",
       "      <td>-0.116523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>poet</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.832950</td>\n",
       "      <td>-0.118651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>ghost</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.870981</td>\n",
       "      <td>-0.119735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>hermit</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.861498</td>\n",
       "      <td>-0.120373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>bard</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.862576</td>\n",
       "      <td>-0.121733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>ascetic</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.834632</td>\n",
       "      <td>-0.124436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>zealot</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.766515</td>\n",
       "      <td>-0.129866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>wraith</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.849069</td>\n",
       "      <td>-0.139864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>demon</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.816017</td>\n",
       "      <td>-0.140048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>genie</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.838406</td>\n",
       "      <td>-0.142917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tree</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.818532</td>\n",
       "      <td>-0.143231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>absurdist</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.790939</td>\n",
       "      <td>-0.144481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>vampire</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.823770</td>\n",
       "      <td>-0.149999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>void</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.780103</td>\n",
       "      <td>-0.168217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>eldritch</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.795911</td>\n",
       "      <td>-0.184012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>leviathan</td>\n",
       "      <td>role</td>\n",
       "      <td>pos_3</td>\n",
       "      <td>0.787183</td>\n",
       "      <td>-0.185045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name label role_type  default_similarity  contrast_similarity\n",
       "156   simulacrum  role     pos_3            0.883287            -0.054747\n",
       "212     parasite  role     pos_3            0.866285            -0.054758\n",
       "149       spirit  role     pos_3            0.897585            -0.056028\n",
       "229   narcissist  role     pos_3            0.747981            -0.060354\n",
       "167     romantic  role     pos_3            0.887845            -0.061376\n",
       "112      warrior  role     pos_3            0.883315            -0.065532\n",
       "154     smuggler  role     pos_3            0.810311            -0.070233\n",
       "322     criminal  role     pos_3            0.802728            -0.070508\n",
       "228     narrator  role     pos_3            0.899819            -0.071091\n",
       "194     predator  role     pos_3            0.867048            -0.074169\n",
       "336      chimera  role     pos_3            0.888955            -0.074634\n",
       "290        exile  role     pos_3            0.871230            -0.075358\n",
       "243      luddite  role     pos_3            0.787089            -0.076158\n",
       "231  mycorrhizal  role     pos_3            0.852218            -0.078633\n",
       "109         wind  role     pos_3            0.873513            -0.079126\n",
       "285      flaneur  role     pos_3            0.893082            -0.080256\n",
       "183  provocateur  role     pos_3            0.839165            -0.080924\n",
       "158       shaman  role     pos_3            0.866307            -0.081136\n",
       "230       mystic  role     pos_3            0.875267            -0.083189\n",
       "261   homunculus  role     pos_3            0.880295            -0.096083\n",
       "320  crystalline  role     pos_3            0.837987            -0.096483\n",
       "111        whale  role     pos_3            0.865674            -0.098696\n",
       "203      pilgrim  role     pos_3            0.874064            -0.099074\n",
       "305      dreamer  role     pos_3            0.878789            -0.100025\n",
       "376   aberration  role     pos_3            0.868664            -0.102044\n",
       "185      prophet  role     pos_3            0.873673            -0.103063\n",
       "217       oracle  role     pos_3            0.872035            -0.104297\n",
       "126    trickster  role     pos_3            0.868010            -0.105226\n",
       "168        rogue  role     pos_3            0.851260            -0.105277\n",
       "345     bohemian  role     pos_3            0.856232            -0.109528\n",
       "251       jester  role     pos_3            0.812406            -0.112551\n",
       "276        golem  role     pos_3            0.853356            -0.113629\n",
       "172     revenant  role     pos_3            0.861850            -0.115594\n",
       "304         echo  role     pos_3            0.866393            -0.115656\n",
       "108        witch  role     pos_3            0.861482            -0.116523\n",
       "197         poet  role     pos_3            0.832950            -0.118651\n",
       "277        ghost  role     pos_3            0.870981            -0.119735\n",
       "265       hermit  role     pos_3            0.861498            -0.120373\n",
       "349         bard  role     pos_3            0.862576            -0.121733\n",
       "354      ascetic  role     pos_3            0.834632            -0.124436\n",
       "103       zealot  role     pos_3            0.766515            -0.129866\n",
       "105       wraith  role     pos_3            0.849069            -0.139864\n",
       "314        demon  role     pos_3            0.816017            -0.140048\n",
       "279        genie  role     pos_3            0.838406            -0.142917\n",
       "127         tree  role     pos_3            0.818532            -0.143231\n",
       "375    absurdist  role     pos_3            0.790939            -0.144481\n",
       "122      vampire  role     pos_3            0.823770            -0.149999\n",
       "114         void  role     pos_3            0.780103            -0.168217\n",
       "298     eldritch  role     pos_3            0.795911            -0.184012\n",
       "247    leviathan  role     pos_3            0.787183            -0.185045"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['role_type'] == 'pos_3'].sort_values(by='contrast_similarity', ascending=False).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_df.sort_values(by='default_similarity', ascending=False).to_csv(f\"./results/{model_name}/role_similarity.csv\", index=False)\n",
    "trait_df.sort_values(by='default_similarity', ascending=False).to_csv(f\"./results/{model_name}/trait_similarity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a60c5",
   "metadata": {},
   "source": [
    "## Behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "597d8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "traits_scores_path = f\"{base_dir}/traits/default_scores\"\n",
    "trait_scores = {}\n",
    "\n",
    "for file in os.listdir(traits_scores_path):\n",
    "    if file.endswith('.json'):\n",
    "        trait_name = file.replace('.json', '')\n",
    "        with open(os.path.join(traits_scores_path, file), 'r') as f:\n",
    "            scores = json.load(f)\n",
    "\n",
    "        numeric_scores = [v for v in scores.values() if isinstance(v, (int, float))]\n",
    "            \n",
    "        if numeric_scores:\n",
    "            mean_score = np.mean(numeric_scores)\n",
    "        else:\n",
    "            # If all values are non-numeric, use NaN\n",
    "            mean_score = np.nan\n",
    "\n",
    "        trait_scores[trait_name] = mean_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles_scores_path = f\"{base_dir}/roles/default_scores\"\n",
    "role_scores = {}\n",
    "\n",
    "for file in os.listdir(roles_scores_path):\n",
    "    if file.endswith('.json'):\n",
    "        role_name = file.replace('.json', '')\n",
    "        with open(os.path.join(roles_scores_path, file), 'r') as f:\n",
    "            scores = json.load(f)\n",
    "\n",
    "        numeric_scores = [v for v in scores.values() if isinstance(v, (int, float))]\n",
    "\n",
    "        # Remap: 0->0, 1->0, 2->1, 3->2\n",
    "        remapped = [0 if s in [0, 1] else (1 if s == 2 else 2) for s in numeric_scores]\n",
    "\n",
    "        # Count occurrences of each score\n",
    "        counts = {\n",
    "            'pos_0': numeric_scores.count(0),\n",
    "            'pos_1': numeric_scores.count(1),\n",
    "            'pos_2': numeric_scores.count(2),\n",
    "            'pos_3': numeric_scores.count(3),\n",
    "            'mean_score': sum(remapped) / (len(remapped) * 2) if remapped else np.nan\n",
    "        }\n",
    "\n",
    "        role_scores[role_name] = counts\n",
    "\n",
    "# Convert to DataFrame\n",
    "role_scores_df = pd.DataFrame.from_dict(role_scores, orient='index')\n",
    "role_scores_df.index.name = 'name'\n",
    "role_scores_df = role_scores_df.reset_index()\n",
    "\n",
    "print(role_scores_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74356ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trait rows with scores: 240\n",
      "           name role_type  default_similarity  contrast_similarity  pos_0  \\\n",
      "0     assistant     pos_3            0.999253            -0.020101      0   \n",
      "1   interpreter     pos_2            0.998760            -0.054107      0   \n",
      "2    generalist     pos_2            0.998374            -0.035637      0   \n",
      "3   facilitator     pos_2            0.998215            -0.037791      0   \n",
      "4  collaborator     pos_2            0.998125            -0.053676      0   \n",
      "\n",
      "   pos_1  pos_2  pos_3  \n",
      "0      0      4    196  \n",
      "1      5     63    132  \n",
      "2     39     83     78  \n",
      "3      3     55    142  \n",
      "4      1     61    138  \n"
     ]
    }
   ],
   "source": [
    "# Load CSVs\n",
    "role_df = pd.read_csv(f\"./results/{model_name}/role_similarity.csv\")\n",
    "trait_df = pd.read_csv(f\"./results/{model_name}/trait_similarity.csv\")\n",
    "\n",
    "# Add trait_score to trait_df\n",
    "trait_df['trait_score'] = trait_df['name'].map(trait_scores)\n",
    "\n",
    "# Merge role score counts into role_df\n",
    "role_df = role_df.merge(role_scores_df, on='name', how='left')\n",
    "\n",
    "# Save updated CSVs\n",
    "role_df.to_csv(f\"./results/{model_name}/role_similarity.csv\", index=False)\n",
    "trait_df.to_csv(f\"./results/{model_name}/trait_similarity.csv\", index=False)\n",
    "\n",
    "print(f\"Trait rows with scores: {trait_df['trait_score'].notna().sum()}\")\n",
    "print(role_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11v9gofixlq",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0sq0ri2hl",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "import json\n",
    "\n",
    "# Load separate CSVs\n",
    "role_df = pd.read_csv(f\"./results/{model_name}/role_similarity.csv\")\n",
    "trait_df = pd.read_csv(f\"./results/{model_name}/trait_similarity.csv\")\n",
    "trait_df = trait_df.dropna(subset=['trait_score'])\n",
    "role_df_with_scores = role_df.dropna(subset=['mean_score'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Correlation: default_similarity vs contrast_similarity\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Roles only\n",
    "pearson_roles, p_pearson_roles = pearsonr(role_df['default_similarity'], role_df['contrast_similarity'])\n",
    "spearman_roles, p_spearman_roles = spearmanr(role_df['default_similarity'], role_df['contrast_similarity'])\n",
    "print(f\"\\nRoles (n={len(role_df)}):\")\n",
    "print(f\"  Pearson:  r={pearson_roles:.4f}, p={p_pearson_roles:.2e}\")\n",
    "print(f\"  Spearman: ={spearman_roles:.4f}, p={p_spearman_roles:.2e}\")\n",
    "\n",
    "# Traits only\n",
    "pearson_traits, p_pearson_traits = pearsonr(trait_df['default_similarity'], trait_df['contrast_similarity'])\n",
    "spearman_traits, p_spearman_traits = spearmanr(trait_df['default_similarity'], trait_df['contrast_similarity'])\n",
    "print(f\"\\nTraits (n={len(trait_df)}):\")\n",
    "print(f\"  Pearson:  r={pearson_traits:.4f}, p={p_pearson_traits:.2e}\")\n",
    "print(f\"  Spearman: ={spearman_traits:.4f}, p={p_spearman_traits:.2e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Correlation: vector similarity vs behavioral score\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Roles: default_similarity vs mean_score\n",
    "pearson_default_role, p_default_role = pearsonr(role_df_with_scores['default_similarity'], role_df_with_scores['mean_score'])\n",
    "spearman_default_role, p_spearman_default_role = spearmanr(role_df_with_scores['default_similarity'], role_df_with_scores['mean_score'])\n",
    "print(f\"\\nRoles - default_similarity vs mean_score (n={len(role_df_with_scores)}):\")\n",
    "print(f\"  Pearson:  r={pearson_default_role:.4f}, p={p_default_role:.2e}\")\n",
    "print(f\"  Spearman: ={spearman_default_role:.4f}, p={p_spearman_default_role:.2e}\")\n",
    "\n",
    "# Roles: contrast_similarity vs mean_score\n",
    "pearson_contrast_role, p_contrast_role = pearsonr(role_df_with_scores['contrast_similarity'], role_df_with_scores['mean_score'])\n",
    "spearman_contrast_role, p_spearman_contrast_role = spearmanr(role_df_with_scores['contrast_similarity'], role_df_with_scores['mean_score'])\n",
    "print(f\"\\nRoles - contrast_similarity vs mean_score (n={len(role_df_with_scores)}):\")\n",
    "print(f\"  Pearson:  r={pearson_contrast_role:.4f}, p={p_contrast_role:.2e}\")\n",
    "print(f\"  Spearman: ={spearman_contrast_role:.4f}, p={p_spearman_contrast_role:.2e}\")\n",
    "\n",
    "# Traits: default_similarity vs trait_score\n",
    "pearson_default_trait, p_default_trait = pearsonr(trait_df['default_similarity'], trait_df['trait_score'])\n",
    "spearman_default_trait, p_spearman_default_trait = spearmanr(trait_df['default_similarity'], trait_df['trait_score'])\n",
    "print(f\"\\nTraits - default_similarity vs trait_score (n={len(trait_df)}):\")\n",
    "print(f\"  Pearson:  r={pearson_default_trait:.4f}, p={p_default_trait:.2e}\")\n",
    "print(f\"  Spearman: ={spearman_default_trait:.4f}, p={p_spearman_default_trait:.2e}\")\n",
    "\n",
    "# Traits: contrast_similarity vs trait_score\n",
    "pearson_contrast_trait, p_contrast_trait = pearsonr(trait_df['contrast_similarity'], trait_df['trait_score'])\n",
    "spearman_contrast_trait, p_spearman_contrast_trait = spearmanr(trait_df['contrast_similarity'], trait_df['trait_score'])\n",
    "print(f\"\\nTraits - contrast_similarity vs trait_score (n={len(trait_df)}):\")\n",
    "print(f\"  Pearson:  r={pearson_contrast_trait:.4f}, p={p_contrast_trait:.2e}\")\n",
    "print(f\"  Spearman: ={spearman_contrast_trait:.4f}, p={p_spearman_contrast_trait:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2679483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "results = {\n",
    "    \"default_vs_contrast\": {\n",
    "        \"roles\": {\n",
    "            \"n\": len(role_df),\n",
    "            \"pearson\": {\"r\": pearson_roles, \"p\": p_pearson_roles},\n",
    "            \"spearman\": {\"rho\": spearman_roles, \"p\": p_spearman_roles}\n",
    "        },\n",
    "        \"traits\": {\n",
    "            \"n\": len(trait_df),\n",
    "            \"pearson\": {\"r\": pearson_traits, \"p\": p_pearson_traits},\n",
    "            \"spearman\": {\"rho\": spearman_traits, \"p\": p_spearman_traits}\n",
    "        }\n",
    "    },\n",
    "    \"vector_similarity_vs_behavioral_score\": {\n",
    "        \"roles\": {\n",
    "            \"default_similarity\": {\n",
    "                \"n\": len(role_df_with_scores),\n",
    "                \"pearson\": {\"r\": pearson_default_role, \"p\": p_default_role},\n",
    "                \"spearman\": {\"rho\": spearman_default_role, \"p\": p_spearman_default_role}\n",
    "            },\n",
    "            \"contrast_similarity\": {\n",
    "                \"n\": len(role_df_with_scores),\n",
    "                \"pearson\": {\"r\": pearson_contrast_role, \"p\": p_contrast_role},\n",
    "                \"spearman\": {\"rho\": spearman_contrast_role, \"p\": p_spearman_contrast_role}\n",
    "            }\n",
    "        },\n",
    "        \"traits\": {\n",
    "            \"default_similarity\": {\n",
    "                \"n\": len(trait_df),\n",
    "                \"pearson\": {\"r\": pearson_default_trait, \"p\": p_default_trait},\n",
    "                \"spearman\": {\"rho\": spearman_default_trait, \"p\": p_spearman_default_trait}\n",
    "            },\n",
    "            \"contrast_similarity\": {\n",
    "                \"n\": len(trait_df),\n",
    "                \"pearson\": {\"r\": pearson_contrast_trait, \"p\": p_contrast_trait},\n",
    "                \"spearman\": {\"rho\": spearman_contrast_trait, \"p\": p_spearman_contrast_trait}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"./results/{model_name}/correlation_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Saved correlation results to ./results/{model_name}/correlation_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06gpjhb5zqdf",
   "metadata": {},
   "source": [
    "## Role PC similarity with traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bm9qrgx1p1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PC1 - Top 10 traits (most similar)\n",
      "============================================================\n",
      "       trait      PC1\n",
      "   enigmatic 0.762524\n",
      "    ethereal 0.758917\n",
      "    romantic 0.743763\n",
      "    mystical 0.731033\n",
      "     cryptic 0.722849\n",
      "   whimsical 0.721664\n",
      " spontaneous 0.694479\n",
      "melodramatic 0.670557\n",
      "    dramatic 0.652410\n",
      "   grandiose 0.625320\n",
      "\n",
      "PC1 - Bottom 10 traits (most dissimilar)\n",
      "------------------------------------------------------------\n",
      "       trait       PC1\n",
      " transparent -0.657656\n",
      "     factual -0.596230\n",
      "    moderate -0.539773\n",
      "    grounded -0.507743\n",
      "conciliatory -0.506993\n",
      "        calm -0.487453\n",
      "  diplomatic -0.482365\n",
      "  methodical -0.470943\n",
      "    reserved -0.450273\n",
      "  analytical -0.437280\n",
      "\n",
      "============================================================\n",
      "PC2 - Top 10 traits (most similar)\n",
      "============================================================\n",
      "       trait      PC2\n",
      "    reactive 0.716139\n",
      "      casual 0.715274\n",
      "    visceral 0.701328\n",
      "   impulsive 0.652146\n",
      "    flippant 0.642449\n",
      "  irreverent 0.637775\n",
      "       petty 0.587813\n",
      "disorganized 0.582317\n",
      "    neurotic 0.581644\n",
      "  nonchalant 0.569046\n",
      "\n",
      "PC2 - Bottom 10 traits (most dissimilar)\n",
      "------------------------------------------------------------\n",
      "        trait       PC2\n",
      "  calculating -0.785651\n",
      "   meticulous -0.751580\n",
      "       solemn -0.729281\n",
      "       formal -0.726656\n",
      "perfectionist -0.718035\n",
      "    strategic -0.675193\n",
      "conscientious -0.673380\n",
      "  introverted -0.670442\n",
      "structuralist -0.667513\n",
      "      serious -0.666409\n",
      "\n",
      "============================================================\n",
      "PC3 - Top 10 traits (most similar)\n",
      "============================================================\n",
      "          trait      PC3\n",
      "     empathetic 0.562218\n",
      "     humanistic 0.526990\n",
      "    qualitative 0.517327\n",
      "      emotional 0.496796\n",
      "      intuitive 0.430652\n",
      "improvisational 0.404292\n",
      "     gregarious 0.396389\n",
      "       pacifist 0.392126\n",
      "    charismatic 0.382902\n",
      "    big_picture 0.348312\n",
      "\n",
      "PC3 - Bottom 10 traits (most dissimilar)\n",
      "------------------------------------------------------------\n",
      "        trait       PC3\n",
      "     detached -0.564243\n",
      "  rationalist -0.557727\n",
      "dispassionate -0.513193\n",
      "  data_driven -0.474960\n",
      "    formalist -0.464976\n",
      "  materialist -0.458151\n",
      "     reserved -0.436941\n",
      "      literal -0.429593\n",
      "  descriptive -0.417788\n",
      " quantitative -0.393255\n",
      "\n",
      "============================================================\n",
      "PC4 - Top 10 traits (most similar)\n",
      "============================================================\n",
      "          trait      PC4\n",
      "confrontational 0.584644\n",
      "        cynical 0.540251\n",
      "   iconoclastic 0.510405\n",
      "       militant 0.497754\n",
      "        callous 0.495009\n",
      "          cruel 0.479679\n",
      "         savage 0.475747\n",
      "        acerbic 0.468334\n",
      "    competitive 0.468149\n",
      "        hostile 0.461098\n",
      "\n",
      "PC4 - Bottom 10 traits (most dissimilar)\n",
      "------------------------------------------------------------\n",
      "       trait       PC4\n",
      "   agreeable -0.511738\n",
      "   forgiving -0.491897\n",
      "  benevolent -0.473749\n",
      "     tactful -0.473364\n",
      "conciliatory -0.467294\n",
      "       chill -0.429274\n",
      "    moderate -0.427073\n",
      "  meditative -0.400031\n",
      "  diplomatic -0.397227\n",
      "       naive -0.384403\n",
      "\n",
      "============================================================\n",
      "PC5 - Top 10 traits (most similar)\n",
      "============================================================\n",
      "            trait      PC5\n",
      "      provocative 0.373445\n",
      "       subversive 0.364909\n",
      "     iconoclastic 0.360388\n",
      "         socratic 0.355818\n",
      "       contrarian 0.330698\n",
      "       nihilistic 0.296128\n",
      "         critical 0.295495\n",
      "      challenging 0.290079\n",
      "deconstructionist 0.278837\n",
      "       rebellious 0.272678\n",
      "\n",
      "PC5 - Bottom 10 traits (most dissimilar)\n",
      "------------------------------------------------------------\n",
      "          trait       PC5\n",
      "       grounded -0.233339\n",
      "   experiential -0.214020\n",
      "closure_seeking -0.213974\n",
      "    traditional -0.212741\n",
      "     optimistic -0.211247\n",
      "       flexible -0.207296\n",
      "       decisive -0.197018\n",
      "  inspirational -0.195949\n",
      "problem_solving -0.194909\n",
      "systems_thinker -0.180997\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "# Get top 5 role PCs\n",
    "role_pcs = torch.tensor(role_results['pca'].components_[:5]).float()  # Shape: [5, hidden_dim]\n",
    "\n",
    "# Get trait vectors at the specified layer\n",
    "trait_vecs = trait_vectors[:, layer, :].float()  # Shape: [n_traits, hidden_dim]\n",
    "\n",
    "# Normalize both for cosine similarity\n",
    "role_pcs_norm = F.normalize(role_pcs, dim=-1)  # Shape: [5, hidden_dim]\n",
    "trait_vecs_norm = F.normalize(trait_vecs, dim=-1)  # Shape: [n_traits, hidden_dim]\n",
    "\n",
    "# Compute cosine similarity: [n_traits, 5]\n",
    "similarities = trait_vecs_norm @ role_pcs_norm.T\n",
    "\n",
    "# Create dataframe with similarities\n",
    "pc_sim_df = pd.DataFrame({\n",
    "    'trait': trait_labels,\n",
    "    'PC1': similarities[:, 0].numpy(),\n",
    "    'PC2': similarities[:, 1].numpy(),\n",
    "    'PC3': similarities[:, 2].numpy(),\n",
    "    'PC4': similarities[:, 3].numpy(),\n",
    "    'PC5': similarities[:, 4].numpy(),\n",
    "})\n",
    "\n",
    "# Print top 10 and bottom 10 for each PC\n",
    "for i in range(5):\n",
    "    pc_col = f'PC{i+1}'\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{pc_col} - Top 10 traits (most similar)\")\n",
    "    print(\"=\"*60)\n",
    "    print(pc_sim_df.nlargest(10, pc_col)[['trait', pc_col]].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n{pc_col} - Bottom 10 traits (most dissimilar)\")\n",
    "    print(\"-\"*60)\n",
    "    print(pc_sim_df.nsmallest(10, pc_col)[['trait', pc_col]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "jzfnhrmgqpl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ./results/llama-3.3-70b/role_pc_trait_similarity.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the PC similarity dataframe\n",
    "pc_sim_df.to_csv(f\"./results/{model_name}/role_pc_trait_similarity.csv\", index=False)\n",
    "print(f\"Saved to ./results/{model_name}/role_pc_trait_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e401eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in csv for all 3 models\n",
    "models = [\n",
    "    'gemma-2-27b',\n",
    "    'qwen-3-32b',\n",
    "    'llama-3.3-70b',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "uo2tytsuhrf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gemma-2-27b\n",
      "============================================================\n",
      "\n",
      "PC1 - Top 5:\n",
      "        trait      PC1\n",
      "      factual 0.873635\n",
      "   methodical 0.812940\n",
      "  transparent 0.794871\n",
      "     moderate 0.746195\n",
      "structuralist 0.743175\n",
      "\n",
      "PC1 - Bottom 5:\n",
      "    trait       PC1\n",
      " romantic -0.877956\n",
      "enigmatic -0.827663\n",
      " ethereal -0.802732\n",
      "  cryptic -0.794250\n",
      "obsessive -0.780832\n",
      "\n",
      "PC2 - Top 5:\n",
      "   trait      PC2\n",
      "   stoic 0.705741\n",
      " serious 0.671351\n",
      "detached 0.647201\n",
      "  formal 0.612947\n",
      "reserved 0.607707\n",
      "\n",
      "PC2 - Bottom 5:\n",
      "          trait       PC2\n",
      "     gregarious -0.679885\n",
      "improvisational -0.677909\n",
      "         casual -0.632634\n",
      "     irreverent -0.586699\n",
      "     empathetic -0.582980\n",
      "\n",
      "PC3 - Top 5:\n",
      "       trait      PC3\n",
      "    grounded 0.539665\n",
      "   practical 0.506593\n",
      "experiential 0.422742\n",
      "reductionist 0.399932\n",
      "       naive 0.396455\n",
      "\n",
      "PC3 - Bottom 5:\n",
      "      trait       PC3\n",
      "   abstract -0.611486\n",
      "introverted -0.607227\n",
      " conceptual -0.587547\n",
      "big_picture -0.535779\n",
      "    erudite -0.532346\n",
      "\n",
      "qwen-3-32b\n",
      "============================================================\n",
      "\n",
      "PC1 - Top 5:\n",
      "      trait      PC1\n",
      " methodical 0.876927\n",
      "    factual 0.846249\n",
      "       calm 0.817309\n",
      "transparent 0.800275\n",
      " analytical 0.735930\n",
      "\n",
      "PC1 - Bottom 5:\n",
      "      trait       PC1\n",
      "spontaneous -0.894961\n",
      "   romantic -0.880118\n",
      "   ethereal -0.870564\n",
      "  mercurial -0.867403\n",
      "     flirty -0.865662\n",
      "\n",
      "PC2 - Top 5:\n",
      "       trait      PC2\n",
      "    grounded 0.651561\n",
      "      casual 0.650491\n",
      "   practical 0.595664\n",
      "experiential 0.512059\n",
      "     anxious 0.510550\n",
      "\n",
      "PC2 - Bottom 5:\n",
      "      trait       PC2\n",
      "introverted -0.739818\n",
      "ritualistic -0.707567\n",
      "    erudite -0.677845\n",
      "   eloquent -0.670648\n",
      "   abstract -0.663974\n",
      "\n",
      "PC3 - Top 5:\n",
      "      trait      PC3\n",
      "    cynical 0.717271\n",
      "    callous 0.655408\n",
      "      blunt 0.601381\n",
      "    acerbic 0.594840\n",
      "competitive 0.594252\n",
      "\n",
      "PC3 - Bottom 5:\n",
      "     trait       PC3\n",
      "benevolent -0.724068\n",
      " forgiving -0.708526\n",
      "humanistic -0.695770\n",
      " nurturing -0.610145\n",
      "meditative -0.601366\n",
      "\n",
      "llama-3.3-70b\n",
      "============================================================\n",
      "\n",
      "PC1 - Top 5:\n",
      "    trait      PC1\n",
      "enigmatic 0.762524\n",
      " ethereal 0.758917\n",
      " romantic 0.743763\n",
      " mystical 0.731033\n",
      "  cryptic 0.722849\n",
      "\n",
      "PC1 - Bottom 5:\n",
      "       trait       PC1\n",
      " transparent -0.657656\n",
      "     factual -0.596230\n",
      "    moderate -0.539772\n",
      "    grounded -0.507743\n",
      "conciliatory -0.506993\n",
      "\n",
      "PC2 - Top 5:\n",
      "    trait      PC2\n",
      " reactive 0.716139\n",
      "   casual 0.715274\n",
      " visceral 0.701328\n",
      "impulsive 0.652146\n",
      " flippant 0.642449\n",
      "\n",
      "PC2 - Bottom 5:\n",
      "        trait       PC2\n",
      "  calculating -0.785651\n",
      "   meticulous -0.751580\n",
      "       solemn -0.729281\n",
      "       formal -0.726656\n",
      "perfectionist -0.718035\n",
      "\n",
      "PC3 - Top 5:\n",
      "      trait      PC3\n",
      " empathetic 0.562218\n",
      " humanistic 0.526990\n",
      "qualitative 0.517327\n",
      "  emotional 0.496796\n",
      "  intuitive 0.430652\n",
      "\n",
      "PC3 - Bottom 5:\n",
      "        trait       PC3\n",
      "     detached -0.564243\n",
      "  rationalist -0.557727\n",
      "dispassionate -0.513193\n",
      "  data_driven -0.474960\n",
      "    formalist -0.464976\n"
     ]
    }
   ],
   "source": [
    "# Load PC similarity CSVs for all models\n",
    "pc_sim_dfs = {}\n",
    "for model in models:\n",
    "    pc_sim_dfs[model] = pd.read_csv(f\"./results/{model}/role_pc_trait_similarity.csv\")\n",
    "\n",
    "# Print top N traits for qwen PC1-3 and gemma PC2-3\n",
    "N = 5\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n{model}\")\n",
    "    print(\"=\"*60)\n",
    "    for pc in ['PC1', 'PC2', 'PC3']:\n",
    "        print(f\"\\n{pc} - Top {N}:\")\n",
    "        print(pc_sim_dfs[model].nlargest(N, pc)[['trait', pc]].to_string(index=False))\n",
    "        print(f\"\\n{pc} - Bottom {N}:\")\n",
    "        print(pc_sim_dfs[model].nsmallest(N, pc)[['trait', pc]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ixb0s2z925l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Edit this cell to change what gets plotted\n",
    "# ============================================================\n",
    "\n",
    "N = 5  # Number of traits to use from each PC\n",
    "\n",
    "# Define axes: (model, pc, end) where end is 'top' or 'bottom'\n",
    "# Each tuple becomes one axis on the radial plot\n",
    "plot_axes = [\n",
    "    ('qwen-3-32b', 'PC1', 'top'),       # analytical, calm, factual, methodical, transparent\n",
    "    ('qwen-3-32b', 'PC3', 'bottom'),    # benevolent, forgiving, humanistic, meditative, nurturing\n",
    "    ('gemma-2-27b', 'PC2', 'top'),   # casual, empathetic, gregarious, improvisational, irreverent\n",
    "    ('gemma-2-27b', 'PC3', 'bottom'),      # experiential, grounded, naive, practical, reductionist\n",
    "    ('qwen-3-32b', 'PC2', 'bottom'),    # abstract, eloquent, erudite, introverted, ritualistic\n",
    "]\n",
    "\n",
    "# Labels for each axis (customize as needed)\n",
    "axis_labels = [\n",
    "    'Assistant-like',\n",
    "    'Supportive', \n",
    "    'Systematic',\n",
    "    'Pedagogical',\n",
    "    'Individualistic',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "am53vgfap8n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded behavioral scores for 3 models\n"
     ]
    }
   ],
   "source": [
    "# Load behavioral trait scores for all 3 models\n",
    "import json\n",
    "behavioral_scores = {}\n",
    "\n",
    "for model in models:\n",
    "    model_scores_path = f'/workspace/{model}/traits/default_scores'\n",
    "    model_data = {}\n",
    "    \n",
    "    for file in os.listdir(model_scores_path):\n",
    "        if file.endswith('.json'):\n",
    "            trait_name = file.replace('.json', '')\n",
    "            with open(os.path.join(model_scores_path, file), 'r') as f:\n",
    "                scores = json.load(f)\n",
    "            \n",
    "            numeric_scores = [v for v in scores.values() if isinstance(v, (int, float))]\n",
    "            if numeric_scores:\n",
    "                model_data[trait_name] = np.mean(numeric_scores)\n",
    "            else:\n",
    "                model_data[trait_name] = np.nan\n",
    "    \n",
    "    behavioral_scores[model] = model_data\n",
    "\n",
    "print(f\"Loaded behavioral scores for {len(models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ovy6j2vdri",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen-3-32b PC1 (top): ['methodical', 'factual', 'calm', 'transparent', 'analytical']\n",
      "qwen-3-32b PC3 (bottom): ['benevolent', 'forgiving', 'humanistic', 'nurturing', 'meditative']\n",
      "gemma-2-27b PC2 (top): ['stoic', 'serious', 'detached', 'formal', 'reserved']\n",
      "gemma-2-27b PC3 (bottom): ['abstract', 'introverted', 'conceptual', 'big_picture', 'erudite']\n",
      "qwen-3-32b PC2 (bottom): ['introverted', 'ritualistic', 'erudite', 'eloquent', 'abstract']\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "rgb(31, 119, 180)"
         },
         "name": "gemma-2-27b",
         "r": [
          92.68499999999999,
          85.615,
          80.59,
          70.385,
          64.08500000000001,
          92.68499999999999
         ],
         "theta": [
          "Assistant-like",
          "Supportive",
          "Systematic",
          "Pedagogical",
          "Individualistic",
          "Assistant-like"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "rgb(255, 127, 14)"
         },
         "name": "qwen-3-32b",
         "r": [
          94.27000000000001,
          86.951,
          76.745,
          75.66,
          73.197,
          94.27000000000001
         ],
         "theta": [
          "Assistant-like",
          "Supportive",
          "Systematic",
          "Pedagogical",
          "Individualistic",
          "Assistant-like"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "rgb(44, 160, 44)"
         },
         "name": "llama-3.3-70b",
         "r": [
          92.60999999999999,
          86.19500000000001,
          78.405,
          66.60000000000001,
          62.916999999999994,
          92.60999999999999
         ],
         "theta": [
          "Assistant-like",
          "Supportive",
          "Systematic",
          "Pedagogical",
          "Individualistic",
          "Assistant-like"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "height": 500,
        "polar": {
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "showticklabels": false
         }
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Default Behavior Scores for Role PC Traits"
        },
        "width": 600
       }
      },
      "text/html": [
       "<div>                            <div id=\"05fb4d7c-91b3-41a5-a937-9e94f82cc5b4\" class=\"plotly-graph-div\" style=\"height:500px; width:600px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"05fb4d7c-91b3-41a5-a937-9e94f82cc5b4\")) {                    Plotly.newPlot(                        \"05fb4d7c-91b3-41a5-a937-9e94f82cc5b4\",                        [{\"line\":{\"color\":\"rgb(31, 119, 180)\"},\"name\":\"gemma-2-27b\",\"r\":[92.68499999999999,85.615,80.59,70.385,64.08500000000001,92.68499999999999],\"theta\":[\"Assistant-like\",\"Supportive\",\"Systematic\",\"Pedagogical\",\"Individualistic\",\"Assistant-like\"],\"type\":\"scatterpolar\"},{\"line\":{\"color\":\"rgb(255, 127, 14)\"},\"name\":\"qwen-3-32b\",\"r\":[94.27000000000001,86.951,76.745,75.66,73.197,94.27000000000001],\"theta\":[\"Assistant-like\",\"Supportive\",\"Systematic\",\"Pedagogical\",\"Individualistic\",\"Assistant-like\"],\"type\":\"scatterpolar\"},{\"line\":{\"color\":\"rgb(44, 160, 44)\"},\"name\":\"llama-3.3-70b\",\"r\":[92.60999999999999,86.19500000000001,78.405,66.60000000000001,62.916999999999994,92.60999999999999],\"theta\":[\"Assistant-like\",\"Supportive\",\"Systematic\",\"Pedagogical\",\"Individualistic\",\"Assistant-like\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"radialaxis\":{\"range\":[0,100],\"showticklabels\":false}},\"title\":{\"text\":\"Default Behavior Scores for Role PC Traits\"},\"height\":500,\"width\":600,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('05fb4d7c-91b3-41a5-a937-9e94f82cc5b4');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Get traits for each axis based on configuration\n",
    "axis_traits = []\n",
    "for source_model, pc, end in plot_axes:\n",
    "    df = pc_sim_dfs[source_model]\n",
    "    if end == 'top':\n",
    "        traits = df.nlargest(N, pc)['trait'].tolist()\n",
    "    else:\n",
    "        traits = df.nsmallest(N, pc)['trait'].tolist()\n",
    "    axis_traits.append(traits)\n",
    "    print(f\"{source_model} {pc} ({end}): {traits}\")\n",
    "\n",
    "# Calculate mean behavioral score for each axis for each model\n",
    "plot_data = {model: [] for model in models}\n",
    "\n",
    "for axis_idx, traits in enumerate(axis_traits):\n",
    "    for model in models:\n",
    "        scores = [behavioral_scores[model].get(t, np.nan) for t in traits]\n",
    "        mean_score = np.nanmean(scores)\n",
    "        plot_data[model].append(mean_score)\n",
    "\n",
    "# Create radial plot\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = ['rgb(31, 119, 180)', 'rgb(255, 127, 14)', 'rgb(44, 160, 44)']\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    values = plot_data[model] + [plot_data[model][0]]  # Close the polygon\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=axis_labels + [axis_labels[0]],\n",
    "        name=model,\n",
    "        line=dict(color=colors[idx])\n",
    "    ))\n",
    "\n",
    "fig.update_polars(\n",
    "    radialaxis=dict(\n",
    "        range=[0, 100],\n",
    "        showticklabels=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Default Behavior Scores for Role PC Traits\",\n",
    "    height=500,\n",
    "    width=600,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e29a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
