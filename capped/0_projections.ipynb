{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58bef749",
   "metadata": {},
   "source": [
    "# Projections across different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5849fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.pca_utils import L2MeanScaler, MeanScaler\n",
    "from utils.inference_utils import *\n",
    "from utils.probing_utils import *\n",
    "from utils.steering_utils import *\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama-3.3-70b\"\n",
    "layer = 40\n",
    "total_layers = 80\n",
    "base_dir = f\"/workspace/{model_name}\"\n",
    "\n",
    "output_file = f\"{base_dir}/capped/configs/multi_contrast_vectors.pt\"\n",
    "\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "plot_dir = f\"/root/git/plots/{model_name}/capped/projections\"\n",
    "os.makedirs(plot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b06e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and project default onto the vectors\n",
    "default_vectors = torch.load(f\"{base_dir}/roles_240/default_vectors.pt\", weights_only=False)\n",
    "contrast_vectors = torch.load(output_file, weights_only=False)\n",
    "\n",
    "# Get default activations (shape: [64, 5120] - one per layer)\n",
    "assistant_layer_activation = default_vectors['activations']['default_1'].float()\n",
    "\n",
    "# Stack all contrast vectors into a single tensor (shape: [64, 5120])\n",
    "contrast_vecs_stacked = torch.stack([cv['vector'].float() for cv in contrast_vectors])\n",
    "\n",
    "# L2 normalize all contrast vectors at once\n",
    "contrast_vecs_normalized = contrast_vecs_stacked / contrast_vecs_stacked.norm(p=2, dim=1, keepdim=True)\n",
    "\n",
    "# Vectorized projection: element-wise multiply and sum along feature dimension\n",
    "# This computes all 64 dot products at once (shape: [64])\n",
    "default_projections = (assistant_layer_activation * contrast_vecs_normalized).sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e6d92",
   "metadata": {},
   "source": [
    "## Role/trait rollout projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_file = f\"{base_dir}/capped/projections/roles_projections.jsonl\"\n",
    "trait_file = f\"{base_dir}/capped/projections/traits_projections.jsonl\"\n",
    "\n",
    "# Load each file directly into pandas\n",
    "df_role = pd.read_json(role_file, lines=True)\n",
    "df_trait = pd.read_json(trait_file, lines=True)\n",
    "\n",
    "# Add source_file column to track origin\n",
    "df_role['source_file'] = 'role'\n",
    "df_trait['source_file'] = 'trait'\n",
    "\n",
    "# Concatenate the dataframes\n",
    "df_rt = pd.concat([df_role, df_trait], ignore_index=True)\n",
    "\n",
    "# Add type column based on source file, name format, and prompt_label\n",
    "def determine_type(row):\n",
    "    # Check if prompt_label is default\n",
    "    if row.get('prompt_label') == 'default':\n",
    "        return 'default'\n",
    "    \n",
    "    # Check if name matches {integer}_default format\n",
    "    if isinstance(row['role'], str) and '_default' in row['role']:\n",
    "        parts = row['role'].split('_')\n",
    "        if len(parts) == 2 and parts[0].isdigit() and parts[1] == 'default':\n",
    "            return 'default'\n",
    "    \n",
    "    # Otherwise use source file\n",
    "    return row['source_file']\n",
    "\n",
    "df_rt['type'] = df_rt.apply(determine_type, axis=1)\n",
    "\n",
    "# Remove the temporary source_file column\n",
    "df_rt = df_rt.drop('source_file', axis=1)\n",
    "\n",
    "# Display the type distribution\n",
    "print(\"Type distribution:\")\n",
    "print(df_rt['type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5zlzm4ibf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand projections into separate columns\n",
    "projections_df = pd.json_normalize(df_rt['projections'])\n",
    "df_rt = pd.concat([df_rt.drop('projections', axis=1), projections_df], axis=1)\n",
    "\n",
    "print(f\"Expanded shape: {df_rt.shape}\")\n",
    "print(f\"\\nSample projection columns: {[col for col in df_rt.columns if col.startswith('layer_')][:5]}\")\n",
    "print(f\"\\nDataFrame info:\")\n",
    "print(f\"  - Types: {df_rt['type'].value_counts().to_dict()}\")\n",
    "print(f\"  - Score distribution: {df_rt['score'].value_counts(dropna=False).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad84a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_scores(df):\n",
    "    \"\"\"\n",
    "    Add a score_bin column to the dataframe that bins scores consistently:\n",
    "    - Bin 0: Role score 0, Trait 0-25, Default (all)\n",
    "    - Bin 1: Role score 1, Trait 25-50\n",
    "    - Bin 2: Role score 2, Trait 50-75\n",
    "    - Bin 3: Role score 3, Trait 75-100\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing 'type' and 'score' columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with added 'score_bin' column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle REFUSAL and null scores\n",
    "    df['score'] = df['score'].replace('REFUSAL', 0)\n",
    "    df['score'] = df['score'].fillna(-1)\n",
    "    df['score'] = df['score'].astype(int)\n",
    "    \n",
    "    # Create binned score column\n",
    "    def bin_score(row):\n",
    "        if row['type'] == 'role':\n",
    "            # Role scores are already 0-3\n",
    "            return row['score']\n",
    "        elif row['type'] == 'trait':\n",
    "            # Bin trait scores: 0-25 -> 0, 25-50 -> 1, 50-75 -> 2, 75-100 -> 3\n",
    "            if row['score'] < 25:\n",
    "                return 0\n",
    "            elif row['score'] < 50:\n",
    "                return 1\n",
    "            elif row['score'] < 75:\n",
    "                return 2\n",
    "            else:\n",
    "                return 3\n",
    "        else:  # default\n",
    "            # All defaults go to bin 0\n",
    "            return 0\n",
    "    \n",
    "    df['score_bin'] = df.apply(bin_score, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6tuuah04mjd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin the scores\n",
    "df_rt_binned = bin_scores(df_rt)\n",
    "\n",
    "print(f\"Score bin distribution:\")\n",
    "print(df_rt_binned['score_bin'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xos9xxr3xp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_projection_stats(df, percentiles=[1, 5, 10, 25, 50, 75, 90, 95, 99]):\n",
    "    \"\"\"\n",
    "    Compute statistics for all projection columns in the role/trait dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing projection columns (columns starting with 'layer_')\n",
    "    percentiles : list, optional\n",
    "        List of percentile values to compute (default: [1, 5, 10, 25, 50, 75, 90, 95, 99])\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with structure matching chat dataset JSON format:\n",
    "        {\n",
    "            'per_vector_stats': {\n",
    "                'layer_X/vector_name': {\n",
    "                    'count': int,\n",
    "                    'mean': float,\n",
    "                    'std': float,\n",
    "                    'min': float,\n",
    "                    'max': float,\n",
    "                    'percentiles': {\n",
    "                        '1': float,\n",
    "                        '5': float,\n",
    "                        ...\n",
    "                    }\n",
    "                },\n",
    "                ...\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Get all projection columns (columns starting with 'layer_')\n",
    "    projection_cols = [col for col in df.columns if col.startswith('layer_')]\n",
    "    \n",
    "    if not projection_cols:\n",
    "        raise ValueError(\"No projection columns found (columns starting with 'layer_')\")\n",
    "    \n",
    "    per_vector_stats = {}\n",
    "    \n",
    "    for col in projection_cols:\n",
    "        # Get non-null values for this column\n",
    "        values = df[col].dropna()\n",
    "        \n",
    "        if len(values) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Compute statistics\n",
    "        stats = {\n",
    "            'count': int(len(values)),\n",
    "            'mean': float(values.mean()),\n",
    "            'std': float(values.std()),\n",
    "            'min': float(values.min()),\n",
    "            'max': float(values.max()),\n",
    "            'percentiles': {}\n",
    "        }\n",
    "        \n",
    "        # Compute percentiles\n",
    "        for p in percentiles:\n",
    "            stats['percentiles'][str(p)] = float(np.percentile(values, p))\n",
    "        \n",
    "        per_vector_stats[col] = stats\n",
    "    \n",
    "    return {'per_vector_stats': per_vector_stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4lqccta93wt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics for role/trait projections\n",
    "rt_stats = compute_projection_stats(df_rt_binned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67679f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display sample stats for one layer\n",
    "# layer = 32\n",
    "vector_name = f'layer_{layer}/contrast_role_pos3_default1'\n",
    "sample_stats = rt_stats['per_vector_stats'][vector_name]\n",
    "\n",
    "print(f\"Statistics for {vector_name}:\")\n",
    "print(f\"  Count: {sample_stats['count']:,}\")\n",
    "print(f\"  Mean: {sample_stats['mean']:.6f}\")\n",
    "print(f\"  Std: {sample_stats['std']:.6f}\")\n",
    "print(f\"  Min: {sample_stats['min']:.6f}\")\n",
    "print(f\"  Max: {sample_stats['max']:.6f}\")\n",
    "print(f\"  Percentiles:\")\n",
    "for p, val in sample_stats['percentiles'].items():\n",
    "    print(f\"    p{p}: {val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "up4l2wulqc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_score_histogram(df, vector_name, title, subtitle, stats_data, nbinsx=50, default_projection=None):\n",
    "    \"\"\"\n",
    "    Create a histogram of projections colored by score bins, with bars overlaid by score.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing projection column and 'score_bin' column\n",
    "    projection_col : str\n",
    "        Name of the projection column to plot\n",
    "    title : str, optional\n",
    "        Title for the plot\n",
    "    nbinsx : int, optional\n",
    "        Number of bins for histogram (default: 50)\n",
    "    default_projection : float, optional\n",
    "        Default projection value to show as a vertical line\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    plotly.graph_objects.Figure\n",
    "    \"\"\"\n",
    "    if vector_name not in df.columns:\n",
    "        raise ValueError(f\"Projection column {vector_name} not found in dataframe\")\n",
    "    \n",
    "    if 'score_bin' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'score_bin' column. Call bin_scores() first.\")\n",
    "    \n",
    "    # Bin labels and colors\n",
    "    bin_labels = {\n",
    "        0: 'None (0-25)',\n",
    "        1: 'Slightly (25-50)',\n",
    "        2: 'Somewhat (50-75)',\n",
    "        3: 'Fully (75-100)'\n",
    "    }\n",
    "    \n",
    "    bin_colors = {\n",
    "        0: '#e74c3c',  # red\n",
    "        1: '#3498db',  # blue\n",
    "        2: '#f39c12',  # orange\n",
    "        3: '#2ecc71'   # green\n",
    "    }\n",
    "    stats = stats_data['per_vector_stats'][vector_name]\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add traces for each bin\n",
    "    for bin_val in sorted(df['score_bin'].unique()):\n",
    "        if bin_val == -1:\n",
    "            continue\n",
    "            \n",
    "        data = df[df['score_bin'] == bin_val][vector_name]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=data,\n",
    "                name=bin_labels.get(bin_val, str(bin_val)),\n",
    "                marker_color=bin_colors.get(bin_val, '#95a5a6'),\n",
    "                opacity=0.6,\n",
    "                nbinsx=nbinsx\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Add percentile lines\n",
    "    percentiles = stats['percentiles']\n",
    "    # Add percentile lines with red annotations at top-left\n",
    "    for pct, value in percentiles.items():\n",
    "        fig.add_vline(\n",
    "            x=value,\n",
    "            line_width=1,\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"red\",\n",
    "            opacity=0.5,\n",
    "            annotation=dict(\n",
    "                text=f\"p{pct}:<br>{value:.1f}\",\n",
    "                align=\"right\",\n",
    "                font=dict(color=\"red\", size=9),\n",
    "                xanchor=\"right\",   # position text to the left of the line\n",
    "                yanchor=\"top\", # anchor text to bottom so it sits within the plot area\n",
    "                y=1,              # normalized coordinate (top of plot)\n",
    "                yref=\"paper\",     # relative to the full plot height\n",
    "                showarrow=False,\n",
    "                opacity=0.5\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Add default projection line if provided\n",
    "    if default_projection is not None:\n",
    "        fig.add_vline(\n",
    "            x=default_projection,\n",
    "            line_width=2,\n",
    "            line_dash=\"solid\",\n",
    "            line_color=\"black\",\n",
    "            opacity=0.8,\n",
    "            annotation=dict(\n",
    "                text=f\"Default:<br>{default_projection:.1f}\",\n",
    "                align=\"left\",\n",
    "                font=dict(color=\"black\", size=10),\n",
    "                xanchor=\"right\",\n",
    "                yanchor=\"top\",\n",
    "                y=0.9,\n",
    "                yref=\"paper\",\n",
    "                showarrow=False,\n",
    "                opacity=0.8\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': title,\n",
    "            'subtitle': {\n",
    "                'text': subtitle,\n",
    "            }\n",
    "        },\n",
    "        xaxis_title=\"Projection\",\n",
    "        yaxis_title=\"Count\",\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        barmode='overlay',\n",
    "        bargap=0,\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            title=\"Expression\",\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.01,\n",
    "            xanchor=\"right\",\n",
    "            x=1.01\n",
    "        )\n",
    "    )\n",
    "\n",
    "    stats_text = f\"n={stats['count']:,}<br>μ={stats['mean']:.4f}<br>σ={stats['std']:.4f}\"\n",
    "    fig.add_annotation(\n",
    "        text=stats_text,\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.98, y=0.98,\n",
    "        xanchor=\"right\", yanchor=\"top\",\n",
    "        showarrow=False,\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r99o8btaqs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot projection histogram for layer 32\n",
    "fig = plot_score_histogram(\n",
    "    df_rt_binned, \n",
    "    vector_name=f'layer_{layer}/contrast_role_pos3_default1',\n",
    "    title='Role and Trait Responses Projected on Assistant Contrast Vector',\n",
    "    subtitle=f'{model_name.replace(\"-\", \" \").title()}, Layer {layer}',\n",
    "    stats_data=rt_stats,\n",
    "    default_projection=default_projections[layer].item()\n",
    ")\n",
    "fig.show()\n",
    "#fig.write_html(f'{plot_dir}/layer{layer}_role_trait.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc18b6",
   "metadata": {},
   "source": [
    "## Chat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade1176",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"lmsys_10000\"\n",
    "readable_name = \"LMSYS-Chat-1M\"\n",
    "chat_file = f\"{base_dir}/capped/projections/{name}.json\"\n",
    "\n",
    "# Load each file directly into pandas\n",
    "df_chat = pd.read_json(chat_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dthgncngn9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chat_histogram(data, vector_name, title, subtitle):\n",
    "    \"\"\"\n",
    "    Plot a histogram from pre-computed chat projection data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : dict\n",
    "        Dictionary containing 'per_vector_stats' with histogram bins and counts\n",
    "    vector_name : str\n",
    "        Name of the vector to plot (e.g., 'layer_32/contrast_role_pos3_default1')\n",
    "    title : str\n",
    "        Title for the plot\n",
    "    subtitle : str\n",
    "        Subtitle for the plot\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    plotly.graph_objects.Figure\n",
    "    \"\"\"\n",
    "    if vector_name not in data['per_vector_stats']:\n",
    "        raise ValueError(f\"Vector {vector_name} not found in data\")\n",
    "    \n",
    "    stats = data['per_vector_stats'][vector_name]\n",
    "    bins = stats['histogram']['bins']\n",
    "    counts = stats['histogram']['counts']\n",
    "    \n",
    "    # Reconstruct sample data from histogram bins and counts\n",
    "    # For each bin, create samples at the bin center repeated by count\n",
    "    reconstructed_data = []\n",
    "    for i in range(len(counts)):\n",
    "        bin_center = (bins[i] + bins[i+1]) / 2\n",
    "        # Add bin_center repeated counts[i] times\n",
    "        reconstructed_data.extend([bin_center] * int(counts[i]))\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Calculate number of bins to match original histogram\n",
    "    nbins = len(counts)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=reconstructed_data,\n",
    "            marker_color='#3498db',  # blue\n",
    "            opacity=0.8,\n",
    "            name='Chat Dataset',\n",
    "            nbinsx=nbins,\n",
    "            xbins=dict(\n",
    "                start=bins[0],\n",
    "                end=bins[-1],\n",
    "                size=(bins[-1] - bins[0]) / nbins\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add percentile lines\n",
    "    percentiles = stats['percentiles']\n",
    "    # Add percentile lines with red annotations at top-left\n",
    "    for pct, value in percentiles.items():\n",
    "        fig.add_vline(\n",
    "            x=value,\n",
    "            line_width=1,\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"red\",\n",
    "            opacity=0.5,\n",
    "            annotation=dict(\n",
    "                text=f\"p{pct}:<br>{value:.1f}\",\n",
    "                align=\"right\",\n",
    "                font=dict(color=\"red\", size=9),\n",
    "                xanchor=\"right\",   # position text to the left of the line\n",
    "                yanchor=\"top\", # anchor text to bottom so it sits within the plot area\n",
    "                y=1,              # normalized coordinate (top of plot)\n",
    "                yref=\"paper\",     # relative to the full plot height\n",
    "                showarrow=False,\n",
    "                opacity=0.5\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': title,\n",
    "            'subtitle': {\n",
    "                'text': subtitle,\n",
    "            }\n",
    "        },\n",
    "        xaxis_title=\"Projection\",\n",
    "        yaxis_title=\"Count\",\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        bargap=0,  # No gap between bars\n",
    "    )\n",
    "    \n",
    "    # Add text annotation with statistics\n",
    "    stats_text = f\"n={stats['count']:,}<br>μ={stats['mean']:.4f}<br>σ={stats['std']:.4f}\"\n",
    "    fig.add_annotation(\n",
    "        text=stats_text,\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.98, y=0.98,\n",
    "        xanchor=\"right\", yanchor=\"top\",\n",
    "        showarrow=False,\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wjmru6a26t",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot chat histogram for layer 32\n",
    "layer = 40\n",
    "fig = plot_chat_histogram(\n",
    "    df_chat,\n",
    "    vector_name=f'layer_{layer}/contrast_role_pos3_default1',\n",
    "    title='Chat Dataset Responses Projected on Assistant Contrast Vector',\n",
    "    subtitle=f'{model_name.replace(\"-\", \" \").title()}, Layer {layer} - 10000 Conversations Sampled from {readable_name}'\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(f'{plot_dir}/layer{layer}_{name}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dfae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"wildchat_10000\"\n",
    "readable_name = \"WildChat\"\n",
    "chat_file = f\"{base_dir}/capped/projections/{name}.json\"\n",
    "\n",
    "# Load each file directly into pandas\n",
    "df_chat = pd.read_json(chat_file)\n",
    "\n",
    "fig = plot_chat_histogram(\n",
    "    df_chat,\n",
    "    vector_name=f'layer_{layer}/contrast_role_pos3_default1',\n",
    "    title='Chat Dataset Responses Projected on Assistant Contrast Vector',\n",
    "    subtitle=f'{model_name.replace(\"-\", \" \").title()}, Layer {layer} - 10000 Conversations Sampled from {readable_name}'\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(f'{plot_dir}/layer{layer}_{name}.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a19178",
   "metadata": {},
   "source": [
    "## Comparing caps with datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6j91axkjcza",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing caps config if it exists\n",
    "cfg_file = f\"{base_dir}/capped/configs/multi_contrast_layers_config.pt\"\n",
    "\n",
    "# Experiments 4-7 are all layers (layers_0:64) with different thresholds:\n",
    "# - layers_0:64-harm_0.01: Block 99% of harmful responses\n",
    "# - layers_0:64-harm_0.25: Block 75% of harmful responses  \n",
    "# - layers_0:64-safe_0.01: Block 99% of safe-default responses\n",
    "# - layers_0:64-safe_0.50: Block 50% of safe-default responses\n",
    "\n",
    "if os.path.exists(cfg_file):\n",
    "    cfg = torch.load(cfg_file, weights_only=False)\n",
    "    \n",
    "    # Extract the 4 all-layer experiments (indices 4-7)\n",
    "    experiments_all_layers = cfg['experiments'][4:8]\n",
    "    \n",
    "    # Create a dataframe mapping vector names to cap values\n",
    "    caps_data = []\n",
    "    \n",
    "    # Get all vector names from the first experiment\n",
    "    vector_names = [interv['vector'] for interv in experiments_all_layers[0]['interventions']]\n",
    "    \n",
    "    for vec_name in vector_names:\n",
    "        # Extract layer number from vector name (e.g., \"layer_32/contrast_role_pos3_default1\" -> 32)\n",
    "        layer_num = int(vec_name.split('/')[0].replace('layer_', ''))\n",
    "        \n",
    "        # Extract cap values from each of the 4 experiments\n",
    "        caps = {}\n",
    "        for exp in experiments_all_layers:\n",
    "            exp_id = exp['id'].split('-')[1]  # e.g., \"layers_0:64-harm_0.01\" -> \"harm_0.01\"\n",
    "            \n",
    "            # Find this vector's cap in this experiment\n",
    "            for interv in exp['interventions']:\n",
    "                if interv['vector'] == vec_name:\n",
    "                    caps[exp_id] = interv['cap']\n",
    "                    break\n",
    "        \n",
    "        caps_data.append({\n",
    "            'layer': layer_num,\n",
    "            'vector_name': vec_name,\n",
    "            'harm_0.01': caps.get('harm_0.01'),\n",
    "            'harm_0.25': caps.get('harm_0.25'),\n",
    "            'safe_0.01': caps.get('safe_0.01'),\n",
    "            'safe_0.50': caps.get('safe_0.50'),\n",
    "        })\n",
    "    \n",
    "    df_caps = pd.DataFrame(caps_data).sort_values('layer')\n",
    "    \n",
    "    print(f\"Loaded caps config from {cfg_file}\")\n",
    "    print(f\"  - {len(cfg['vectors'])} vectors\")\n",
    "    print(f\"  - {len(cfg['experiments'])} experiments\")\n",
    "    print(f\"  - Extracted caps for {len(df_caps)} vectors across 4 threshold levels\")\n",
    "else:\n",
    "    print(f\"Config file not found: {cfg_file}\")\n",
    "    df_caps = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "woyurao3lh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_caps_for_layer(layer_num, caps_df=df_caps):\n",
    "    \"\"\"\n",
    "    Pretty print the cap values for a given layer.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    layer_num : int\n",
    "        The layer number to display caps for\n",
    "    caps_df : pd.DataFrame, optional\n",
    "        The caps dataframe (defaults to df_caps)\n",
    "    \"\"\"\n",
    "    if caps_df is None:\n",
    "        print(\"No caps data loaded. Run the config loading cell first.\")\n",
    "        return\n",
    "    \n",
    "    # Filter to the specified layer\n",
    "    layer_data = caps_df[caps_df['layer'] == layer_num]\n",
    "    \n",
    "    if len(layer_data) == 0:\n",
    "        print(f\"No cap data found for layer {layer_num}\")\n",
    "        return\n",
    "    \n",
    "    row = layer_data.iloc[0]\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Cap Values for Layer {layer_num}\")\n",
    "    print(f\"Vector: {row['vector_name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print()\n",
    "    print(f\"{'Threshold':<20} {'Cap Value':>15} {'Description':<30}\")\n",
    "    print(f\"{'-'*70}\")\n",
    "    print(f\"{'safe_0.01':<20} {row['safe_0.01']:>15.4f} {'Block 99% of safe-default':<30}\")\n",
    "    print(f\"{'safe_0.50':<20} {row['safe_0.50']:>15.4f} {'Block 50% of safe-default':<30}\")\n",
    "    print(f\"{'harm_0.01':<20} {row['harm_0.01']:>15.4f} {'Block 99% of harmful':<30}\")\n",
    "    print(f\"{'harm_0.25':<20} {row['harm_0.25']:>15.4f} {'Block 75% of harmful':<30}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "# Display caps for the default layer (32)\n",
    "if df_caps is not None:\n",
    "    print_caps_for_layer(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xhul708bg7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WildChat dataset\n",
    "wildchat_file = f\"{base_dir}/capped/projections/wildchat_10000.json\"\n",
    "df_wildchat = pd.read_json(wildchat_file)\n",
    "\n",
    "print(f\"Loaded chat datasets:\")\n",
    "print(f\"  - LMSYS-Chat-1M: {df_chat['metadata']['n_assistant_turns']:,} assistant turns\")\n",
    "print(f\"  - WildChat: {df_wildchat['metadata']['n_assistant_turns']:,} assistant turns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bwcwsf8j5vq",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percentile_from_data(value, data):\n",
    "    \"\"\"\n",
    "    Compute the percentile rank of a value in a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    value : float\n",
    "        The value to find the percentile for\n",
    "    data : array-like\n",
    "        The dataset\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Percentile rank (0-100)\n",
    "    \"\"\"\n",
    "    return (data < value).sum() / len(data) * 100\n",
    "\n",
    "\n",
    "def interpolate_percentile_from_stats(value, percentiles_dict):\n",
    "    \"\"\"\n",
    "    Interpolate the percentile rank of a value from pre-computed percentiles.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    value : float\n",
    "        The value to find the percentile for\n",
    "    percentiles_dict : dict\n",
    "        Dictionary mapping percentile strings (e.g., '1', '5', '10') to values\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Estimated percentile rank (0-100)\n",
    "    \"\"\"\n",
    "    # Convert to sorted lists\n",
    "    pcts = sorted([int(k) for k in percentiles_dict.keys()])\n",
    "    vals = [percentiles_dict[str(p)] for p in pcts]\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if value <= vals[0]:\n",
    "        return pcts[0]\n",
    "    if value >= vals[-1]:\n",
    "        return pcts[-1]\n",
    "    \n",
    "    # Linear interpolation\n",
    "    for i in range(len(vals) - 1):\n",
    "        if vals[i] <= value <= vals[i+1]:\n",
    "            # Interpolate between pcts[i] and pcts[i+1]\n",
    "            t = (value - vals[i]) / (vals[i+1] - vals[i])\n",
    "            return pcts[i] + t * (pcts[i+1] - pcts[i])\n",
    "    \n",
    "    return 50.0  # Fallback\n",
    "\n",
    "\n",
    "def print_cap_percentiles_for_layer(layer_num, caps_df=df_caps, rt_df=df_rt_binned, \n",
    "                                     lmsys_data=df_chat, wildchat_data=df_wildchat):\n",
    "    \"\"\"\n",
    "    Print the percentile rank of each cap value across different datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    layer_num : int\n",
    "        The layer number to analyze\n",
    "    caps_df : pd.DataFrame\n",
    "        DataFrame with cap values\n",
    "    rt_df : pd.DataFrame\n",
    "        Role/trait dataframe with projection columns\n",
    "    lmsys_data : dict\n",
    "        LMSYS chat dataset with per_vector_stats\n",
    "    wildchat_data : dict\n",
    "        WildChat dataset with per_vector_stats\n",
    "    \"\"\"\n",
    "    if caps_df is None:\n",
    "        print(\"No caps data loaded. Run the config loading cell first.\")\n",
    "        return\n",
    "    \n",
    "    # Get cap values for this layer\n",
    "    layer_data = caps_df[caps_df['layer'] == layer_num]\n",
    "    if len(layer_data) == 0:\n",
    "        print(f\"No cap data found for layer {layer_num}\")\n",
    "        return\n",
    "    \n",
    "    row = layer_data.iloc[0]\n",
    "    vector_name = row['vector_name']\n",
    "    \n",
    "    print(f\"{'='*90}\")\n",
    "    print(f\"Cap Percentiles for Layer {layer_num}\")\n",
    "    print(f\"Vector: {vector_name}\")\n",
    "    print(f\"{'='*90}\")\n",
    "    print()\n",
    "    \n",
    "    # Table header\n",
    "    print(f\"{'Threshold':<15} {'Cap Value':>12} {'Role/Trait':>15} {'LMSYS-Chat':>15} {'WildChat':>15}\")\n",
    "    print(f\"{'-'*90}\")\n",
    "    \n",
    "    # Get role/trait data for this vector\n",
    "    rt_values = rt_df[vector_name].dropna().values\n",
    "    \n",
    "    # Get chat dataset percentiles\n",
    "    lmsys_percentiles = lmsys_data['per_vector_stats'][vector_name]['percentiles']\n",
    "    wildchat_percentiles = wildchat_data['per_vector_stats'][vector_name]['percentiles']\n",
    "    \n",
    "    # Compute percentiles for each cap threshold\n",
    "    thresholds = [\n",
    "        ('safe_0.01', 'Block 99% safe'),\n",
    "        ('safe_0.50', 'Block 50% safe'),\n",
    "        ('harm_0.01', 'Block 99% harm'),\n",
    "        ('harm_0.25', 'Block 75% harm'),\n",
    "    ]\n",
    "    \n",
    "    for threshold_name, description in thresholds:\n",
    "        cap_value = row[threshold_name]\n",
    "        \n",
    "        # Compute percentiles in each dataset\n",
    "        rt_pct = compute_percentile_from_data(cap_value, rt_values)\n",
    "        lmsys_pct = interpolate_percentile_from_stats(cap_value, lmsys_percentiles)\n",
    "        wildchat_pct = interpolate_percentile_from_stats(cap_value, wildchat_percentiles)\n",
    "        \n",
    "        print(f\"{threshold_name:<15} {cap_value:>12.4f} {rt_pct:>14.1f}% {lmsys_pct:>14.1f}% {wildchat_pct:>14.1f}%\")\n",
    "    \n",
    "    print(f\"{'='*90}\")\n",
    "    print()\n",
    "    print(\"Interpretation:\")\n",
    "    print(\"  - Percentile shows what % of responses fall BELOW the cap threshold\")\n",
    "    print(\"  - Higher percentile = more responses blocked by the cap\")\n",
    "    print(f\"  - Role/Trait dataset: {len(rt_values):,} samples\")\n",
    "    print(f\"  - LMSYS-Chat dataset: {lmsys_data['per_vector_stats'][vector_name]['count']:,} samples\")\n",
    "    print(f\"  - WildChat dataset: {wildchat_data['per_vector_stats'][vector_name]['count']:,} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yqek497445r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute percentiles for all layers across all datasets and thresholds\n",
    "def compute_all_layer_percentiles(caps_df=df_caps, rt_df=df_rt_binned, \n",
    "                                   lmsys_data=df_chat, wildchat_data=df_wildchat):\n",
    "    \"\"\"\n",
    "    Compute percentiles for all layers, datasets, and cap thresholds.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns: layer, dataset, threshold, percentile\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    thresholds = ['safe_0.01', 'safe_0.50', 'harm_0.01', 'harm_0.25']\n",
    "    \n",
    "    for _, row in caps_df.iterrows():\n",
    "        layer_num = row['layer']\n",
    "        vector_name = row['vector_name']\n",
    "        \n",
    "        # Get data for this layer\n",
    "        rt_values = rt_df[vector_name].dropna().values\n",
    "        lmsys_percentiles = lmsys_data['per_vector_stats'][vector_name]['percentiles']\n",
    "        wildchat_percentiles = wildchat_data['per_vector_stats'][vector_name]['percentiles']\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            cap_value = row[threshold]\n",
    "            \n",
    "            # Compute percentile for each dataset\n",
    "            rt_pct = compute_percentile_from_data(cap_value, rt_values)\n",
    "            lmsys_pct = interpolate_percentile_from_stats(cap_value, lmsys_percentiles)\n",
    "            wildchat_pct = interpolate_percentile_from_stats(cap_value, wildchat_percentiles)\n",
    "            \n",
    "            results.append({\n",
    "                'layer': layer_num,\n",
    "                'dataset': 'Role/Trait',\n",
    "                'threshold': threshold,\n",
    "                'percentile': rt_pct\n",
    "            })\n",
    "            results.append({\n",
    "                'layer': layer_num,\n",
    "                'dataset': 'LMSYS-Chat',\n",
    "                'threshold': threshold,\n",
    "                'percentile': lmsys_pct\n",
    "            })\n",
    "            results.append({\n",
    "                'layer': layer_num,\n",
    "                'dataset': 'WildChat',\n",
    "                'threshold': threshold,\n",
    "                'percentile': wildchat_pct\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Compute all percentiles\n",
    "print(\"Computing percentiles for all layers...\")\n",
    "df_percentiles = compute_all_layer_percentiles()\n",
    "print(f\"Computed {len(df_percentiles)} data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xjjd6hj9tk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create line plot showing percentiles across all layers\n",
    "fig = go.Figure()\n",
    "\n",
    "# Define colors for datasets\n",
    "dataset_colors = {\n",
    "    'Role/Trait': '#3498db',    # blue\n",
    "    'LMSYS-Chat': '#2ecc71',    # green\n",
    "    'WildChat': '#e67e22'       # orange\n",
    "}\n",
    "\n",
    "# Define markers for thresholds\n",
    "threshold_markers = {\n",
    "    'safe_0.01': 'circle',\n",
    "    'safe_0.50': 'square',\n",
    "    'harm_0.01': 'diamond',\n",
    "    'harm_0.25': 'triangle-up'\n",
    "}\n",
    "\n",
    "# Define threshold labels\n",
    "threshold_labels = {\n",
    "    'safe_0.01': 'Block 99% safe',\n",
    "    'safe_0.50': 'Block 50% safe',\n",
    "    'harm_0.01': 'Block 99% harm',\n",
    "    'harm_0.25': 'Block 75% harm'\n",
    "}\n",
    "\n",
    "# Add a trace for each dataset-threshold combination\n",
    "for dataset in ['Role/Trait', 'LMSYS-Chat', 'WildChat']:\n",
    "    for threshold in ['safe_0.01', 'safe_0.50', 'harm_0.01', 'harm_0.25']:\n",
    "        # Filter data for this combination\n",
    "        mask = (df_percentiles['dataset'] == dataset) & (df_percentiles['threshold'] == threshold)\n",
    "        subset = df_percentiles[mask].sort_values('layer')\n",
    "        \n",
    "        # Create trace name\n",
    "        trace_name = f\"{dataset} - {threshold_labels[threshold]}\"\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=subset['layer'],\n",
    "                y=subset['percentile'],\n",
    "                mode='lines+markers',\n",
    "                name=trace_name,\n",
    "                line=dict(color=dataset_colors[dataset], width=2),\n",
    "                marker=dict(\n",
    "                    symbol=threshold_markers[threshold],\n",
    "                    size=6,\n",
    "                    color=dataset_colors[dataset],\n",
    "                    line=dict(width=1, color='white')\n",
    "                ),\n",
    "                legendgroup=dataset,\n",
    "                showlegend=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Percentage of Responses Blocked by Caps',\n",
    "        'subtitle': {\n",
    "            'text': f'{model_name.replace(\"-\", \" \").title()} - Caps from Jailbreak Rollouts',\n",
    "        }\n",
    "    },\n",
    "    xaxis_title=\"Layer\",\n",
    "    yaxis_title=\"Percentile (%)\",\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    hovermode='closest',\n",
    "    legend=dict(\n",
    "        title=\"Dataset - Threshold\",\n",
    "        orientation=\"v\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.0,\n",
    "        xanchor=\"left\",\n",
    "        x=1.01,\n",
    "        font=dict(size=10)\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        tickmode='linear',\n",
    "        tick0=0,\n",
    "        dtick=4\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        range=[-2, 102],\n",
    "        ticksuffix='%'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(f'{plot_dir}/cap_percentile_comparison.html')\n",
    "print(f\"Saved plot to {plot_dir}/cap_percentile_comparison.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17df51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
