{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Config Generation\n",
    "\n",
    "This notebook generates experiment configs based on projection percentiles from:\n",
    "1. Role/Trait data → `role_trait_config.pt`\n",
    "2. LMSYS Chat-1M data → `lmsys_10000_config.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: llama-3.3-70b\n",
      "Total layers: 80\n",
      "Vectors file: /workspace/llama-3.3-70b/capped/configs/multi_contrast_vectors.pt\n",
      "Output directory: /workspace/llama-3.3-70b/capped/configs\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Change these for different models\n",
    "model_name = \"llama-3.3-70b\"\n",
    "layer = 40\n",
    "total_layers = 80\n",
    "base_dir = f\"/workspace/{model_name}\"\n",
    "\n",
    "vectors_file = f\"{base_dir}/capped/configs/multi_contrast_vectors.pt\"\n",
    "output_dir = f\"{base_dir}/capped/configs\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Total layers: {total_layers}\")\n",
    "print(f\"Vectors file: {vectors_file}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 vectors\n",
      "Sample vector: layer_0/contrast_role_pos3_default1 at layer 0\n",
      "Created vectors dictionary with 80 entries\n"
     ]
    }
   ],
   "source": [
    "# Load vectors\n",
    "vectors = torch.load(vectors_file, weights_only=False)\n",
    "print(f\"Loaded {len(vectors)} vectors\")\n",
    "print(f\"Sample vector: {vectors[0]['name']} at layer {vectors[0]['layer']}\")\n",
    "\n",
    "# Create vectors dictionary for config\n",
    "vectors_dict = {}\n",
    "for vec in vectors:\n",
    "    vectors_dict[vec['name']] = {\n",
    "        'vector': vec['vector'],\n",
    "        'layer': vec['layer']\n",
    "    }\n",
    "\n",
    "print(f\"Created vectors dictionary with {len(vectors_dict)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_scores(df):\n",
    "    \"\"\"\n",
    "    Add a score_bin column to the dataframe that bins scores consistently:\n",
    "    - Bin 0: Role score 0, Trait 0-25, Default (all)\n",
    "    - Bin 1: Role score 1, Trait 25-50\n",
    "    - Bin 2: Role score 2, Trait 50-75\n",
    "    - Bin 3: Role score 3, Trait 75-100\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle REFUSAL and null scores\n",
    "    df['score'] = df['score'].replace('REFUSAL', 0)\n",
    "    df['score'] = df['score'].fillna(-1)\n",
    "    df['score'] = df['score'].astype(int)\n",
    "    \n",
    "    # Create binned score column\n",
    "    def bin_score(row):\n",
    "        if row['type'] == 'role':\n",
    "            return row['score']\n",
    "        elif row['type'] == 'trait':\n",
    "            if row['score'] < 25:\n",
    "                return 0\n",
    "            elif row['score'] < 50:\n",
    "                return 1\n",
    "            elif row['score'] < 75:\n",
    "                return 2\n",
    "            else:\n",
    "                return 3\n",
    "        else:  # default\n",
    "            return 0\n",
    "    \n",
    "    df['score_bin'] = df.apply(bin_score, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_experiments(percentile_df, percentiles, layer_selections, vectors_dict):\n",
    "    \"\"\"\n",
    "    Build experiments from percentile DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        percentile_df: DataFrame with columns ['layer', 'vector_name', 'p1', 'p25', 'p50', 'p75']\n",
    "        percentiles: List of percentile values [0.01, 0.25, 0.50, 0.75]\n",
    "        layer_selections: Dict mapping layer range string to list of layer indices\n",
    "        vectors_dict: Dictionary of all vectors\n",
    "    \n",
    "    Returns:\n",
    "        List of experiment dictionaries\n",
    "    \"\"\"\n",
    "    # Map percentile values to column names\n",
    "    percentile_to_col = {\n",
    "        0.01: 'p1',\n",
    "        0.25: 'p25',\n",
    "        0.50: 'p50',\n",
    "        0.75: 'p75'\n",
    "    }\n",
    "    \n",
    "    experiments = []\n",
    "    \n",
    "    for layer_range_str, layer_list in layer_selections.items():\n",
    "        for percentile in percentiles:\n",
    "            exp_id = f\"layers_{layer_range_str}-p{percentile}\"\n",
    "            col_name = percentile_to_col[percentile]\n",
    "            \n",
    "            # Filter vectors in this layer range\n",
    "            vectors_in_range = percentile_df[percentile_df['layer'].isin(layer_list)]\n",
    "            \n",
    "            # Create interventions\n",
    "            interventions = []\n",
    "            for _, row in vectors_in_range.iterrows():\n",
    "                interventions.append({\n",
    "                    'vector': row['vector_name'],\n",
    "                    'cap': float(row[col_name])\n",
    "                })\n",
    "            \n",
    "            experiments.append({\n",
    "                'id': exp_id,\n",
    "                'interventions': interventions\n",
    "            })\n",
    "    \n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Role/Trait Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 908400 role/trait records\n",
      "Type distribution:\n",
      "type\n",
      "trait      576000\n",
      "role       330000\n",
      "default      2400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load role/trait projection data\n",
    "role_file = f\"{base_dir}/capped/projections/roles_projections.jsonl\"\n",
    "trait_file = f\"{base_dir}/capped/projections/traits_projections.jsonl\"\n",
    "\n",
    "# Load each file into pandas\n",
    "df_role = pd.read_json(role_file, lines=True)\n",
    "df_trait = pd.read_json(trait_file, lines=True)\n",
    "\n",
    "# Add source_file column\n",
    "df_role['source_file'] = 'role'\n",
    "df_trait['source_file'] = 'trait'\n",
    "\n",
    "# Concatenate\n",
    "df_rt = pd.concat([df_role, df_trait], ignore_index=True)\n",
    "\n",
    "# Add type column\n",
    "def determine_type(row):\n",
    "    if row.get('prompt_label') == 'default':\n",
    "        return 'default'\n",
    "    if isinstance(row['role'], str) and '_default' in row['role']:\n",
    "        parts = row['role'].split('_')\n",
    "        if len(parts) == 2 and parts[0].isdigit() and parts[1] == 'default':\n",
    "            return 'default'\n",
    "    return row['source_file']\n",
    "\n",
    "df_rt['type'] = df_rt.apply(determine_type, axis=1)\n",
    "df_rt = df_rt.drop('source_file', axis=1)\n",
    "\n",
    "print(f\"Loaded {len(df_rt)} role/trait records\")\n",
    "print(f\"Type distribution:\\n{df_rt['type'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_371260/2615495987.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['score'] = df['score'].replace('REFUSAL', 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded shape: (908400, 86)\n",
      "Score bin distribution:\n",
      "score_bin\n",
      "0    262834\n",
      "1     37557\n",
      "2     43465\n",
      "3    564544\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Expand projections into columns\n",
    "projections_df = pd.json_normalize(df_rt['projections'])\n",
    "df_rt = pd.concat([df_rt.drop('projections', axis=1), projections_df], axis=1)\n",
    "\n",
    "# Bin scores\n",
    "df_rt_binned = bin_scores(df_rt)\n",
    "\n",
    "print(f\"Expanded shape: {df_rt_binned.shape}\")\n",
    "print(f\"Score bin distribution:\\n{df_rt_binned['score_bin'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 projection columns\n",
      "\n",
      "Computed percentiles for 80 vectors\n",
      "\n",
      "Sample percentiles for layer 40:\n",
      "    layer                           vector_name        p1    p25       p50  \\\n",
      "40     40  layer_40/contrast_role_pos3_default1 -2.796875 -1.875 -1.171875   \n",
      "\n",
      "        p75  \n",
      "40 -0.21875  \n"
     ]
    }
   ],
   "source": [
    "# Compute percentiles for each vector\n",
    "projection_cols = [col for col in df_rt_binned.columns if col.startswith('layer_')]\n",
    "print(f\"Found {len(projection_cols)} projection columns\")\n",
    "\n",
    "percentiles_to_compute = [1, 25, 50, 75]\n",
    "rt_percentile_data = []\n",
    "\n",
    "for col in projection_cols:\n",
    "    values = df_rt_binned[col].dropna().values\n",
    "    \n",
    "    if len(values) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Extract layer number\n",
    "    layer_num = int(col.split('/')[0].replace('layer_', ''))\n",
    "    \n",
    "    # Compute percentiles\n",
    "    pcts = np.percentile(values, percentiles_to_compute)\n",
    "    \n",
    "    rt_percentile_data.append({\n",
    "        'layer': layer_num,\n",
    "        'vector_name': col,\n",
    "        'p1': pcts[0],\n",
    "        'p25': pcts[1],\n",
    "        'p50': pcts[2],\n",
    "        'p75': pcts[3]\n",
    "    })\n",
    "\n",
    "df_rt_percentiles = pd.DataFrame(rt_percentile_data).sort_values('layer')\n",
    "print(f\"\\nComputed percentiles for {len(df_rt_percentiles)} vectors\")\n",
    "print(f\"\\nSample percentiles for layer {layer}:\")\n",
    "print(df_rt_percentiles[df_rt_percentiles['layer'] == layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer selections:\n",
      "  0:80: 80 layers (0-79)\n",
      "  0:20: 20 layers (0-19)\n",
      "  20:30: 10 layers (20-29)\n",
      "  10:20: 10 layers (10-19)\n"
     ]
    }
   ],
   "source": [
    "# Define layer selections\n",
    "layer_selections = {\n",
    "    f'0:{total_layers}': list(range(0, total_layers)),\n",
    "    f'0:{total_layers//4}': list(range(0, total_layers//4)),\n",
    "    f'{total_layers//4}:{total_layers//4 + total_layers//8}': \n",
    "        list(range(total_layers//4, total_layers//4 + total_layers//8)),\n",
    "    f'{total_layers//8}:{total_layers//8 + total_layers//8}': \n",
    "        list(range(total_layers//8, total_layers//8 + total_layers//8)),\n",
    "}\n",
    "\n",
    "print(\"Layer selections:\")\n",
    "for name, layers in layer_selections.items():\n",
    "    print(f\"  {name}: {len(layers)} layers ({min(layers)}-{max(layers)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 16 role/trait experiments:\n",
      "  - layers_0:80-p0.01: 80 interventions\n",
      "  - layers_0:80-p0.25: 80 interventions\n",
      "  - layers_0:80-p0.5: 80 interventions\n",
      "  - layers_0:80-p0.75: 80 interventions\n",
      "  - layers_0:20-p0.01: 20 interventions\n",
      "  - layers_0:20-p0.25: 20 interventions\n",
      "  - layers_0:20-p0.5: 20 interventions\n",
      "  - layers_0:20-p0.75: 20 interventions\n",
      "  - layers_20:30-p0.01: 10 interventions\n",
      "  - layers_20:30-p0.25: 10 interventions\n",
      "  - layers_20:30-p0.5: 10 interventions\n",
      "  - layers_20:30-p0.75: 10 interventions\n",
      "  - layers_10:20-p0.01: 10 interventions\n",
      "  - layers_10:20-p0.25: 10 interventions\n",
      "  - layers_10:20-p0.5: 10 interventions\n",
      "  - layers_10:20-p0.75: 10 interventions\n"
     ]
    }
   ],
   "source": [
    "# Build role/trait experiments\n",
    "percentiles = [0.01, 0.25, 0.50, 0.75]\n",
    "\n",
    "rt_experiments = build_experiments(\n",
    "    percentile_df=df_rt_percentiles,\n",
    "    percentiles=percentiles,\n",
    "    layer_selections=layer_selections,\n",
    "    vectors_dict=vectors_dict\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated {len(rt_experiments)} role/trait experiments:\")\n",
    "for exp in rt_experiments:\n",
    "    print(f\"  - {exp['id']}: {len(exp['interventions'])} interventions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample experiment details:\n",
      "\n",
      "layers_0:80-p0.01:\n",
      "  Vectors: 80\n",
      "  Cap range: -5.28 to 1.83\n",
      "  First 3 interventions:\n",
      "    layer_0/contrast_role_pos3_default1: -0.0840\n",
      "    layer_1/contrast_role_pos3_default1: -0.2305\n",
      "    layer_2/contrast_role_pos3_default1: -0.2832\n",
      "\n",
      "layers_0:20-p0.01:\n",
      "  Vectors: 20\n",
      "  Cap range: -1.31 to -0.08\n",
      "  First 3 interventions:\n",
      "    layer_0/contrast_role_pos3_default1: -0.0840\n",
      "    layer_1/contrast_role_pos3_default1: -0.2305\n",
      "    layer_2/contrast_role_pos3_default1: -0.2832\n",
      "\n",
      "layers_20:30-p0.01:\n",
      "  Vectors: 10\n",
      "  Cap range: -1.28 to -0.33\n",
      "  First 3 interventions:\n",
      "    layer_20/contrast_role_pos3_default1: -0.9414\n",
      "    layer_21/contrast_role_pos3_default1: -0.7461\n",
      "    layer_22/contrast_role_pos3_default1: -0.7266\n",
      "\n",
      "layers_10:20-p0.01:\n",
      "  Vectors: 10\n",
      "  Cap range: -1.31 to -0.40\n",
      "  First 3 interventions:\n",
      "    layer_10/contrast_role_pos3_default1: -0.4043\n",
      "    layer_11/contrast_role_pos3_default1: -0.4590\n",
      "    layer_12/contrast_role_pos3_default1: -0.5547\n"
     ]
    }
   ],
   "source": [
    "# Show sample experiments\n",
    "print(\"\\nSample experiment details:\")\n",
    "for i in [0, 4, 8, 12]:\n",
    "    exp = rt_experiments[i]\n",
    "    caps = [interv['cap'] for interv in exp['interventions']]\n",
    "    print(f\"\\n{exp['id']}:\")\n",
    "    print(f\"  Vectors: {len(exp['interventions'])}\")\n",
    "    print(f\"  Cap range: {min(caps):.2f} to {max(caps):.2f}\")\n",
    "    print(f\"  First 3 interventions:\")\n",
    "    for interv in exp['interventions'][:3]:\n",
    "        print(f\"    {interv['vector']}: {interv['cap']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved role/trait config to /workspace/llama-3.3-70b/capped/configs/role_trait_config.pt\n",
      "\n",
      "Config summary:\n",
      "  - 80 vectors\n",
      "  - 16 experiments\n",
      "  - 480 total interventions\n"
     ]
    }
   ],
   "source": [
    "# Save role/trait config\n",
    "rt_config_file = f\"{output_dir}/role_trait_config.pt\"\n",
    "\n",
    "rt_config = {\n",
    "    'vectors': vectors_dict,\n",
    "    'experiments': rt_experiments\n",
    "}\n",
    "\n",
    "torch.save(rt_config, rt_config_file)\n",
    "\n",
    "print(f\"✓ Saved role/trait config to {rt_config_file}\")\n",
    "print(f\"\\nConfig summary:\")\n",
    "print(f\"  - {len(rt_config['vectors'])} vectors\")\n",
    "print(f\"  - {len(rt_config['experiments'])} experiments\")\n",
    "print(f\"  - {sum(len(exp['interventions']) for exp in rt_config['experiments'])} total interventions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: LMSYS Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LMSYS data\n",
      "Metadata: {'dataset': 'lmsys/lmsys-chat-1m', 'model': 'meta-llama/Llama-3.3-70B-Instruct', 'n_conversations_requested': 10000, 'seed': 42, 'language_filter': 'English', 'n_conversations_sampled': 10000, 'n_assistant_turns': 78334}\n",
      "Vectors: 80\n"
     ]
    }
   ],
   "source": [
    "# Load LMSYS projection statistics\n",
    "lmsys_file = f\"{base_dir}/capped/projections/lmsys_10000.json\"\n",
    "\n",
    "with open(lmsys_file, 'r') as f:\n",
    "    lmsys_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded LMSYS data\")\n",
    "print(f\"Metadata: {lmsys_data.get('metadata', {})}\")\n",
    "print(f\"Vectors: {len(lmsys_data['per_vector_stats'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted percentiles for 80 vectors\n",
      "\n",
      "Sample percentiles for layer 40:\n",
      "    layer                           vector_name       p1       p25       p50  \\\n",
      "40     40  layer_40/contrast_role_pos3_default1 -2.21875 -1.257812 -0.898438   \n",
      "\n",
      "         p75  \n",
      "40 -0.570312  \n"
     ]
    }
   ],
   "source": [
    "# Extract percentiles from pre-computed statistics\n",
    "lmsys_percentile_data = []\n",
    "\n",
    "for vector_name, stats in lmsys_data['per_vector_stats'].items():\n",
    "    # Extract layer number\n",
    "    layer_num = int(vector_name.split('/')[0].replace('layer_', ''))\n",
    "    \n",
    "    # Get percentiles from pre-computed stats\n",
    "    percentiles_dict = stats['percentiles']\n",
    "    \n",
    "    lmsys_percentile_data.append({\n",
    "        'layer': layer_num,\n",
    "        'vector_name': vector_name,\n",
    "        'p1': float(percentiles_dict['1']),\n",
    "        'p25': float(percentiles_dict['25']),\n",
    "        'p50': float(percentiles_dict['50']),\n",
    "        'p75': float(percentiles_dict['75'])\n",
    "    })\n",
    "\n",
    "df_lmsys_percentiles = pd.DataFrame(lmsys_percentile_data).sort_values('layer')\n",
    "print(f\"\\nExtracted percentiles for {len(df_lmsys_percentiles)} vectors\")\n",
    "print(f\"\\nSample percentiles for layer {layer}:\")\n",
    "print(df_lmsys_percentiles[df_lmsys_percentiles['layer'] == layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 16 LMSYS experiments:\n",
      "  - layers_0:80-p0.01: 80 interventions\n",
      "  - layers_0:80-p0.25: 80 interventions\n",
      "  - layers_0:80-p0.5: 80 interventions\n",
      "  - layers_0:80-p0.75: 80 interventions\n",
      "  - layers_0:20-p0.01: 20 interventions\n",
      "  - layers_0:20-p0.25: 20 interventions\n",
      "  - layers_0:20-p0.5: 20 interventions\n",
      "  - layers_0:20-p0.75: 20 interventions\n",
      "  - layers_20:30-p0.01: 10 interventions\n",
      "  - layers_20:30-p0.25: 10 interventions\n",
      "  - layers_20:30-p0.5: 10 interventions\n",
      "  - layers_20:30-p0.75: 10 interventions\n",
      "  - layers_10:20-p0.01: 10 interventions\n",
      "  - layers_10:20-p0.25: 10 interventions\n",
      "  - layers_10:20-p0.5: 10 interventions\n",
      "  - layers_10:20-p0.75: 10 interventions\n"
     ]
    }
   ],
   "source": [
    "# Build LMSYS experiments\n",
    "lmsys_experiments = build_experiments(\n",
    "    percentile_df=df_lmsys_percentiles,\n",
    "    percentiles=percentiles,\n",
    "    layer_selections=layer_selections,\n",
    "    vectors_dict=vectors_dict\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated {len(lmsys_experiments)} LMSYS experiments:\")\n",
    "for exp in lmsys_experiments:\n",
    "    print(f\"  - {exp['id']}: {len(exp['interventions'])} interventions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample experiment details:\n",
      "\n",
      "layers_0:80-p0.01:\n",
      "  Vectors: 80\n",
      "  Cap range: -4.03 to -0.01\n",
      "  First 3 interventions:\n",
      "    layer_0/contrast_role_pos3_default1: -0.0100\n",
      "    layer_1/contrast_role_pos3_default1: -0.1494\n",
      "    layer_2/contrast_role_pos3_default1: -0.2266\n",
      "\n",
      "layers_0:20-p0.01:\n",
      "  Vectors: 20\n",
      "  Cap range: -1.04 to -0.01\n",
      "  First 3 interventions:\n",
      "    layer_0/contrast_role_pos3_default1: -0.0100\n",
      "    layer_1/contrast_role_pos3_default1: -0.1494\n",
      "    layer_2/contrast_role_pos3_default1: -0.2266\n",
      "\n",
      "layers_20:30-p0.01:\n",
      "  Vectors: 10\n",
      "  Cap range: -1.23 to -0.44\n",
      "  First 3 interventions:\n",
      "    layer_20/contrast_role_pos3_default1: -0.8125\n",
      "    layer_21/contrast_role_pos3_default1: -0.7539\n",
      "    layer_22/contrast_role_pos3_default1: -0.7656\n",
      "\n",
      "layers_10:20-p0.01:\n",
      "  Vectors: 10\n",
      "  Cap range: -1.04 to -0.27\n",
      "  First 3 interventions:\n",
      "    layer_10/contrast_role_pos3_default1: -0.2715\n",
      "    layer_11/contrast_role_pos3_default1: -0.3340\n",
      "    layer_12/contrast_role_pos3_default1: -0.3867\n"
     ]
    }
   ],
   "source": [
    "# Show sample experiments\n",
    "print(\"\\nSample experiment details:\")\n",
    "for i in [0, 4, 8, 12]:\n",
    "    exp = lmsys_experiments[i]\n",
    "    caps = [interv['cap'] for interv in exp['interventions']]\n",
    "    print(f\"\\n{exp['id']}:\")\n",
    "    print(f\"  Vectors: {len(exp['interventions'])}\")\n",
    "    print(f\"  Cap range: {min(caps):.2f} to {max(caps):.2f}\")\n",
    "    print(f\"  First 3 interventions:\")\n",
    "    for interv in exp['interventions'][:3]:\n",
    "        print(f\"    {interv['vector']}: {interv['cap']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved LMSYS config to /workspace/llama-3.3-70b/capped/configs/lmsys_10000_config.pt\n",
      "\n",
      "Config summary:\n",
      "  - 80 vectors\n",
      "  - 16 experiments\n",
      "  - 480 total interventions\n"
     ]
    }
   ],
   "source": [
    "# Save LMSYS config\n",
    "lmsys_config_file = f\"{output_dir}/lmsys_10000_config.pt\"\n",
    "\n",
    "lmsys_config = {\n",
    "    'vectors': vectors_dict,\n",
    "    'experiments': lmsys_experiments\n",
    "}\n",
    "\n",
    "torch.save(lmsys_config, lmsys_config_file)\n",
    "\n",
    "print(f\"✓ Saved LMSYS config to {lmsys_config_file}\")\n",
    "print(f\"\\nConfig summary:\")\n",
    "print(f\"  - {len(lmsys_config['vectors'])} vectors\")\n",
    "print(f\"  - {len(lmsys_config['experiments'])} experiments\")\n",
    "print(f\"  - {sum(len(exp['interventions']) for exp in lmsys_config['experiments'])} total interventions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Config Generation Complete\n",
      "======================================================================\n",
      "\n",
      "Model: llama-3.3-70b\n",
      "Total layers: 80\n",
      "\n",
      "Generated configs:\n",
      "  1. /workspace/llama-3.3-70b/capped/configs/role_trait_config.pt\n",
      "     - 16 experiments\n",
      "     - Based on role/trait projection data\n",
      "\n",
      "  2. /workspace/llama-3.3-70b/capped/configs/lmsys_10000_config.pt\n",
      "     - 16 experiments\n",
      "     - Based on LMSYS-Chat-1M projection data\n",
      "\n",
      "Percentiles used: [0.01, 0.25, 0.5, 0.75]\n",
      "Layer selections: ['0:80', '0:20', '20:30', '10:20']\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Config Generation Complete\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel: {model_name}\")\n",
    "print(f\"Total layers: {total_layers}\")\n",
    "print(f\"\\nGenerated configs:\")\n",
    "print(f\"  1. {rt_config_file}\")\n",
    "print(f\"     - {len(rt_config['experiments'])} experiments\")\n",
    "print(f\"     - Based on role/trait projection data\")\n",
    "print(f\"\\n  2. {lmsys_config_file}\")\n",
    "print(f\"     - {len(lmsys_config['experiments'])} experiments\")\n",
    "print(f\"     - Based on LMSYS-Chat-1M projection data\")\n",
    "print(f\"\\nPercentiles used: {percentiles}\")\n",
    "print(f\"Layer selections: {list(layer_selections.keys())}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
