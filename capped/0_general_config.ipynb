{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Config Generation\n",
    "\n",
    "This notebook generates experiment configs based on projection percentiles from:\n",
    "1. Role/Trait data → `role_trait_config.pt`\n",
    "2. LMSYS Chat-1M data → `lmsys_10000_config.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: qwen-3-32b\n",
      "Total layers: 64\n",
      "Vectors file: /workspace/qwen-3-32b/capped/configs/multi_contrast_vectors.pt\n",
      "Output directory: /workspace/qwen-3-32b/capped/configs\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Change these for different models\n",
    "model_name = \"qwen-3-32b\"\n",
    "layer = 32\n",
    "total_layers = 64\n",
    "base_dir = f\"/workspace/{model_name}\"\n",
    "\n",
    "vectors_file = f\"{base_dir}/capped/configs/multi_contrast_vectors.pt\"\n",
    "output_dir = f\"{base_dir}/capped/configs\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Total layers: {total_layers}\")\n",
    "print(f\"Vectors file: {vectors_file}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 64 vectors\n",
      "Sample vector: layer_0/contrast_role_pos3_default1 at layer 0\n",
      "Created vectors dictionary with 64 entries\n"
     ]
    }
   ],
   "source": [
    "# Load vectors\n",
    "vectors = torch.load(vectors_file, weights_only=False)\n",
    "print(f\"Loaded {len(vectors)} vectors\")\n",
    "print(f\"Sample vector: {vectors[0]['name']} at layer {vectors[0]['layer']}\")\n",
    "\n",
    "# Create vectors dictionary for config\n",
    "vectors_dict = {}\n",
    "for vec in vectors:\n",
    "    vectors_dict[vec['name']] = {\n",
    "        'vector': vec['vector'],\n",
    "        'layer': vec['layer']\n",
    "    }\n",
    "\n",
    "print(f\"Created vectors dictionary with {len(vectors_dict)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_scores(df):\n",
    "    \"\"\"\n",
    "    Add a score_bin column to the dataframe that bins scores consistently:\n",
    "    - Bin 0: Role score 0, Trait 0-25, Default (all)\n",
    "    - Bin 1: Role score 1, Trait 25-50\n",
    "    - Bin 2: Role score 2, Trait 50-75\n",
    "    - Bin 3: Role score 3, Trait 75-100\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle REFUSAL and null scores\n",
    "    df['score'] = df['score'].replace('REFUSAL', 0)\n",
    "    df['score'] = df['score'].fillna(-1)\n",
    "    df['score'] = df['score'].astype(int)\n",
    "    \n",
    "    # Create binned score column\n",
    "    def bin_score(row):\n",
    "        if row['type'] == 'role':\n",
    "            return row['score']\n",
    "        elif row['type'] == 'trait':\n",
    "            if row['score'] < 25:\n",
    "                return 0\n",
    "            elif row['score'] < 50:\n",
    "                return 1\n",
    "            elif row['score'] < 75:\n",
    "                return 2\n",
    "            else:\n",
    "                return 3\n",
    "        else:  # default\n",
    "            return 0\n",
    "    \n",
    "    df['score_bin'] = df.apply(bin_score, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_experiments(percentile_df, percentiles, layer_selections, vectors_dict):\n",
    "    \"\"\"\n",
    "    Build experiments from percentile DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        percentile_df: DataFrame with columns ['layer', 'vector_name', 'p1', 'p25', 'p50', 'p75']\n",
    "        percentiles: List of percentile values [0.01, 0.25, 0.50, 0.75]\n",
    "        layer_selections: Dict mapping layer range string to list of layer indices\n",
    "        vectors_dict: Dictionary of all vectors\n",
    "    \n",
    "    Returns:\n",
    "        List of experiment dictionaries\n",
    "    \"\"\"\n",
    "    # Map percentile values to column names\n",
    "    percentile_to_col = {\n",
    "        0.01: 'p1',\n",
    "        0.25: 'p25',\n",
    "        0.50: 'p50',\n",
    "        0.75: 'p75'\n",
    "    }\n",
    "    \n",
    "    experiments = []\n",
    "    \n",
    "    for layer_range_str, layer_list in layer_selections.items():\n",
    "        for percentile in percentiles:\n",
    "            exp_id = f\"layers_{layer_range_str}-p{percentile}\"\n",
    "            col_name = percentile_to_col[percentile]\n",
    "            \n",
    "            # Filter vectors in this layer range\n",
    "            vectors_in_range = percentile_df[percentile_df['layer'].isin(layer_list)]\n",
    "            \n",
    "            # Create interventions\n",
    "            interventions = []\n",
    "            for _, row in vectors_in_range.iterrows():\n",
    "                interventions.append({\n",
    "                    'vector': row['vector_name'],\n",
    "                    'cap': float(row[col_name])\n",
    "                })\n",
    "            \n",
    "            experiments.append({\n",
    "                'id': exp_id,\n",
    "                'interventions': interventions\n",
    "            })\n",
    "    \n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Role/Trait Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 909599 role/trait records\n",
      "Type distribution:\n",
      "type\n",
      "trait      576000\n",
      "role       329999\n",
      "default      3600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load role/trait projection data\n",
    "role_file = f\"{base_dir}/capped/projections/roles_projections.jsonl\"\n",
    "trait_file = f\"{base_dir}/capped/projections/traits_projections.jsonl\"\n",
    "\n",
    "# Load each file into pandas\n",
    "df_role = pd.read_json(role_file, lines=True)\n",
    "df_trait = pd.read_json(trait_file, lines=True)\n",
    "\n",
    "# Add source_file column\n",
    "df_role['source_file'] = 'role'\n",
    "df_trait['source_file'] = 'trait'\n",
    "\n",
    "# Concatenate\n",
    "df_rt = pd.concat([df_role, df_trait], ignore_index=True)\n",
    "\n",
    "# Add type column\n",
    "def determine_type(row):\n",
    "    if row.get('prompt_label') == 'default':\n",
    "        return 'default'\n",
    "    if isinstance(row['role'], str) and '_default' in row['role']:\n",
    "        parts = row['role'].split('_')\n",
    "        if len(parts) == 2 and parts[0].isdigit() and parts[1] == 'default':\n",
    "            return 'default'\n",
    "    return row['source_file']\n",
    "\n",
    "df_rt['type'] = df_rt.apply(determine_type, axis=1)\n",
    "df_rt = df_rt.drop('source_file', axis=1)\n",
    "\n",
    "print(f\"Loaded {len(df_rt)} role/trait records\")\n",
    "print(f\"Type distribution:\\n{df_rt['type'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1820797/2615495987.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['score'] = df['score'].replace('REFUSAL', 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded shape: (909599, 70)\n",
      "Score bin distribution:\n",
      "score_bin\n",
      "0    256688\n",
      "1     57355\n",
      "2     57002\n",
      "3    538554\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Expand projections into columns\n",
    "projections_df = pd.json_normalize(df_rt['projections'])\n",
    "df_rt = pd.concat([df_rt.drop('projections', axis=1), projections_df], axis=1)\n",
    "\n",
    "# Bin scores\n",
    "df_rt_binned = bin_scores(df_rt)\n",
    "\n",
    "print(f\"Expanded shape: {df_rt_binned.shape}\")\n",
    "print(f\"Score bin distribution:\\n{df_rt_binned['score_bin'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 projection columns\n",
      "\n",
      "Computed percentiles for 64 vectors\n",
      "\n",
      "Sample percentiles for layer 32:\n",
      "    layer                           vector_name     p1      p25      p50  \\\n",
      "32     32  layer_32/contrast_role_pos3_default1 -11.25  5.28125  15.3125   \n",
      "\n",
      "       p75  \n",
      "32  31.125  \n"
     ]
    }
   ],
   "source": [
    "# Compute percentiles for each vector\n",
    "projection_cols = [col for col in df_rt_binned.columns if col.startswith('layer_')]\n",
    "print(f\"Found {len(projection_cols)} projection columns\")\n",
    "\n",
    "percentiles_to_compute = [1, 25, 50, 75]\n",
    "rt_percentile_data = []\n",
    "\n",
    "for col in projection_cols:\n",
    "    values = df_rt_binned[col].dropna().values\n",
    "    \n",
    "    if len(values) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Extract layer number\n",
    "    layer_num = int(col.split('/')[0].replace('layer_', ''))\n",
    "    \n",
    "    # Compute percentiles\n",
    "    pcts = np.percentile(values, percentiles_to_compute)\n",
    "    \n",
    "    rt_percentile_data.append({\n",
    "        'layer': layer_num,\n",
    "        'vector_name': col,\n",
    "        'p1': pcts[0],\n",
    "        'p25': pcts[1],\n",
    "        'p50': pcts[2],\n",
    "        'p75': pcts[3]\n",
    "    })\n",
    "\n",
    "df_rt_percentiles = pd.DataFrame(rt_percentile_data).sort_values('layer')\n",
    "print(f\"\\nComputed percentiles for {len(df_rt_percentiles)} vectors\")\n",
    "print(f\"\\nSample percentiles for layer {layer}:\")\n",
    "print(df_rt_percentiles[df_rt_percentiles['layer'] == layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer selections:\n",
      "  32:36: 4 layers (32-35)\n",
      "  34:38: 4 layers (34-37)\n",
      "  36:40: 4 layers (36-39)\n",
      "  38:42: 4 layers (38-41)\n",
      "  40:44: 4 layers (40-43)\n",
      "  42:46: 4 layers (42-45)\n",
      "  44:48: 4 layers (44-47)\n",
      "  46:50: 4 layers (46-49)\n",
      "  48:52: 4 layers (48-51)\n",
      "  50:54: 4 layers (50-53)\n",
      "  52:56: 4 layers (52-55)\n",
      "  54:58: 4 layers (54-57)\n",
      "  56:60: 4 layers (56-59)\n",
      "  32:40: 8 layers (32-39)\n",
      "  34:42: 8 layers (34-41)\n",
      "  36:44: 8 layers (36-43)\n",
      "  38:46: 8 layers (38-45)\n",
      "  40:48: 8 layers (40-47)\n",
      "  42:50: 8 layers (42-49)\n",
      "  44:52: 8 layers (44-51)\n",
      "  46:54: 8 layers (46-53)\n",
      "  48:56: 8 layers (48-55)\n",
      "  50:58: 8 layers (50-57)\n",
      "  52:60: 8 layers (52-59)\n",
      "  32:48: 16 layers (32-47)\n",
      "  34:50: 16 layers (34-49)\n",
      "  36:52: 16 layers (36-51)\n",
      "  38:54: 16 layers (38-53)\n",
      "  40:56: 16 layers (40-55)\n",
      "  42:58: 16 layers (42-57)\n",
      "  44:60: 16 layers (44-59)\n"
     ]
    }
   ],
   "source": [
    "# Define layer selections\n",
    "layer_selections = {\n",
    "    # f'0:{total_layers}': list(range(0, total_layers)),\n",
    "    # f'0:{total_layers//4}': list(range(0, total_layers//4)),\n",
    "    # f'{total_layers//4}:{total_layers//4 + total_layers//8}': \n",
    "    #     list(range(total_layers//4, total_layers//4 + total_layers//8)),\n",
    "    # f'{total_layers//8}:{total_layers//8 + total_layers//8}': \n",
    "    #     list(range(total_layers//8, total_layers//8 + total_layers//8)),\n",
    "}\n",
    "\n",
    "# for i in range(3, 8):\n",
    "#     layer_selections[f'{total_layers//8*i}:{total_layers//8*i + total_layers//8}'] = list(range(total_layers//8*i, total_layers//8*i + total_layers//8))\n",
    "\n",
    "# Sliding windows with different sizes and increments\n",
    "# Window size 4, increment by 2\n",
    "for i in range(32, 60, 2):\n",
    "    if i + 4 <= 60:\n",
    "        layer_selections[f'{i}:{i + 4}'] = list(range(i, i + 4))\n",
    "\n",
    "# Window size 4, increment by 4\n",
    "for i in range(32, 60, 4):\n",
    "    if i + 4 <= 60:\n",
    "        layer_selections[f'{i}:{i + 4}'] = list(range(i, i + 4))\n",
    "\n",
    "# Window size 8, increment by 2\n",
    "for i in range(32, 60, 2):\n",
    "    if i + 8 <= 60:\n",
    "        layer_selections[f'{i}:{i + 8}'] = list(range(i, i + 8))\n",
    "\n",
    "# Window size 8, increment by 4\n",
    "for i in range(32, 60, 4):\n",
    "    if i + 8 <= 60:\n",
    "        layer_selections[f'{i}:{i + 8}'] = list(range(i, i + 8))\n",
    "\n",
    "# Window size 16, increment by 2\n",
    "for i in range(32, 60, 2):\n",
    "    if i + 16 <= 60:\n",
    "        layer_selections[f'{i}:{i + 16}'] = list(range(i, i + 16))\n",
    "\n",
    "# Window size 16, increment by 4\n",
    "for i in range(32, 60, 4):\n",
    "    if i + 16 <= 60:\n",
    "        layer_selections[f'{i}:{i + 16}'] = list(range(i, i + 16))\n",
    "\n",
    "# Sort by window size (4, 8, 16), then by starting layer\n",
    "layer_selections = dict(sorted(layer_selections.items(), \n",
    "                               key=lambda x: (len(x[1]), min(x[1]))))\n",
    "\n",
    "print(\"Layer selections:\")\n",
    "for name, layers in layer_selections.items():\n",
    "    print(f\"  {name}: {len(layers)} layers ({min(layers)}-{max(layers)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 124 role/trait experiments:\n",
      "  - layers_32:36-p0.01: 4 interventions\n",
      "  - layers_32:36-p0.25: 4 interventions\n",
      "  - layers_32:36-p0.5: 4 interventions\n",
      "  - layers_32:36-p0.75: 4 interventions\n",
      "  - layers_34:38-p0.01: 4 interventions\n",
      "  - layers_34:38-p0.25: 4 interventions\n",
      "  - layers_34:38-p0.5: 4 interventions\n",
      "  - layers_34:38-p0.75: 4 interventions\n",
      "  - layers_36:40-p0.01: 4 interventions\n",
      "  - layers_36:40-p0.25: 4 interventions\n",
      "  - layers_36:40-p0.5: 4 interventions\n",
      "  - layers_36:40-p0.75: 4 interventions\n",
      "  - layers_38:42-p0.01: 4 interventions\n",
      "  - layers_38:42-p0.25: 4 interventions\n",
      "  - layers_38:42-p0.5: 4 interventions\n",
      "  - layers_38:42-p0.75: 4 interventions\n",
      "  - layers_40:44-p0.01: 4 interventions\n",
      "  - layers_40:44-p0.25: 4 interventions\n",
      "  - layers_40:44-p0.5: 4 interventions\n",
      "  - layers_40:44-p0.75: 4 interventions\n",
      "  - layers_42:46-p0.01: 4 interventions\n",
      "  - layers_42:46-p0.25: 4 interventions\n",
      "  - layers_42:46-p0.5: 4 interventions\n",
      "  - layers_42:46-p0.75: 4 interventions\n",
      "  - layers_44:48-p0.01: 4 interventions\n",
      "  - layers_44:48-p0.25: 4 interventions\n",
      "  - layers_44:48-p0.5: 4 interventions\n",
      "  - layers_44:48-p0.75: 4 interventions\n",
      "  - layers_46:50-p0.01: 4 interventions\n",
      "  - layers_46:50-p0.25: 4 interventions\n",
      "  - layers_46:50-p0.5: 4 interventions\n",
      "  - layers_46:50-p0.75: 4 interventions\n",
      "  - layers_48:52-p0.01: 4 interventions\n",
      "  - layers_48:52-p0.25: 4 interventions\n",
      "  - layers_48:52-p0.5: 4 interventions\n",
      "  - layers_48:52-p0.75: 4 interventions\n",
      "  - layers_50:54-p0.01: 4 interventions\n",
      "  - layers_50:54-p0.25: 4 interventions\n",
      "  - layers_50:54-p0.5: 4 interventions\n",
      "  - layers_50:54-p0.75: 4 interventions\n",
      "  - layers_52:56-p0.01: 4 interventions\n",
      "  - layers_52:56-p0.25: 4 interventions\n",
      "  - layers_52:56-p0.5: 4 interventions\n",
      "  - layers_52:56-p0.75: 4 interventions\n",
      "  - layers_54:58-p0.01: 4 interventions\n",
      "  - layers_54:58-p0.25: 4 interventions\n",
      "  - layers_54:58-p0.5: 4 interventions\n",
      "  - layers_54:58-p0.75: 4 interventions\n",
      "  - layers_56:60-p0.01: 4 interventions\n",
      "  - layers_56:60-p0.25: 4 interventions\n",
      "  - layers_56:60-p0.5: 4 interventions\n",
      "  - layers_56:60-p0.75: 4 interventions\n",
      "  - layers_32:40-p0.01: 8 interventions\n",
      "  - layers_32:40-p0.25: 8 interventions\n",
      "  - layers_32:40-p0.5: 8 interventions\n",
      "  - layers_32:40-p0.75: 8 interventions\n",
      "  - layers_34:42-p0.01: 8 interventions\n",
      "  - layers_34:42-p0.25: 8 interventions\n",
      "  - layers_34:42-p0.5: 8 interventions\n",
      "  - layers_34:42-p0.75: 8 interventions\n",
      "  - layers_36:44-p0.01: 8 interventions\n",
      "  - layers_36:44-p0.25: 8 interventions\n",
      "  - layers_36:44-p0.5: 8 interventions\n",
      "  - layers_36:44-p0.75: 8 interventions\n",
      "  - layers_38:46-p0.01: 8 interventions\n",
      "  - layers_38:46-p0.25: 8 interventions\n",
      "  - layers_38:46-p0.5: 8 interventions\n",
      "  - layers_38:46-p0.75: 8 interventions\n",
      "  - layers_40:48-p0.01: 8 interventions\n",
      "  - layers_40:48-p0.25: 8 interventions\n",
      "  - layers_40:48-p0.5: 8 interventions\n",
      "  - layers_40:48-p0.75: 8 interventions\n",
      "  - layers_42:50-p0.01: 8 interventions\n",
      "  - layers_42:50-p0.25: 8 interventions\n",
      "  - layers_42:50-p0.5: 8 interventions\n",
      "  - layers_42:50-p0.75: 8 interventions\n",
      "  - layers_44:52-p0.01: 8 interventions\n",
      "  - layers_44:52-p0.25: 8 interventions\n",
      "  - layers_44:52-p0.5: 8 interventions\n",
      "  - layers_44:52-p0.75: 8 interventions\n",
      "  - layers_46:54-p0.01: 8 interventions\n",
      "  - layers_46:54-p0.25: 8 interventions\n",
      "  - layers_46:54-p0.5: 8 interventions\n",
      "  - layers_46:54-p0.75: 8 interventions\n",
      "  - layers_48:56-p0.01: 8 interventions\n",
      "  - layers_48:56-p0.25: 8 interventions\n",
      "  - layers_48:56-p0.5: 8 interventions\n",
      "  - layers_48:56-p0.75: 8 interventions\n",
      "  - layers_50:58-p0.01: 8 interventions\n",
      "  - layers_50:58-p0.25: 8 interventions\n",
      "  - layers_50:58-p0.5: 8 interventions\n",
      "  - layers_50:58-p0.75: 8 interventions\n",
      "  - layers_52:60-p0.01: 8 interventions\n",
      "  - layers_52:60-p0.25: 8 interventions\n",
      "  - layers_52:60-p0.5: 8 interventions\n",
      "  - layers_52:60-p0.75: 8 interventions\n",
      "  - layers_32:48-p0.01: 16 interventions\n",
      "  - layers_32:48-p0.25: 16 interventions\n",
      "  - layers_32:48-p0.5: 16 interventions\n",
      "  - layers_32:48-p0.75: 16 interventions\n",
      "  - layers_34:50-p0.01: 16 interventions\n",
      "  - layers_34:50-p0.25: 16 interventions\n",
      "  - layers_34:50-p0.5: 16 interventions\n",
      "  - layers_34:50-p0.75: 16 interventions\n",
      "  - layers_36:52-p0.01: 16 interventions\n",
      "  - layers_36:52-p0.25: 16 interventions\n",
      "  - layers_36:52-p0.5: 16 interventions\n",
      "  - layers_36:52-p0.75: 16 interventions\n",
      "  - layers_38:54-p0.01: 16 interventions\n",
      "  - layers_38:54-p0.25: 16 interventions\n",
      "  - layers_38:54-p0.5: 16 interventions\n",
      "  - layers_38:54-p0.75: 16 interventions\n",
      "  - layers_40:56-p0.01: 16 interventions\n",
      "  - layers_40:56-p0.25: 16 interventions\n",
      "  - layers_40:56-p0.5: 16 interventions\n",
      "  - layers_40:56-p0.75: 16 interventions\n",
      "  - layers_42:58-p0.01: 16 interventions\n",
      "  - layers_42:58-p0.25: 16 interventions\n",
      "  - layers_42:58-p0.5: 16 interventions\n",
      "  - layers_42:58-p0.75: 16 interventions\n",
      "  - layers_44:60-p0.01: 16 interventions\n",
      "  - layers_44:60-p0.25: 16 interventions\n",
      "  - layers_44:60-p0.5: 16 interventions\n",
      "  - layers_44:60-p0.75: 16 interventions\n"
     ]
    }
   ],
   "source": [
    "# Build role/trait experiments\n",
    "percentiles = [0.01, 0.25, 0.50, 0.75]\n",
    "\n",
    "rt_experiments = build_experiments(\n",
    "    percentile_df=df_rt_percentiles,\n",
    "    percentiles=percentiles,\n",
    "    layer_selections=layer_selections,\n",
    "    vectors_dict=vectors_dict\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated {len(rt_experiments)} role/trait experiments:\")\n",
    "for exp in rt_experiments:\n",
    "    print(f\"  - {exp['id']}: {len(exp['interventions'])} interventions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample experiment details:\n",
      "\n",
      "layers_32:36-p0.01:\n",
      "  Vectors: 4\n",
      "  Cap range: -26.25 to -8.88\n",
      "  First 3 interventions:\n",
      "    layer_32/contrast_role_pos3_default1: -11.2500\n",
      "    layer_33/contrast_role_pos3_default1: -8.8750\n",
      "    layer_34/contrast_role_pos3_default1: -16.0000\n",
      "\n",
      "layers_34:38-p0.01:\n",
      "  Vectors: 4\n",
      "  Cap range: -30.00 to -16.00\n",
      "  First 3 interventions:\n",
      "    layer_34/contrast_role_pos3_default1: -16.0000\n",
      "    layer_35/contrast_role_pos3_default1: -26.2500\n",
      "    layer_36/contrast_role_pos3_default1: -30.0000\n",
      "\n",
      "layers_36:40-p0.01:\n",
      "  Vectors: 4\n",
      "  Cap range: -30.00 to -19.00\n",
      "  First 3 interventions:\n",
      "    layer_36/contrast_role_pos3_default1: -30.0000\n",
      "    layer_37/contrast_role_pos3_default1: -24.5000\n",
      "    layer_38/contrast_role_pos3_default1: -19.0000\n",
      "\n",
      "layers_38:42-p0.01:\n",
      "  Vectors: 4\n",
      "  Cap range: -29.75 to -19.00\n",
      "  First 3 interventions:\n",
      "    layer_38/contrast_role_pos3_default1: -19.0000\n",
      "    layer_39/contrast_role_pos3_default1: -25.3750\n",
      "    layer_40/contrast_role_pos3_default1: -27.5000\n"
     ]
    }
   ],
   "source": [
    "# Show sample experiments\n",
    "print(\"\\nSample experiment details:\")\n",
    "for i in [0, 4, 8, 12]:\n",
    "    exp = rt_experiments[i]\n",
    "    caps = [interv['cap'] for interv in exp['interventions']]\n",
    "    print(f\"\\n{exp['id']}:\")\n",
    "    print(f\"  Vectors: {len(exp['interventions'])}\")\n",
    "    print(f\"  Cap range: {min(caps):.2f} to {max(caps):.2f}\")\n",
    "    print(f\"  First 3 interventions:\")\n",
    "    for interv in exp['interventions'][:3]:\n",
    "        print(f\"    {interv['vector']}: {interv['cap']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved role/trait config to /workspace/qwen-3-32b/capped/configs/role_trait_sliding_config.pt\n",
      "\n",
      "Config summary:\n",
      "  - 64 vectors\n",
      "  - 124 experiments\n",
      "  - 1008 total interventions\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save role/trait config\n",
    "rt_config_file = f\"{output_dir}/role_trait_sliding_config.pt\"\n",
    "\n",
    "rt_config = {\n",
    "    'vectors': vectors_dict,\n",
    "    'experiments': rt_experiments\n",
    "}\n",
    "\n",
    "torch.save(rt_config, rt_config_file)\n",
    "\n",
    "print(f\"✓ Saved role/trait config to {rt_config_file}\")\n",
    "print(f\"\\nConfig summary:\")\n",
    "print(f\"  - {len(rt_config['vectors'])} vectors\")\n",
    "print(f\"  - {len(rt_config['experiments'])} experiments\")\n",
    "print(f\"  - {sum(len(exp['interventions']) for exp in rt_config['experiments'])} total interventions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: LMSYS Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LMSYS data\n",
      "Metadata: {'dataset': 'lmsys/lmsys-chat-1m', 'model': 'Qwen/Qwen3-32B', 'n_conversations_requested': 10000, 'seed': 42, 'language_filter': 'English', 'n_conversations_sampled': 10000, 'n_assistant_turns': 1206464}\n",
      "Vectors: 64\n"
     ]
    }
   ],
   "source": [
    "# Load LMSYS projection statistics\n",
    "lmsys_file = f\"{base_dir}/capped/projections/lmsys_10000.json\"\n",
    "\n",
    "with open(lmsys_file, 'r') as f:\n",
    "    lmsys_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded LMSYS data\")\n",
    "print(f\"Metadata: {lmsys_data.get('metadata', {})}\")\n",
    "print(f\"Vectors: {len(lmsys_data['per_vector_stats'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted percentiles for 64 vectors\n",
      "\n",
      "Sample percentiles for layer 32:\n",
      "    layer                           vector_name       p1  p25      p50    p75\n",
      "32     32  layer_32/contrast_role_pos3_default1 -7.90625  6.0  13.0625  19.25\n"
     ]
    }
   ],
   "source": [
    "# Extract percentiles from pre-computed statistics\n",
    "lmsys_percentile_data = []\n",
    "\n",
    "for vector_name, stats in lmsys_data['per_vector_stats'].items():\n",
    "    # Extract layer number\n",
    "    layer_num = int(vector_name.split('/')[0].replace('layer_', ''))\n",
    "    \n",
    "    # Get percentiles from pre-computed stats\n",
    "    percentiles_dict = stats['percentiles']\n",
    "    \n",
    "    lmsys_percentile_data.append({\n",
    "        'layer': layer_num,\n",
    "        'vector_name': vector_name,\n",
    "        'p1': float(percentiles_dict['1']),\n",
    "        'p25': float(percentiles_dict['25']),\n",
    "        'p50': float(percentiles_dict['50']),\n",
    "        'p75': float(percentiles_dict['75'])\n",
    "    })\n",
    "\n",
    "df_lmsys_percentiles = pd.DataFrame(lmsys_percentile_data).sort_values('layer')\n",
    "print(f\"\\nExtracted percentiles for {len(df_lmsys_percentiles)} vectors\")\n",
    "print(f\"\\nSample percentiles for layer {layer}:\")\n",
    "print(df_lmsys_percentiles[df_lmsys_percentiles['layer'] == layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 20 LMSYS experiments:\n",
      "  - layers_24:32-p0.01: 8 interventions\n",
      "  - layers_24:32-p0.25: 8 interventions\n",
      "  - layers_24:32-p0.5: 8 interventions\n",
      "  - layers_24:32-p0.75: 8 interventions\n",
      "  - layers_32:40-p0.01: 8 interventions\n",
      "  - layers_32:40-p0.25: 8 interventions\n",
      "  - layers_32:40-p0.5: 8 interventions\n",
      "  - layers_32:40-p0.75: 8 interventions\n",
      "  - layers_40:48-p0.01: 8 interventions\n",
      "  - layers_40:48-p0.25: 8 interventions\n",
      "  - layers_40:48-p0.5: 8 interventions\n",
      "  - layers_40:48-p0.75: 8 interventions\n",
      "  - layers_48:56-p0.01: 8 interventions\n",
      "  - layers_48:56-p0.25: 8 interventions\n",
      "  - layers_48:56-p0.5: 8 interventions\n",
      "  - layers_48:56-p0.75: 8 interventions\n",
      "  - layers_56:64-p0.01: 8 interventions\n",
      "  - layers_56:64-p0.25: 8 interventions\n",
      "  - layers_56:64-p0.5: 8 interventions\n",
      "  - layers_56:64-p0.75: 8 interventions\n"
     ]
    }
   ],
   "source": [
    "# Build LMSYS experiments\n",
    "lmsys_experiments = build_experiments(\n",
    "    percentile_df=df_lmsys_percentiles,\n",
    "    percentiles=percentiles,\n",
    "    layer_selections=layer_selections,\n",
    "    vectors_dict=vectors_dict\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated {len(lmsys_experiments)} LMSYS experiments:\")\n",
    "for exp in lmsys_experiments:\n",
    "    print(f\"  - {exp['id']}: {len(exp['interventions'])} interventions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample experiment details:\n",
      "\n",
      "layers_24:32-p0.01:\n",
      "  Vectors: 8\n",
      "  Cap range: -59.50 to -11.38\n",
      "  First 3 interventions:\n",
      "    layer_24/contrast_role_pos3_default1: -59.5000\n",
      "    layer_25/contrast_role_pos3_default1: -49.7500\n",
      "    layer_26/contrast_role_pos3_default1: -34.5000\n",
      "\n",
      "layers_32:40-p0.01:\n",
      "  Vectors: 8\n",
      "  Cap range: -22.12 to -6.78\n",
      "  First 3 interventions:\n",
      "    layer_32/contrast_role_pos3_default1: -7.9062\n",
      "    layer_33/contrast_role_pos3_default1: -6.7812\n",
      "    layer_34/contrast_role_pos3_default1: -10.9375\n",
      "\n",
      "layers_40:48-p0.01:\n",
      "  Vectors: 8\n",
      "  Cap range: -81.00 to -20.75\n",
      "  First 3 interventions:\n",
      "    layer_40/contrast_role_pos3_default1: -20.7500\n",
      "    layer_41/contrast_role_pos3_default1: -21.6250\n",
      "    layer_42/contrast_role_pos3_default1: -24.8750\n",
      "\n",
      "layers_48:56-p0.01:\n",
      "  Vectors: 8\n",
      "  Cap range: -67.50 to -47.00\n",
      "  First 3 interventions:\n",
      "    layer_48/contrast_role_pos3_default1: -51.7500\n",
      "    layer_49/contrast_role_pos3_default1: -54.5000\n",
      "    layer_50/contrast_role_pos3_default1: -52.7500\n"
     ]
    }
   ],
   "source": [
    "# Show sample experiments\n",
    "print(\"\\nSample experiment details:\")\n",
    "for i in [0, 4, 8, 12]:\n",
    "    exp = lmsys_experiments[i]\n",
    "    caps = [interv['cap'] for interv in exp['interventions']]\n",
    "    print(f\"\\n{exp['id']}:\")\n",
    "    print(f\"  Vectors: {len(exp['interventions'])}\")\n",
    "    print(f\"  Cap range: {min(caps):.2f} to {max(caps):.2f}\")\n",
    "    print(f\"  First 3 interventions:\")\n",
    "    for interv in exp['interventions'][:3]:\n",
    "        print(f\"    {interv['vector']}: {interv['cap']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved LMSYS config to /workspace/qwen-3-32b/capped/configs/lmsys_10000_eighths_config.pt\n",
      "\n",
      "Config summary:\n",
      "  - 64 vectors\n",
      "  - 20 experiments\n",
      "  - 160 total interventions\n"
     ]
    }
   ],
   "source": [
    "# Save LMSYS config\n",
    "lmsys_config_file = f\"{output_dir}/lmsys_10000_eighths_config.pt\"\n",
    "\n",
    "lmsys_config = {\n",
    "    'vectors': vectors_dict,\n",
    "    'experiments': lmsys_experiments\n",
    "}\n",
    "\n",
    "torch.save(lmsys_config, lmsys_config_file)\n",
    "\n",
    "print(f\"✓ Saved LMSYS config to {lmsys_config_file}\")\n",
    "print(f\"\\nConfig summary:\")\n",
    "print(f\"  - {len(lmsys_config['vectors'])} vectors\")\n",
    "print(f\"  - {len(lmsys_config['experiments'])} experiments\")\n",
    "print(f\"  - {sum(len(exp['interventions']) for exp in lmsys_config['experiments'])} total interventions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Config Generation Complete\n",
      "======================================================================\n",
      "\n",
      "Model: qwen-3-32b\n",
      "Total layers: 64\n",
      "\n",
      "Generated configs:\n",
      "  1. /workspace/qwen-3-32b/capped/configs/role_trait_eighths_config.pt\n",
      "     - 20 experiments\n",
      "     - Based on role/trait projection data\n",
      "\n",
      "  2. /workspace/qwen-3-32b/capped/configs/lmsys_10000_eighths_config.pt\n",
      "     - 20 experiments\n",
      "     - Based on LMSYS-Chat-1M projection data\n",
      "\n",
      "Percentiles used: [0.01, 0.25, 0.5, 0.75]\n",
      "Layer selections: ['24:32', '32:40', '40:48', '48:56', '56:64']\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Config Generation Complete\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel: {model_name}\")\n",
    "print(f\"Total layers: {total_layers}\")\n",
    "print(f\"\\nGenerated configs:\")\n",
    "print(f\"  1. {rt_config_file}\")\n",
    "print(f\"     - {len(rt_config['experiments'])} experiments\")\n",
    "print(f\"     - Based on role/trait projection data\")\n",
    "print(f\"\\n  2. {lmsys_config_file}\")\n",
    "print(f\"     - {len(lmsys_config['experiments'])} experiments\")\n",
    "print(f\"     - Based on LMSYS-Chat-1M projection data\")\n",
    "print(f\"\\nPercentiles used: {percentiles}\")\n",
    "print(f\"Layer selections: {list(layer_selections.keys())}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
