{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28531137",
   "metadata": {},
   "source": [
    "# Analyze scores for each trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f3bcdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:08.842015Z",
     "iopub.status.busy": "2025-08-06T00:18:08.841387Z",
     "iopub.status.idle": "2025-08-06T00:18:09.171163Z",
     "shell.execute_reply": "2025-08-06T00:18:09.170519Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47c1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_short = \"gemma-3-27b\"\n",
    "\n",
    "dir = f'{model_short}/traits_240'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50bcb7",
   "metadata": {},
   "source": [
    "## Score statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411c5350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:09.175040Z",
     "iopub.status.busy": "2025-08-06T00:18:09.174845Z",
     "iopub.status.idle": "2025-08-06T00:18:09.200056Z",
     "shell.execute_reply": "2025-08-06T00:18:09.199491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 traits with scores\n"
     ]
    }
   ],
   "source": [
    "# load data from data/extract_scores\n",
    "score_dir = f\"/workspace/{dir}/extract_scores\"\n",
    "\n",
    "# iterate through each json file in the directory\n",
    "scores = {}\n",
    "for file in os.listdir(score_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(score_dir, file), \"r\") as f:\n",
    "            scores[file.replace(\".json\", \"\")] = json.load(f)\n",
    "\n",
    "print(f\"Found {len(scores.keys())} traits with scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "xn9eevi5y8h",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:09.203182Z",
     "iopub.status.busy": "2025-08-06T00:18:09.203055Z",
     "iopub.status.idle": "2025-08-06T00:18:09.222862Z",
     "shell.execute_reply": "2025-08-06T00:18:09.222318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refusal Statistics:\n",
      "Total refusals across all traits: 0\n",
      "Traits with refusals: 0\n"
     ]
    }
   ],
   "source": [
    "# Analyze refusals and clean data\n",
    "refusal_info = {}\n",
    "scores_clean = {}\n",
    "\n",
    "for trait, score_obj in scores.items():\n",
    "    refusals = []\n",
    "    cleaned_scores = {}\n",
    "    \n",
    "    # Check each score for refusals\n",
    "    for key, value in score_obj.items():\n",
    "        if value == \"REFUSAL\":\n",
    "            refusals.append(key)\n",
    "            cleaned_scores[key] = 0  # Replace refusals with NaN\n",
    "        else:\n",
    "            cleaned_scores[key] = float(value)  # Ensure numeric\n",
    "    \n",
    "    scores_clean[trait] = cleaned_scores\n",
    "    refusal_info[trait] = {\n",
    "        \"refusals\": refusals,\n",
    "        \"refusal_count\": len(refusals)\n",
    "    }\n",
    "\n",
    "# Show refusal statistics\n",
    "total_refusals = sum(info[\"refusal_count\"] for info in refusal_info.values())\n",
    "traits_with_refusals = sum(1 for info in refusal_info.values() if info[\"refusal_count\"] > 0)\n",
    "\n",
    "print(f\"Refusal Statistics:\")\n",
    "print(f\"Total refusals across all traits: {total_refusals}\")\n",
    "print(f\"Traits with refusals: {traits_with_refusals}\")\n",
    "\n",
    "if total_refusals > 0:\n",
    "    sorted_refusals = sorted(refusal_info.items(), key=lambda x: x[1][\"refusal_count\"], reverse=True)\n",
    "    print(f\"\\nTop 10 traits with most refusals:\")\n",
    "    for trait, info in sorted_refusals[:10]:\n",
    "        if info[\"refusal_count\"] > 0:\n",
    "            print(f\"  {trait}: {info['refusal_count']} refusals - {info['refusals']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918944a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:09.225377Z",
     "iopub.status.busy": "2025-08-06T00:18:09.225242Z",
     "iopub.status.idle": "2025-08-06T00:18:09.259886Z",
     "shell.execute_reply": "2025-08-06T00:18:09.259317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created numpy arrays for 240 traits\n",
      "Shape of each array: (3, 5, 240)\n",
      "Example (first trait): zealous\n",
      "Pos scores for first 2 prompts, 5 questions:\n",
      "[[ 98.  95.  95.  95. 100.]\n",
      " [ 95.  95.  95.  95. 100.]]\n",
      "Neg scores for first 2 prompts, 5 questions:\n",
      "[[20. 10. 10. 10. 20.]\n",
      " [20. 10. 10. 40. 20.]]\n"
     ]
    }
   ],
   "source": [
    "# Create numpy arrays using cleaned scores (refusals as NaN)\n",
    "# Structure: 3D tensor with shape (3 types, 5 prompts, 240 questions)\n",
    "scores_np = {}\n",
    "\n",
    "for trait, cleaned_scores in scores_clean.items():\n",
    "    # Create 3D array: [type, prompt, question]\n",
    "    scores_3d = np.full((3, 5, 240), np.nan)\n",
    "    \n",
    "    # Extract scores for each type, prompt, and question\n",
    "    for prompt_idx in range(5):\n",
    "        for question_idx in range(240):\n",
    "            # pos scores\n",
    "            pos_key = f\"pos_p{prompt_idx}_q{question_idx}\"\n",
    "            if pos_key in cleaned_scores:\n",
    "                scores_3d[0, prompt_idx, question_idx] = cleaned_scores[pos_key]\n",
    "            \n",
    "            # neg scores  \n",
    "            neg_key = f\"neg_p{prompt_idx}_q{question_idx}\"\n",
    "            if neg_key in cleaned_scores:\n",
    "                scores_3d[1, prompt_idx, question_idx] = cleaned_scores[neg_key]\n",
    "            \n",
    "            # default scores\n",
    "            default_key = f\"default_p{prompt_idx}_q{question_idx}\"\n",
    "            if default_key in cleaned_scores:\n",
    "                scores_3d[2, prompt_idx, question_idx] = cleaned_scores[default_key]\n",
    "    \n",
    "    scores_np[trait] = scores_3d\n",
    "\n",
    "print(f\"Created numpy arrays for {len(scores_np)} traits\")\n",
    "print(f\"Shape of each array: {next(iter(scores_np.values())).shape}\")\n",
    "print(f\"Example (first trait): {list(scores_np.keys())[0]}\")\n",
    "example_trait = list(scores_np.keys())[0]\n",
    "print(f\"Pos scores for first 2 prompts, 5 questions:\\n{scores_np[example_trait][0, :2, :5]}\")\n",
    "print(f\"Neg scores for first 2 prompts, 5 questions:\\n{scores_np[example_trait][1, :2, :5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eab3243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T00:18:09.262430Z",
     "iopub.status.busy": "2025-08-06T00:18:09.262302Z",
     "iopub.status.idle": "2025-08-06T00:18:09.275196Z",
     "shell.execute_reply": "2025-08-06T00:18:09.274665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exported statistics to pos.csv\n",
      "Shape: (240, 2)\n"
     ]
    }
   ],
   "source": [
    "# Calculate simplified statistics for each trait\n",
    "stats = {}\n",
    "\n",
    "for trait, scores_3d in scores_np.items():\n",
    "    pos_scores = scores_3d[0]  # shape: (5, 20) \n",
    "    \n",
    "    # Count all pos/neg pairs with same prompt_index and question_index\n",
    "    pos_70_count = 0\n",
    "    pos_40_70_count = 0\n",
    "    \n",
    "    # Check all 100 pairs (5 prompts Ã— 20 questions)\n",
    "    for prompt_idx in range(5):\n",
    "        for question_idx in range(240):\n",
    "            pos_val = pos_scores[prompt_idx, question_idx]\n",
    "           \n",
    "            \n",
    "            # Skip if either value is NaN\n",
    "            if not (np.isnan(pos_val)):\n",
    "                # Count high pos, low neg cases\n",
    "                if pos_val >= 70:\n",
    "                    pos_70_count += 1\n",
    "                if pos_val >= 40 and pos_val < 70:\n",
    "                    pos_40_70_count += 1\n",
    "    \n",
    "    stats[trait] = {\n",
    "        \"pos_70_count\": pos_70_count,\n",
    "        \"pos_40_70_count\": pos_40_70_count,\n",
    "    }\n",
    "\n",
    "\n",
    "# Export to CSV\n",
    "stats_df = pd.DataFrame.from_dict(stats, orient='index')\n",
    "stats_df.index.name = 'trait'\n",
    "\n",
    "stats_df.to_csv(f'./results/{model_short}/pos.csv')\n",
    "print(f\"\\nExported statistics to pos.csv\")\n",
    "print(f\"Shape: {stats_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0124e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "45\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# get number of traits with pos_70_count >= 10\n",
    "print(len([trait for trait, stats in stats.items() if stats['pos_70_count'] >= 10]))\n",
    "\n",
    "# get number of traits with pos_40_70_count >= 10\n",
    "print(len([trait for trait, stats in stats.items() if stats['pos_40_70_count'] >= 10]))\n",
    "\n",
    "# get number of traits with pos_70_count >= 10 and pos_40_70_count >= 10\n",
    "print(len([trait for trait, stats in stats.items() if stats['pos_70_count'] >= 10 and stats['pos_40_70_count'] >= 10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466a3113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example pos-neg statistics for 'zealous':\n",
      "  pos_minus_neg_mean: 81.24\n",
      "  high_pos_low_neg_count: 1191\n",
      "  large_diff_count: 1191\n",
      "\n",
      "Calculated pos-neg statistics for 240 traits\n",
      "\n",
      "High pos, low neg count distribution: min=147, max=1200, mean=1086.0\n",
      "Large diff count distribution: min=152, max=1200, mean=1087.4\n",
      "\n",
      "Exported pos-neg statistics to pos_neg.csv\n",
      "Shape: (240, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculate pos - neg statistics similar to pos - default\n",
    "pos_neg_stats = {}\n",
    "\n",
    "for trait, scores_3d in scores_np.items():\n",
    "    pos_scores = scores_3d[0]      # shape: (5, 240) \n",
    "    neg_scores = scores_3d[1]      # shape: (5, 240)\n",
    "    \n",
    "    # Mean difference between pos and neg across all samples\n",
    "    pos_minus_neg_mean = np.nanmean(pos_scores - neg_scores)\n",
    "    \n",
    "    # Count all pos/neg pairs with same prompt_index and question_index\n",
    "    high_pos_low_neg_count = 0\n",
    "    large_diff_count = 0\n",
    "    \n",
    "    # Check all 1200 pairs (5 prompts Ã— 240 questions)\n",
    "    for prompt_idx in range(5):\n",
    "        for question_idx in range(240):\n",
    "            pos_val = pos_scores[prompt_idx, question_idx]\n",
    "            neg_val = neg_scores[prompt_idx, question_idx]\n",
    "            \n",
    "            # Skip if either value is NaN\n",
    "            if not (np.isnan(pos_val) or np.isnan(neg_val)):\n",
    "                # Count high pos, low neg cases\n",
    "                if pos_val > 50 and neg_val < 50:\n",
    "                    high_pos_low_neg_count += 1\n",
    "                \n",
    "                # Count large difference cases  \n",
    "                if abs(pos_val - neg_val) > 40:\n",
    "                    large_diff_count += 1\n",
    "    \n",
    "    pos_neg_stats[trait] = {\n",
    "        \"pos_minus_neg_mean\": pos_minus_neg_mean,\n",
    "        \"high_pos_low_neg_count\": high_pos_low_neg_count,\n",
    "        \"large_diff_count\": large_diff_count\n",
    "    }\n",
    "\n",
    "# Show example statistics for first trait\n",
    "example_trait = list(pos_neg_stats.keys())[0]\n",
    "print(f\"Example pos-neg statistics for '{example_trait}':\")\n",
    "for key, value in pos_neg_stats[example_trait].items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nCalculated pos-neg statistics for {len(pos_neg_stats)} traits\")\n",
    "\n",
    "# Show summary of counts\n",
    "high_pos_counts = [s[\"high_pos_low_neg_count\"] for s in pos_neg_stats.values()]\n",
    "large_diff_counts = [s[\"large_diff_count\"] for s in pos_neg_stats.values()]\n",
    "print(f\"\\nHigh pos, low neg count distribution: min={min(high_pos_counts)}, max={max(high_pos_counts)}, mean={np.mean(high_pos_counts):.1f}\")\n",
    "print(f\"Large diff count distribution: min={min(large_diff_counts)}, max={max(large_diff_counts)}, mean={np.mean(large_diff_counts):.1f}\")\n",
    "\n",
    "# Export to CSV\n",
    "pos_neg_df = pd.DataFrame.from_dict(pos_neg_stats, orient='index')\n",
    "pos_neg_df.index.name = 'trait'\n",
    "pos_neg_df.to_csv(f'./results/{model_short}/pos_neg.csv')\n",
    "print(f\"\\nExported pos-neg statistics to pos_neg.csv\")\n",
    "print(f\"Shape: {pos_neg_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd408866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example pos-default statistics for 'zealous':\n",
      "  pos_minus_default_mean: nan\n",
      "  high_pos_low_default_count: 0\n",
      "  large_diff_count: 0\n",
      "\n",
      "Calculated pos-default statistics for 240 traits\n",
      "\n",
      "High pos, low default count distribution: min=0, max=0, mean=0.0\n",
      "Large diff count distribution: min=0, max=0, mean=0.0\n",
      "\n",
      "Exported pos-default statistics to pos_default.csv\n",
      "Shape: (240, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1906205/4045600055.py:9: RuntimeWarning: Mean of empty slice\n",
      "  pos_minus_default_mean = np.nanmean(pos_scores - default_scores)\n"
     ]
    }
   ],
   "source": [
    "# Calculate pos - default statistics similar to pos - neg\n",
    "pos_default_stats = {}\n",
    "\n",
    "for trait, scores_3d in scores_np.items():\n",
    "    pos_scores = scores_3d[0]      # shape: (5, 20) \n",
    "    default_scores = scores_3d[2]  # shape: (5, 20)\n",
    "    \n",
    "    # Mean difference between pos and default across all samples\n",
    "    pos_minus_default_mean = np.nanmean(pos_scores - default_scores)\n",
    "    \n",
    "    # Count all pos/default pairs with same prompt_index and question_index\n",
    "    high_pos_low_default_count = 0\n",
    "    large_diff_count = 0\n",
    "    \n",
    "    # Check all 100 pairs (5 prompts Ã— 20 questions)\n",
    "    for prompt_idx in range(5):\n",
    "        for question_idx in range(20):\n",
    "            pos_val = pos_scores[prompt_idx, question_idx]\n",
    "            default_val = default_scores[prompt_idx, question_idx]\n",
    "            \n",
    "            # Skip if either value is NaN\n",
    "            if not (np.isnan(pos_val) or np.isnan(default_val)):\n",
    "                # Count high pos, low default cases\n",
    "                if pos_val > 50 and default_val < 50:\n",
    "                    high_pos_low_default_count += 1\n",
    "                \n",
    "                # Count large difference cases  \n",
    "                if abs(pos_val - default_val) > 40:\n",
    "                    large_diff_count += 1\n",
    "    \n",
    "    pos_default_stats[trait] = {\n",
    "        \"pos_minus_default_mean\": pos_minus_default_mean,\n",
    "        \"high_pos_low_default_count\": high_pos_low_default_count,\n",
    "        \"large_diff_count\": large_diff_count\n",
    "    }\n",
    "\n",
    "# Show example statistics for first trait\n",
    "example_trait = list(pos_default_stats.keys())[0]\n",
    "print(f\"Example pos-default statistics for '{example_trait}':\")\n",
    "for key, value in pos_default_stats[example_trait].items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nCalculated pos-default statistics for {len(pos_default_stats)} traits\")\n",
    "\n",
    "# Show summary of counts\n",
    "high_pos_counts = [s[\"high_pos_low_default_count\"] for s in pos_default_stats.values()]\n",
    "large_diff_counts = [s[\"large_diff_count\"] for s in pos_default_stats.values()]\n",
    "print(f\"\\nHigh pos, low default count distribution: min={min(high_pos_counts)}, max={max(high_pos_counts)}, mean={np.mean(high_pos_counts):.1f}\")\n",
    "print(f\"Large diff count distribution: min={min(large_diff_counts)}, max={max(large_diff_counts)}, mean={np.mean(large_diff_counts):.1f}\")\n",
    "\n",
    "# Export to CSV\n",
    "pos_default_df = pd.DataFrame.from_dict(pos_default_stats, orient='index')\n",
    "pos_default_df.index.name = 'trait'\n",
    "pos_default_df.to_csv(f'./results/{model_short}/pos_default.csv')\n",
    "print(f\"\\nExported pos-default statistics to pos_default.csv\")\n",
    "print(f\"Shape: {pos_default_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a4e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
